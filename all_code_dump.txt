import sqlite3, math, requests

API_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJub25jZSI6IjQ3YWMxNmY1LWJhMDgtNDEzMi05M2I4LTdjZmZhNTQ0NWQwNiIsIm9yZ0lkIjoiNDcxNDM0IiwidXNlcklkIjoiNDg0OTcyIiwidHlwZUlkIjoiM2I5YzlmOGEtNjlkNy00YzBkLWI1YTUtMjY4MzIwZDYzNzliIiwidHlwZSI6IlBST0pFQ1QiLCJpYXQiOjE3NTgyMjQ2NTgsImV4cCI6NDkxMzk4NDY1OH0.6HJ4ANNa_RXnBrnQkVZIZTOX4ksum0hz3elvq59pj8Q"

def get_whales():
    conn = sqlite3.connect("whales.db")
    cur = conn.cursor()
    cur.execute("SELECT address FROM whales;")
    addrs = [row[0] for row in cur.fetchall()]
    conn.close()
    return addrs

def fetch_breakdown(addr):
    url = f"https://deep-index.moralis.io/api/v2.2/wallets/{addr}/profitability"
    headers = {"X-API-Key": API_KEY}
    r = requests.get(url, headers=headers)
    r.raise_for_status()
    return r.json()


def score_whale(breakdown):
    result = breakdown.get("result", [])
    if not result: 
        return 0
    
    pnl = {}
    for t in result:
        realized = float(t.get("realized_profit_usd", 0) or 0)
        token = t.get("symbol") or t.get("token_address")
        pnl[token] = pnl.get(token, 0) + realized
    
    total_pnl = sum(pnl.values())
    if total_pnl <= 0:
        return 0
    
    # concentration index
    shares = [v/total_pnl for v in pnl.values() if v > 0]
    hhi = sum(s**2 for s in shares)
    diversity = 1 - hhi
    
    # summary numbers
    roi_pct = float(breakdown.get("total_realized_profit_percentage", 0) or 0)
    trades = int(breakdown.get("total_count_of_trades", len(result)))
    win_rate = len([v for v in pnl.values() if v > 0]) / len(pnl)
    
    score_base = (
        0.35*roi_pct +
        0.25*win_rate*100 +
        0.15*math.log(trades+1) +
        0.15*(total_pnl/1000)
    )
    adjusted = score_base * (0.1 + 0.9*diversity)
    return adjusted

def update_score(addr, score):
    conn = sqlite3.connect("whales.db")
    cur = conn.cursor()
    cur.execute("UPDATE whales SET score=? WHERE address=?", (score, addr))
    conn.commit()
    conn.close()

if __name__ == "__main__":
    for addr in get_whales():
        breakdown = fetch_breakdown(addr)
        rating = score_whale(breakdown)
        update_score(addr, rating)
        print(addr, "→", rating)
"""
Performance optimizations for Allocator AI based on hardware
"""

import asyncio
import concurrent.futures
from typing import List
import time

class PerformanceOptimizer:
    """Hardware-aware performance optimizations"""
    
    def __init__(self, cpu_cores: int = 4, ram_gb: int = 8):
        self.cpu_cores = cpu_cores
        self.ram_gb = ram_gb
        self.optimal_batch_size = self._calculate_batch_size()
        self.max_workers = self._calculate_max_workers()
    
    def _calculate_batch_size(self) -> int:
        """Calculate optimal batch size based on available RAM"""
        if self.ram_gb >= 16:
            return 500  # Large batches for high-memory systems
        elif self.ram_gb >= 8:
            return 200  # Medium batches
        else:
            return 50   # Small batches for low-memory systems
    
    def _calculate_max_workers(self) -> int:
        """Calculate optimal worker threads based on CPU cores"""
        if self.cpu_cores >= 8:
            return 6  # Leave 2 cores for other processes
        elif self.cpu_cores >= 4:
            return 3  # Leave 1 core free
        else:
            return 2  # Conservative for dual-core
    
    async def optimized_block_scan(self, w3, start_block: int, end_block: int):
        """Optimized parallel block scanning"""
        
        # Split blocks into batches
        block_ranges = []
        total_blocks = end_block - start_block + 1
        
        for i in range(0, total_blocks, self.optimal_batch_size):
            batch_start = start_block + i
            batch_end = min(start_block + i + self.optimal_batch_size - 1, end_block)
            block_ranges.append((batch_start, batch_end))
        
        # Process batches in parallel
        candidate_stats = {}
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_range = {
                executor.submit(self._scan_block_range, w3, start, end): (start, end)
                for start, end in block_ranges
            }
            
            for future in concurrent.futures.as_completed(future_to_range):
                try:
                    batch_results = future.result()
                    # Merge results
                    for addr, stats in batch_results.items():
                        if addr not in candidate_stats:
                            candidate_stats[addr] = {"trades": 0, "profit": 0}
                        candidate_stats[addr]["trades"] += stats["trades"]
                        candidate_stats[addr]["profit"] += stats["profit"]
                except Exception as e:
                    print(f"Batch failed: {e}")
        
        return candidate_stats
    
    def _scan_block_range(self, w3, start_block: int, end_block: int):
        """Scan a range of blocks - optimized for single thread"""
        candidate_stats = {}
        
        # Batch RPC calls for better network efficiency
        try:
            # Use batch requests if supported by your RPC
            blocks = []
            for block_num in range(start_block, end_block + 1):
                try:
                    block = w3.eth.get_block(block_num, full_transactions=True)
                    blocks.append(block)
                except:
                    continue
            
            # Process all blocks in memory (CPU optimization)
            for block in blocks:
                for tx in block.transactions:
                    if tx.to and tx.to.lower() in [
                        "0x7a250d5630b4cf539739df2c5dacb4c659f2488d",
                        "0xe592427a0aece92de3edee1f18e0157c05861564"
                    ]:
                        actor = tx["from"].lower()
                        if actor not in candidate_stats:
                            candidate_stats[actor] = {"trades": 0, "profit": 0}
                        candidate_stats[actor]["trades"] += 1
                        candidate_stats[actor]["profit"] += tx.value / (10**18)
                        
        except Exception as e:
            print(f"Error scanning blocks {start_block}-{end_block}: {e}")
        
        return candidate_stats

# Hardware-specific configurations
HARDWARE_CONFIGS = {
    "budget_vps": {
        "cpu_cores": 2,
        "ram_gb": 4,
        "discovery_refresh": 600,  # 10 minutes
        "max_concurrent_modes": 2
    },
    "standard_vps": {
        "cpu_cores": 4,
        "ram_gb": 8,
        "discovery_refresh": 300,  # 5 minutes
        "max_concurrent_modes": 3
    },
    "high_performance": {
        "cpu_cores": 8,
        "ram_gb": 16,
        "discovery_refresh": 180,  # 3 minutes
        "max_concurrent_modes": 5
    }
}

def get_hardware_config(config_name: str = "standard_vps"):
    """Get optimized settings for your hardware"""
    return HARDWARE_CONFIGS.get(config_name, HARDWARE_CONFIGS["standard_vps"])
"""
Allocator AI - Automated Whale Following Trading Bot

A sophisticated cryptocurrency trading bot that automatically mirrors trades
from successful "whale" traders in real-time.
"""

__version__ = "2.0.0"
__author__ = "Allocator AI Team"

from .core.whale_tracker import WhaleTracker
from .core.trade_executor import TradeExecutor
from .core.risk_manager import RiskManager
from .data.database import DatabaseManager
from .monitoring.mempool_watcher import MempoolWatcher
from .web.dashboard import create_app

__all__ = [
    "WhaleTracker",
    "TradeExecutor", 
    "RiskManager",
    "DatabaseManager",
    "MempoolWatcher",
    "create_app"
]
"""
Monitoring and mempool watching for Allocator AI
"""

from .mempool_watcher import MempoolWatcher
from .trade_parser import TradeParser

__all__ = [
    "MempoolWatcher",
    "TradeParser"
]
"""
Trade parsing utilities for mempool transactions
"""

import logging
from typing import Dict, Any, Optional, List
from web3 import Web3
from decimal import Decimal

from ..utils.web3_utils import TokenManager

logger = logging.getLogger(__name__)


class TradeParser:
    """Parse swap transactions from various DEX protocols"""
    
    def __init__(self, w3: Web3, token_manager: Optional[TokenManager] = None):
        self.w3 = w3
        self.token_manager = token_manager or TokenManager(w3)
        
        # Router addresses (correct and checksummed)
        self.uniswap_v2 = Web3.to_checksum_address("0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D")
        self.uniswap_v3 = Web3.to_checksum_address("0xE592427A0AEce92De3Edee1F18E0157C05861564")
        
        # Load contract ABIs
        self.v2_abi = self._load_abi("uniswap_v2_router")
        self.v3_abi = self._load_abi("uniswap_v3_router")
        
        # Create contract instances
        self.uni_v2_contract = w3.eth.contract(address=self.uniswap_v2, abi=self.v2_abi)
        self.uni_v3_contract = w3.eth.contract(address=self.uniswap_v3, abi=self.v3_abi)
    
    def _load_abi(self, abi_name: str) -> list:
        """Load ABI from file"""
        import json
        import os
        
        abi_path = os.path.join("abis", f"{abi_name}.json")
        if os.path.exists(abi_path):
            with open(abi_path, 'r') as f:
                return json.load(f)
        else:
            logger.warning(f"ABI file not found: {abi_path}")
            return []
    
    def parse_swap_transaction(self, tx: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Parse a swap transaction and extract trade details"""
        try:
            to_address = tx.get("to", "").lower()
            input_data = tx.get("input", "")
            
            if not input_data or not input_data.startswith("0x"):
                return None
            
            # Determine router type and parse accordingly
            if to_address == self.uniswap_v2.lower():
                return self._parse_uniswap_v2_tx(tx, input_data)
            elif to_address == self.uniswap_v3.lower():
                return self._parse_uniswap_v3_tx(tx, input_data)
            else:
                return None
                
        except Exception as e:
            logger.debug(f"Failed to parse swap transaction: {e}")
            return None
    
    def _parse_uniswap_v2_tx(self, tx: Dict[str, Any], input_data: str) -> Optional[Dict[str, Any]]:
        """Parse Uniswap V2 transaction"""
        try:
            # Decode function call
            func_obj, params = self.uni_v2_contract.decode_function_input(input_data)
            func_name = func_obj.fn_name
            
            # Extract token addresses and amounts
            if func_name in ["swapExactTokensForTokens", "swapExactETHForTokens"]:
                path = params.get("path", [])
                amount_in = params.get("amountIn", 0)
                amount_out_min = params.get("amountOutMin", 0)
                
                if len(path) < 2:
                    return None
                
                token_in_addr = path[0]
                token_out_addr = path[-1]
                
            elif func_name in ["swapTokensForExactTokens", "swapTokensForExactETH"]:
                path = params.get("path", [])
                amount_in_max = params.get("amountInMax", 0)
                amount_out = params.get("amountOut", 0)
                
                if len(path) < 2:
                    return None
                
                token_in_addr = path[0]
                token_out_addr = path[-1]
                amount_in = amount_in_max
                amount_out_min = amount_out
                
            else:
                return None
            
            # Get token information
            token_in = self.token_manager.get_token_info(token_in_addr)
            token_out = self.token_manager.get_token_info(token_out_addr)
            
            # Convert amounts to human readable
            amount_in_human = self.token_manager.format_amount(amount_in, token_in["decimals"])
            amount_out_min_human = self.token_manager.format_amount(amount_out_min, token_out["decimals"])
            
            return {
                "from": tx["from"],
                "to": tx["to"],
                "fn_name": func_name,
                "token_in": token_in,
                "token_out": token_out,
                "amount_in": amount_in_human,
                "amount_out_min": amount_out_min_human,
                "raw": tx
            }
            
        except Exception as e:
            logger.debug(f"Failed to parse V2 transaction: {e}")
            return None
    
    def _parse_uniswap_v3_tx(self, tx: Dict[str, Any], input_data: str) -> Optional[Dict[str, Any]]:
        """Parse Uniswap V3 transaction"""
        try:
            # Decode function call
            func_obj, params = self.uni_v3_contract.decode_function_input(input_data)
            func_name = func_obj.fn_name
            
            if func_name == "exactInputSingle":
                # Single token swap
                swap_params = params.get("params", {})
                token_in_addr = swap_params.get("tokenIn")
                token_out_addr = swap_params.get("tokenOut")
                amount_in = swap_params.get("amountIn", 0)
                amount_out_min = swap_params.get("amountOutMinimum", 0)
                fee = swap_params.get("fee", 3000)
                
            elif func_name == "exactInput":
                # Multi-hop swap - would need more complex parsing
                # For now, return None as it's more complex
                return None
                
            else:
                return None
            
            if not token_in_addr or not token_out_addr:
                return None
            
            # Get token information
            token_in = self.token_manager.get_token_info(token_in_addr)
            token_out = self.token_manager.get_token_info(token_out_addr)
            
            # Convert amounts to human readable
            amount_in_human = self.token_manager.format_amount(amount_in, token_in["decimals"])
            amount_out_min_human = self.token_manager.format_amount(amount_out_min, token_out["decimals"])
            
            return {
                "from": tx["from"],
                "to": tx["to"],
                "fn_name": func_name,
                "token_in": token_in,
                "token_out": token_out,
                "amount_in": amount_in_human,
                "amount_out_min": amount_out_min_human,
                "fee": fee,
                "raw": tx
            }
            
        except Exception as e:
            logger.debug(f"Failed to parse V3 transaction: {e}")
            return None
    
    def extract_token_path(self, tx: Dict[str, Any]) -> Optional[List[str]]:
        """Extract token path from transaction"""
        try:
            to_address = tx.get("to", "").lower()
            input_data = tx.get("input", "")
            
            if to_address == self.uniswap_v2.lower():
                func_obj, params = self.uni_v2_contract.decode_function_input(input_data)
                return params.get("path", [])
            elif to_address == self.uniswap_v3.lower():
                func_obj, params = self.uni_v3_contract.decode_function_input(input_data)
                if func_obj.fn_name == "exactInputSingle":
                    swap_params = params.get("params", {})
                    return [swap_params.get("tokenIn"), swap_params.get("tokenOut")]
            
            return None
            
        except Exception as e:
            logger.debug(f"Failed to extract token path: {e}")
            return None
    
    def is_swap_transaction(self, tx: Dict[str, Any]) -> bool:
        """Check if transaction is a swap transaction"""
        try:
            to_address = tx.get("to", "").lower()
            input_data = tx.get("input", "")
            
            if not input_data or not input_data.startswith("0x"):
                return False
            
            # Check if it's a known router
            if to_address not in [self.uniswap_v2.lower(), self.uniswap_v3.lower()]:
                return False
            
            # Try to decode the function call
            if to_address == self.uniswap_v2.lower():
                func_obj, _ = self.uni_v2_contract.decode_function_input(input_data)
                return func_obj.fn_name.startswith("swap")
            elif to_address == self.uniswap_v3.lower():
                func_obj, _ = self.uni_v3_contract.decode_function_input(input_data)
                return func_obj.fn_name in ["exactInputSingle", "exactInput"]
            
            return False
            
        except Exception:
            return False
"""
Mempool monitoring and transaction processing
"""

import time
import logging
from typing import Dict, Any, List, Optional, Callable
from web3 import Web3
from web3.exceptions import TransactionNotFound

from .trade_parser import TradeParser
from ..utils.validation import validate_trade_data

logger = logging.getLogger(__name__)


class MempoolWatcher:
    """Advanced mempool watcher with filtering and processing"""
    
    def __init__(self, w3: Web3, tracked_whales: set, 
                 trade_callback: Optional[Callable] = None):
        self.w3 = w3
        self.tracked_whales = tracked_whales
        self.trade_callback = trade_callback
        self.trade_parser = TradeParser(w3)
        
        # Router addresses to monitor (checksummed)
        self.monitored_routers = {
            Web3.to_checksum_address("0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D").lower(),  # Uniswap V2
            Web3.to_checksum_address("0xE592427A0AEce92De3Edee1F18E0157C05861564").lower()   # Uniswap V3
        }
        
        # State
        self.is_running = False
        self.last_processed_block = 0
        
    def start_watching(self, use_mempool: bool = True) -> None:
        """Start watching for whale transactions"""
        import threading
        
        self.is_running = True
        
        def watch_worker():
            if use_mempool:
                self._watch_mempool()
            else:
                self._watch_blocks()
        
        # Run monitoring in background thread
        watch_thread = threading.Thread(target=watch_worker, daemon=True)
        watch_thread.start()
        logger.info(f"Started {'mempool' if use_mempool else 'block'} monitoring in background thread")
    
    def stop_watching(self) -> None:
        """Stop watching"""
        self.is_running = False
        logger.info("Mempool watcher stopped")
    
    def _watch_mempool(self) -> None:
        """Watch pending mempool transactions"""
        logger.info("Starting mempool monitoring...")
        
        try:
            pending_filter = self.w3.eth.filter("pending")
            
            while self.is_running:
                try:
                    # Get new pending transactions
                    for tx_hash in pending_filter.get_new_entries():
                        if not self.is_running:
                            break
                        
                        try:
                            self._process_transaction(tx_hash)
                        except TransactionNotFound:
                            # Transaction was removed from mempool
                            continue
                        except Exception as e:
                            logger.debug(f"Error processing transaction {tx_hash}: {e}")
                            continue
                    
                    time.sleep(0.5)  # Small delay to prevent excessive CPU usage
                    
                except Exception as e:
                    logger.error(f"Mempool watcher error: {e}")
                    time.sleep(3)  # Wait before retrying
                    
        except Exception as e:
            logger.error(f"Failed to start mempool watcher: {e}")
            self.is_running = False
    
    def _watch_blocks(self) -> None:
        """Watch confirmed blocks (fallback when mempool not available)"""
        logger.info("Starting block monitoring (mempool fallback)...")
        
        last_block = self.w3.eth.block_number
        
        while self.is_running:
            try:
                current_block = self.w3.eth.block_number
                
                if current_block > last_block:
                    # Process new blocks
                    for block_num in range(last_block + 1, current_block + 1):
                        if not self.is_running:
                            break
                        
                        self._process_block(block_num)
                    
                    last_block = current_block
                
                time.sleep(2)  # Check every 2 seconds
                
            except Exception as e:
                logger.error(f"Block watcher error: {e}")
                time.sleep(5)
    
    def _process_transaction(self, tx_hash: str) -> None:
        """Process a single transaction"""
        try:
            tx = self.w3.eth.get_transaction(tx_hash)
            self._process_tx_data(tx)
        except Exception as e:
            logger.debug(f"Failed to process transaction {tx_hash}: {e}")
    
    def _process_block(self, block_number: int) -> None:
        """Process all transactions in a block"""
        try:
            block = self.w3.eth.get_block(block_number, full_transactions=True)
            
            for tx in block.transactions:
                if not self.is_running:
                    break
                
                self._process_tx_data(tx)
                
        except Exception as e:
            logger.debug(f"Failed to process block {block_number}: {e}")
    
    def _process_tx_data(self, tx: Dict[str, Any]) -> None:
        """Process transaction data and check if it's from a tracked whale"""
        try:
            # Check if transaction is from a tracked whale
            from_address = tx.get("from", "").lower()
            if from_address not in self.tracked_whales:
                return
            
            # Check if transaction is to a monitored router
            to_address = tx.get("to", "").lower()
            if to_address not in self.monitored_routers:
                return
            
            # Parse the trade
            trade_data = self.trade_parser.parse_swap_transaction(tx)
            if not trade_data:
                return
            
            # Validate trade data
            if not validate_trade_data(trade_data):
                logger.warning(f"Invalid trade data from {from_address}")
                return
            
            # Add whale address to trade data
            trade_data["whale_address"] = from_address
            
            logger.info(f"Detected whale trade: {from_address} -> {trade_data.get('token_in', {}).get('symbol', '?')} to {trade_data.get('token_out', {}).get('symbol', '?')}")
            
            # Call the trade callback if provided
            if self.trade_callback:
                try:
                    self.trade_callback(trade_data)
                except Exception as e:
                    logger.error(f"Trade callback error: {e}")
                    
        except Exception as e:
            logger.debug(f"Error processing transaction data: {e}")
    
    def add_whale(self, whale_address: str) -> None:
        """Add a whale to the watch list"""
        self.tracked_whales.add(whale_address.lower())
        logger.info(f"Added whale to watch list: {whale_address}")
    
    def remove_whale(self, whale_address: str) -> None:
        """Remove a whale from the watch list"""
        self.tracked_whales.discard(whale_address.lower())
        logger.info(f"Removed whale from watch list: {whale_address}")
    
    def get_watched_whales(self) -> List[str]:
        """Get list of watched whale addresses"""
        return list(self.tracked_whales)
    
    def is_whale_tracked(self, whale_address: str) -> bool:
        """Check if a whale is being tracked"""
        return whale_address.lower() in self.tracked_whales
    
    def get_status(self) -> Dict[str, Any]:
        """Get watcher status"""
        return {
            "is_running": self.is_running,
            "tracked_whales": len(self.tracked_whales),
            "monitored_routers": len(self.monitored_routers),
            "last_processed_block": self.last_processed_block
        }
"""
Data layer for Allocator AI
"""

from .database import DatabaseManager
from .cache import TTLCache, CacheManager

__all__ = [
    "DatabaseManager",
    "TTLCache", 
    "CacheManager"
]
"""
Caching system for Allocator AI
"""

import time
import threading
from typing import Any, Optional, Dict
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


class TTLCache:
    """Time-to-live cache for expensive operations"""
    
    def __init__(self, ttl_seconds: int = 300):
        self.cache = {}
        self.ttl = ttl_seconds
        self.lock = threading.Lock()
    
    def get(self, key: str) -> Optional[Any]:
        """Get value from cache if not expired"""
        with self.lock:
            if key in self.cache:
                value, timestamp = self.cache[key]
                if time.time() - timestamp < self.ttl:
                    return value
                else:
                    del self.cache[key]
            return None
    
    def set(self, key: str, value: Any) -> None:
        """Set value in cache with current timestamp"""
        with self.lock:
            self.cache[key] = (value, time.time())
    
    def clear(self) -> None:
        """Clear all cached values"""
        with self.lock:
            self.cache.clear()
    
    def size(self) -> int:
        """Get current cache size"""
        with self.lock:
            return len(self.cache)
    
    def cleanup_expired(self) -> int:
        """Remove expired entries and return count of removed items"""
        with self.lock:
            now = time.time()
            expired_keys = [
                key for key, (value, timestamp) in self.cache.items()
                if now - timestamp >= self.ttl
            ]
            for key in expired_keys:
                del self.cache[key]
            return len(expired_keys)


class CacheManager:
    """Centralized cache management for different data types"""
    
    def __init__(self):
        self.caches = {
            'token': TTLCache(ttl_seconds=3600),      # 1 hour for token data
            'price': TTLCache(ttl_seconds=60),        # 1 minute for prices
            'whale': TTLCache(ttl_seconds=1800),      # 30 minutes for whale data
            'moralis': TTLCache(ttl_seconds=3600),    # 1 hour for Moralis data
            'web3': TTLCache(ttl_seconds=300)         # 5 minutes for Web3 calls
        }
    
    def get(self, cache_type: str, key: str) -> Optional[Any]:
        """Get value from specific cache"""
        if cache_type in self.caches:
            return self.caches[cache_type].get(key)
        return None
    
    def set(self, cache_type: str, key: str, value: Any) -> None:
        """Set value in specific cache"""
        if cache_type in self.caches:
            self.caches[cache_type].set(key, value)
        else:
            logger.warning(f"Unknown cache type: {cache_type}")
    
    def clear(self, cache_type: Optional[str] = None) -> None:
        """Clear cache(s)"""
        if cache_type:
            if cache_type in self.caches:
                self.caches[cache_type].clear()
        else:
            for cache in self.caches.values():
                cache.clear()
    
    def cleanup_all(self) -> Dict[str, int]:
        """Cleanup all expired entries and return counts"""
        results = {}
        for name, cache in self.caches.items():
            results[name] = cache.cleanup_expired()
        return results
    
    def get_stats(self) -> Dict[str, Dict[str, Any]]:
        """Get cache statistics"""
        stats = {}
        for name, cache in self.caches.items():
            stats[name] = {
                'size': cache.size(),
                'ttl': cache.ttl
            }
        return stats


class RateLimiter:
    """Rate limiter to prevent API abuse and manage request frequency"""
    
    def __init__(self, max_calls: int, time_window: int):
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = defaultdict(list)
        self.lock = threading.Lock()
    
    def can_make_call(self, key: str) -> bool:
        """Check if a call can be made for the given key"""
        with self.lock:
            now = time.time()
            # Remove old calls outside the time window
            self.calls[key] = [call_time for call_time in self.calls[key] 
                              if now - call_time < self.time_window]
            
            return len(self.calls[key]) < self.max_calls
    
    def record_call(self, key: str) -> None:
        """Record a call for the given key"""
        with self.lock:
            self.calls[key].append(time.time())
    
    def get_remaining_calls(self, key: str) -> int:
        """Get remaining calls for the given key"""
        with self.lock:
            now = time.time()
            self.calls[key] = [call_time for call_time in self.calls[key] 
                              if now - call_time < self.time_window]
            return max(0, self.max_calls - len(self.calls[key]))
    
    def get_stats(self, key: str) -> Dict[str, Any]:
        """Get rate limiter stats for a key"""
        with self.lock:
            now = time.time()
            self.calls[key] = [call_time for call_time in self.calls[key] 
                              if now - call_time < self.time_window]
            return {
                'calls_made': len(self.calls[key]),
                'remaining': max(0, self.max_calls - len(self.calls[key])),
                'reset_time': self.calls[key][0] + self.time_window if self.calls[key] else now
            }
"""
Database management for Allocator AI
"""

import sqlite3
import threading
import time
import logging
from typing import Optional, List, Tuple, Any
from pathlib import Path

logger = logging.getLogger(__name__)


class DatabaseManager:
    """Optimized database manager with connection pooling and better performance"""
    
    def __init__(self, db_file: str = "whales.db"):
        self.db_file = db_file
        self.conn = None
        self.lock = threading.Lock()
        self._init_connection()
    
    def _init_connection(self):
        """Initialize database connection with optimizations"""
        with self.lock:
            if self.conn is None:
                self.conn = sqlite3.connect(
                    self.db_file, 
                    check_same_thread=False,
                    timeout=30.0
                )
                # Performance optimizations
                self.conn.execute("PRAGMA journal_mode=WAL")  # Better concurrency
                self.conn.execute("PRAGMA synchronous=NORMAL")  # Faster writes
                self.conn.execute("PRAGMA cache_size=10000")  # Larger cache
                self.conn.execute("PRAGMA temp_store=MEMORY")  # In-memory temp tables
                self._create_tables()
    
    def _create_tables(self):
        """Create database tables if they don't exist"""
        self.conn.execute("""
        CREATE TABLE IF NOT EXISTS whales (
            address TEXT PRIMARY KEY,
            moralis_roi_pct REAL,
            roi_usd REAL,
            trades INTEGER,
            cumulative_pnl REAL DEFAULT 0.0,
            risk_multiplier REAL DEFAULT 1.0,
            allocation_size REAL DEFAULT 0.0,
            score REAL DEFAULT 0.0,
            win_rate REAL DEFAULT 0.0,
            bootstrap_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_refresh TIMESTAMP
        )
        """)
        
        # Add new columns to existing table if they don't exist (for migration)
        try:
            self.conn.execute("ALTER TABLE whales ADD COLUMN cumulative_pnl REAL DEFAULT 0.0")
        except sqlite3.OperationalError:
            pass  # Column already exists
        
        try:
            self.conn.execute("ALTER TABLE whales ADD COLUMN risk_multiplier REAL DEFAULT 1.0")
        except sqlite3.OperationalError:
            pass  # Column already exists
        
        try:
            self.conn.execute("ALTER TABLE whales ADD COLUMN allocation_size REAL DEFAULT 0.0")
        except sqlite3.OperationalError:
            pass  # Column already exists
        
        try:
            self.conn.execute("ALTER TABLE whales ADD COLUMN score REAL DEFAULT 0.0")
        except sqlite3.OperationalError:
            pass  # Column already exists
        
        try:
            self.conn.execute("ALTER TABLE whales ADD COLUMN win_rate REAL DEFAULT 0.0")
        except sqlite3.OperationalError:
            pass  # Column already exists
        
        try:
            self.conn.execute("ALTER TABLE whales ADD COLUMN discarded_timestamp TIMESTAMP")
        except sqlite3.OperationalError:
            pass  # Column already exists
        
        # Create trades table for detailed trade history
        self.conn.execute("""
        CREATE TABLE IF NOT EXISTS trades (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            actor TEXT NOT NULL,
            whale_address TEXT NOT NULL,
            router TEXT,
            path TEXT,
            side TEXT,
            amount_in REAL,
            amount_out REAL,
            token_in TEXT,
            token_out TEXT,
            price_impact REAL,
            gas_cost REAL,
            pnl REAL,
            cum_pnl REAL,
            risk_mult REAL,
            mode TEXT,
            tx_hash TEXT,
            FOREIGN KEY (whale_address) REFERENCES whales (address)
        )
        """)
        
        # Create whale_token_pnl table for token-level performance tracking
        self.conn.execute("""
        CREATE TABLE IF NOT EXISTS whale_token_pnl (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            whale_address TEXT NOT NULL,
            token_symbol TEXT NOT NULL,
            token_address TEXT,
            cumulative_pnl REAL DEFAULT 0.0,
            trade_count INTEGER DEFAULT 0,
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(whale_address, token_symbol),
            FOREIGN KEY (whale_address) REFERENCES whales (address)
        )
        """)
        
        # Create indexes for better performance
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_trades_whale ON trades(whale_address)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_trades_timestamp ON trades(timestamp)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_trades_actor ON trades(actor)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_whale_token_pnl_whale ON whale_token_pnl(whale_address)")
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_whale_token_pnl_symbol ON whale_token_pnl(token_symbol)")
        
        self.conn.commit()
    
    def get_table_info(self, table_name: str = "whales") -> List[Tuple]:
        """Get table schema information for debugging"""
        with self.lock:
            try:
                cursor = self.conn.execute(f"PRAGMA table_info({table_name})")
                return cursor.fetchall()
            except sqlite3.Error as e:
                logger.error(f"Database error getting table info for {table_name}: {e}")
                return []
    
    def get_whale(self, addr: str) -> Optional[Tuple]:
        """Get whale data from database"""
        with self.lock:
            try:
                cursor = self.conn.execute(
                    "SELECT * FROM whales WHERE address=?", 
                    (addr.lower(),)
                )
                return cursor.fetchone()
            except sqlite3.Error as e:
                logger.error(f"Database error getting whale {addr}: {e}")
                return None
    
    def save_whale(self, addr: str, roi_pct: float, usd: float, trades: int, 
                   cumulative_pnl: float = 0.0, risk_multiplier: float = 1.0, 
                   allocation_size: float = 0.0, score: float = 0.0, win_rate: float = 0.0) -> bool:
        """Save whale data to database"""
        import time
        logger.info(f"save_whale: Acquiring database lock for {addr[:10]}...")
        lock_start_time = time.time()
        
        with self.lock:
            lock_acquired_time = time.time()
            logger.info(f"save_whale: Database lock acquired in {lock_acquired_time - lock_start_time:.1f}s for {addr[:10]}")
            try:
                addr_lower = addr.lower()
                current_time = int(time.time())
                
                # Check if whale already exists to preserve bootstrap_time
                logger.info(f"save_whale: Checking if whale exists for {addr[:10]}...")
                check_start_time = time.time()
                # Use direct query instead of get_whale to avoid deadlock (we already have the lock)
                cursor = self.conn.execute(
                    "SELECT * FROM whales WHERE address=?", 
                    (addr_lower,)
                )
                existing_whale = cursor.fetchone()
                check_elapsed = time.time() - check_start_time
                logger.info(f"save_whale: Whale existence check completed in {check_elapsed:.1f}s for {addr[:10]}")
                
                if existing_whale:
                    # Update existing whale, preserve bootstrap_time
                    bootstrap_time = existing_whale[9]  # bootstrap_time is at index 9
                    logger.info(f"save_whale: Updating existing whale for {addr[:10]}...")
                    update_start_time = time.time()
                    self.conn.execute("""
                        UPDATE whales 
                        SET moralis_roi_pct=?, roi_usd=?, trades=?, cumulative_pnl=?, 
                            risk_multiplier=?, allocation_size=?, score=?, win_rate=?, last_refresh=?
                        WHERE address=?
                    """, (float(roi_pct), float(usd), int(trades), float(cumulative_pnl), 
                          float(risk_multiplier), float(allocation_size), float(score), 
                          float(win_rate), current_time, addr_lower))
                    update_elapsed = time.time() - update_start_time
                    logger.info(f"save_whale: UPDATE completed in {update_elapsed:.1f}s for {addr[:10]}")
                else:
                    # Insert new whale with current time as bootstrap_time
                    logger.info(f"save_whale: Inserting new whale for {addr[:10]}...")
                    insert_start_time = time.time()
                    self.conn.execute("""
                        INSERT INTO whales 
                        (address, moralis_roi_pct, roi_usd, trades, cumulative_pnl, 
                         risk_multiplier, allocation_size, score, win_rate, bootstrap_time, last_refresh)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, (addr_lower, float(roi_pct), float(usd), int(trades), 
                          float(cumulative_pnl), float(risk_multiplier), float(allocation_size),
                          float(score), float(win_rate), current_time, current_time))
                    insert_elapsed = time.time() - insert_start_time
                    logger.info(f"save_whale: INSERT completed in {insert_elapsed:.1f}s for {addr[:10]}")
                
                logger.info(f"save_whale: Committing transaction for {addr[:10]}...")
                commit_start_time = time.time()
                self.conn.commit()
                commit_elapsed = time.time() - commit_start_time
                logger.info(f"save_whale: COMMIT completed in {commit_elapsed:.1f}s for {addr[:10]}")
                save_completed_time = time.time()
                logger.info(f"save_whale: Database save completed in {save_completed_time - lock_acquired_time:.1f}s for {addr[:10]}")
                return True
            except sqlite3.Error as e:
                logger.error(f"Database error saving whale {addr}: {e}")
                return False
    
    def get_all_whales(self) -> List[Tuple]:
        """Get all whales from database"""
        with self.lock:
            try:
                cursor = self.conn.execute("SELECT * FROM whales ORDER BY last_refresh DESC")
                return cursor.fetchall()
            except sqlite3.Error as e:
                logger.error(f"Database error getting all whales: {e}")
                return []
    
    def get_all_whales_sorted_by_score(self) -> List[Tuple]:
        """Get all non-discarded whales from database sorted by Score v2.0 (descending)"""
        with self.lock:
            try:
                cursor = self.conn.execute("SELECT * FROM whales WHERE discarded_timestamp IS NULL ORDER BY score DESC")
                return cursor.fetchall()
            except sqlite3.Error as e:
                logger.error(f"Database error getting whales sorted by score: {e}")
                return []
    
    def mark_whale_discarded(self, addr: str, reason: str = None) -> bool:
        """Mark a whale as discarded with timestamp and reason"""
        addr_lower = addr.lower()
        current_time = int(time.time())
        
        with self.lock:
            try:
                self.conn.execute("""
                    UPDATE whales 
                    SET discarded_timestamp = ?, last_refresh = ?
                    WHERE address = ?
                """, (current_time, current_time, addr_lower))
                self.conn.commit()
                
                logger.info(f"Marked whale {addr_lower[:10]}... as discarded. Reason: {reason or 'Insufficient trades/tokens'}")
                return True
            except sqlite3.Error as e:
                logger.error(f"Database error marking whale as discarded {addr}: {e}")
                return False
    
    def get_discarded_whales(self) -> List[Tuple]:
        """Get all discarded whales from database"""
        with self.lock:
            try:
                cursor = self.conn.execute("SELECT * FROM whales WHERE discarded_timestamp IS NOT NULL ORDER BY discarded_timestamp DESC")
                return cursor.fetchall()
            except sqlite3.Error as e:
                logger.error(f"Database error getting discarded whales: {e}")
                return []
    
    def rescan_whale(self, addr: str) -> bool:
        """Remove discarded status from a whale to allow rescanning"""
        addr_lower = addr.lower()
        
        with self.lock:
            try:
                self.conn.execute("""
                    UPDATE whales 
                    SET discarded_timestamp = NULL, last_refresh = ?
                    WHERE address = ?
                """, (int(time.time()), addr_lower))
                self.conn.commit()
                
                logger.info(f"Removed discarded status from whale {addr_lower[:10]}... - ready for rescanning")
                return True
            except sqlite3.Error as e:
                logger.error(f"Database error rescanning whale {addr}: {e}")
                return False

    def update_whale_performance(self, addr: str, cumulative_pnl: float = None, 
                                risk_multiplier: float = None, allocation_size: float = None,
                                score: float = None, win_rate: float = None) -> bool:
        """Update whale performance metrics in database"""
        with self.lock:
            try:
                # Build dynamic query based on provided parameters
                update_fields = []
                values = []
                
                if cumulative_pnl is not None:
                    update_fields.append("cumulative_pnl = ?")
                    values.append(float(cumulative_pnl))
                
                if risk_multiplier is not None:
                    update_fields.append("risk_multiplier = ?")
                    values.append(float(risk_multiplier))
                
                if allocation_size is not None:
                    update_fields.append("allocation_size = ?")
                    values.append(float(allocation_size))
                
                if score is not None:
                    update_fields.append("score = ?")
                    values.append(float(score))
                
                if win_rate is not None:
                    update_fields.append("win_rate = ?")
                    values.append(float(win_rate))
                
                if not update_fields:
                    return True  # Nothing to update
                
                # Add address and timestamp
                values.append(int(time.time()))
                values.append(addr.lower())
                
                query = f"""
                    UPDATE whales 
                    SET {', '.join(update_fields)}, last_refresh = ?
                    WHERE address = ?
                """
                
                self.conn.execute(query, values)
                self.conn.commit()
                return True
            except sqlite3.Error as e:
                logger.error(f"Database error updating whale performance {addr}: {e}")
                return False
    
    def update_whale_token_pnl(self, whale_address: str, token_symbol: str, 
                              pnl_change: float, token_address: str = None, trade_count: int = 1) -> bool:
        """Update token-level PnL for a whale"""
        with self.lock:
            try:
                self.conn.execute("""
                    INSERT OR REPLACE INTO whale_token_pnl 
                    (whale_address, token_symbol, token_address, cumulative_pnl, trade_count, last_updated)
                    VALUES (?, ?, ?, 
                        COALESCE((SELECT cumulative_pnl FROM whale_token_pnl 
                                WHERE whale_address=? AND token_symbol=?), 0) + ?,
                        ?,
                        ?)
                """, (whale_address.lower(), token_symbol, token_address, 
                      whale_address.lower(), token_symbol, float(pnl_change),
                      trade_count, int(time.time())))
                self.conn.commit()
                return True
            except sqlite3.Error as e:
                logger.error(f"Database error updating whale token PnL {whale_address}-{token_symbol}: {e}")
                return False
    
    def get_whale_token_breakdown(self, whale_address: str) -> List[Tuple]:
        """Get token-level PnL breakdown for a whale"""
        with self.lock:
            try:
                cursor = self.conn.execute("""
                    SELECT token_symbol, token_address, cumulative_pnl, trade_count, last_updated
                    FROM whale_token_pnl 
                    WHERE whale_address=? 
                    ORDER BY cumulative_pnl DESC
                """, (whale_address.lower(),))
                return cursor.fetchall()
            except sqlite3.Error as e:
                logger.error(f"Database error getting whale token breakdown {whale_address}: {e}")
                return []
    
    def save_trade(self, trade_data: dict) -> bool:
        """Save trade data to database"""
        with self.lock:
            try:
                self.conn.execute("""
                    INSERT INTO trades 
                    (actor, whale_address, router, path, side, amount_in, amount_out,
                     token_in, token_out, price_impact, gas_cost, pnl, cum_pnl, 
                     risk_mult, mode, tx_hash)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    trade_data.get('actor', ''),
                    trade_data.get('whale', ''),
                    trade_data.get('router', ''),
                    trade_data.get('path', ''),
                    trade_data.get('side', ''),
                    trade_data.get('amount_in', 0),
                    trade_data.get('amount_out', 0),
                    trade_data.get('token_in', ''),
                    trade_data.get('token_out', ''),
                    trade_data.get('price_impact', 0),
                    trade_data.get('gas_cost', 0),
                    trade_data.get('pnl', 0),
                    trade_data.get('cum_pnl', 0),
                    trade_data.get('risk_mult', 1),
                    trade_data.get('mode', ''),
                    trade_data.get('tx_hash', '')
                ))
                self.conn.commit()
                return True
            except sqlite3.Error as e:
                logger.error(f"Database error saving trade: {e}")
                return False
    
    def get_recent_trades(self, limit: int = 100) -> List[Tuple]:
        """Get recent trades from database"""
        with self.lock:
            try:
                cursor = self.conn.execute(
                    "SELECT * FROM trades ORDER BY timestamp DESC LIMIT ?", 
                    (limit,)
                )
                return cursor.fetchall()
            except sqlite3.Error as e:
                logger.error(f"Database error getting recent trades: {e}")
                return []
    
    def get_whale_trades(self, whale_address: str, limit: int = 50) -> List[Tuple]:
        """Get trades for a specific whale"""
        with self.lock:
            try:
                cursor = self.conn.execute(
                    "SELECT * FROM trades WHERE whale_address = ? ORDER BY timestamp DESC LIMIT ?",
                    (whale_address.lower(), limit)
                )
                return cursor.fetchall()
            except sqlite3.Error as e:
                logger.error(f"Database error getting whale trades: {e}")
                return []
    
    def get_stats(self) -> dict:
        """Get database statistics"""
        with self.lock:
            try:
                # Get whale count
                whale_count = self.conn.execute("SELECT COUNT(*) FROM whales").fetchone()[0]
                
                # Get trade count
                trade_count = self.conn.execute("SELECT COUNT(*) FROM trades").fetchone()[0]
                
                # Get total PnL
                total_pnl = self.conn.execute("SELECT SUM(pnl) FROM trades WHERE actor = 'allocator'").fetchone()[0] or 0
                
                return {
                    "whale_count": whale_count,
                    "trade_count": trade_count,
                    "total_pnl": total_pnl
                }
            except sqlite3.Error as e:
                logger.error(f"Database error getting stats: {e}")
                return {"whale_count": 0, "trade_count": 0, "total_pnl": 0}
    
    def close(self):
        """Close database connection"""
        with self.lock:
            if self.conn:
                self.conn.close()
                self.conn = None
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
"""
Configuration management for Allocator AI
"""

from .settings import Config, DatabaseConfig, TradingConfig, Web3Config
from .validation import validate_config

__all__ = [
    "Config",
    "DatabaseConfig", 
    "TradingConfig",
    "Web3Config",
    "validate_config"
]
"""
Configuration settings and data classes for Allocator AI
"""

import os
from dataclasses import dataclass
from decimal import Decimal
from typing import List, Optional
from pathlib import Path


@dataclass
class DatabaseConfig:
    """Database configuration settings"""
    file_path: str = "whales.db"
    journal_mode: str = "WAL"
    timeout: int = 30
    cache_size: int = 10000
    temp_store: str = "MEMORY"


@dataclass
class TradingConfig:
    """Trading configuration settings"""
    capital: Decimal = Decimal("2")
    base_risk: Decimal = Decimal("0.05")
    max_slippage: Decimal = Decimal("0.01")
    min_profit: Decimal = Decimal("0.005")
    gas_boost: Decimal = Decimal("1.1")
    min_moralis_roi_pct: Decimal = Decimal("5")
    min_moralis_profit_usd: Decimal = Decimal("500")
    min_moralis_trades: int = 5


@dataclass
class Web3Config:
    """Web3 and blockchain configuration"""
    rpc_url: str = "ws://152.53.148.57:8546"
    chain_id: Optional[int] = None
    max_retries: int = 3
    timeout: int = 30


@dataclass
class AdaptiveDiscoveryConfig:
    """Adaptive discovery configuration"""
    enabled: bool = False
    percentile_mode: dict = None
    market_adaptive: dict = None
    moralis_feedback: dict = None


@dataclass
class DiscoveryConfig:
    """Whale discovery configuration"""
    modes: List[str] = None
    refresh_interval: int = 600  # 10 minutes
    max_whales: int = 100
    mode_settings: dict = None
    adaptive_discovery: AdaptiveDiscoveryConfig = None
    
    def __post_init__(self):
        if self.modes is None:
            self.modes = ["active_whale", "quick_profit_whale", "fast_mover_whale"]
        if self.mode_settings is None:
            self.mode_settings = {}
        if self.adaptive_discovery is None:
            self.adaptive_discovery = AdaptiveDiscoveryConfig()


@dataclass
class LoggingConfig:
    """Logging configuration"""
    level: str = "INFO"
    log_dir: str = "logs"
    log_file: str = "allocator.log"
    max_file_size: int = 10 * 1024 * 1024  # 10MB
    backup_count: int = 5


@dataclass
class Config:
    """Main configuration class"""
    database: DatabaseConfig
    trading: TradingConfig
    web3: Web3Config
    discovery: DiscoveryConfig
    logging: LoggingConfig
    moralis_api_key: str
    wallet_password: str
    tracked_whales: List[str] = None
    
    def __post_init__(self):
        if self.tracked_whales is None:
            self.tracked_whales = []
    
    @classmethod
    def from_env_and_file(cls, config_file: str = "config.json"):
        """Load configuration from environment variables and config file"""
        import json
        
        # Load from config file
        config_data = {}
        if os.path.exists(config_file):
            with open(config_file, 'r') as f:
                config_data = json.load(f)
        
        # Override with environment variables
        return cls(
            database=DatabaseConfig(
                file_path=os.environ.get("DB_FILE", config_data.get("db_file", "whales.db"))
            ),
            trading=TradingConfig(
                capital=Decimal(str(os.environ.get("CAPITAL", config_data.get("capital", "2")))),
                base_risk=Decimal(str(os.environ.get("BASE_RISK", config_data.get("base_risk", "0.05")))),
                max_slippage=Decimal(str(os.environ.get("MAX_SLIPPAGE", config_data.get("max_slippage", "0.01")))),
                min_profit=Decimal(str(os.environ.get("MIN_PROFIT", config_data.get("min_profit", "0.005")))),
                gas_boost=Decimal(str(os.environ.get("GAS_BOOST", config_data.get("gas_boost", "1.1")))),
                min_moralis_roi_pct=Decimal(str(config_data.get("min_moralis_roi_pct", "5"))),
                min_moralis_profit_usd=Decimal(str(config_data.get("min_moralis_profit_usd", "500"))),
                min_moralis_trades=config_data.get("min_moralis_trades", 5)
            ),
            web3=Web3Config(
                rpc_url=os.environ.get("WEB3_RPC", config_data.get("web3_rpc", "ws://152.53.148.57:8546"))
            ),
            discovery=DiscoveryConfig(
                modes=config_data.get("discovery", {}).get("modes", ["active_whale", "quick_profit_whale", "fast_mover_whale"]),
                refresh_interval=config_data.get("discovery", {}).get("refresh_interval", 600),
                max_whales=config_data.get("discovery", {}).get("max_whales", 100),
                mode_settings=config_data.get("discovery", {}).get("mode_settings", {}),
                adaptive_discovery=AdaptiveDiscoveryConfig(
                    enabled=config_data.get("discovery", {}).get("adaptive_discovery", {}).get("enabled", False),
                    percentile_mode=config_data.get("discovery", {}).get("adaptive_discovery", {}).get("percentile_mode", {}),
                    market_adaptive=config_data.get("discovery", {}).get("adaptive_discovery", {}).get("market_adaptive", {}),
                    moralis_feedback=config_data.get("discovery", {}).get("adaptive_discovery", {}).get("moralis_feedback", {})
                )
            ),
            logging=LoggingConfig(
                level=os.environ.get("LOG_LEVEL", "INFO"),
                log_dir=os.environ.get("LOG_DIR", "logs")
            ),
            moralis_api_key=os.environ.get("MORALIS_API_KEY"),
            wallet_password=os.environ.get("WALLET_PASS"),
            tracked_whales=config_data.get("tracked_whales", [])
        )
    
    def validate(self) -> bool:
        """Validate configuration"""
        if not self.moralis_api_key:
            raise ValueError("MORALIS_API_KEY is required")
        if not self.wallet_password:
            raise ValueError("WALLET_PASS is required")
        if not self.web3.rpc_url:
            raise ValueError("Web3 RPC URL is required")
        
        return True
"""
Configuration validation utilities
"""

from decimal import Decimal, InvalidOperation
from typing import Any, Dict, List
import logging

logger = logging.getLogger(__name__)


def validate_config(config_dict: Dict[str, Any]) -> bool:
    """Validate configuration dictionary"""
    try:
        # Validate required fields
        required_fields = ["web3_rpc", "capital", "base_risk", "max_slippage", "min_profit", "gas_boost"]
        for field in required_fields:
            if field not in config_dict:
                logger.error(f"Missing required config field: {field}")
                return False
        
        # Validate numeric fields
        numeric_fields = {
            "capital": (0, 1000000),  # 0 to 1M ETH
            "base_risk": (0, 1),      # 0 to 100%
            "max_slippage": (0, 0.1), # 0 to 10%
            "min_profit": (0, 0.1),   # 0 to 10%
            "gas_boost": (1, 5)       # 1x to 5x
        }
        
        for field, (min_val, max_val) in numeric_fields.items():
            try:
                value = Decimal(str(config_dict[field]))
                if not (min_val <= value <= max_val):
                    logger.error(f"Invalid {field}: {value} (must be between {min_val} and {max_val})")
                    return False
            except (ValueError, TypeError, InvalidOperation):
                logger.error(f"Invalid {field} value: {config_dict[field]}")
                return False
        
        # Validate tracked_whales if present
        if "tracked_whales" in config_dict:
            if not isinstance(config_dict["tracked_whales"], list):
                logger.error("tracked_whales must be a list")
                return False
            
            for whale in config_dict["tracked_whales"]:
                if not isinstance(whale, str) or len(whale) != 42 or not whale.startswith("0x"):
                    logger.error(f"Invalid whale address format: {whale}")
                    return False
        
        return True
        
    except Exception as e:
        logger.error(f"Configuration validation error: {e}")
        return False


def validate_environment() -> bool:
    """Validate environment variables"""
    import os
    
    required_env_vars = ["MORALIS_API_KEY", "WALLET_PASS"]
    missing_vars = []
    
    for var in required_env_vars:
        if not os.environ.get(var):
            missing_vars.append(var)
    
    if missing_vars:
        logger.error(f"Missing required environment variables: {missing_vars}")
        return False
    
    return True
"""
Allocation engine for determining trade sizes and strategies
"""

import logging
from decimal import Decimal
from typing import Dict, Any, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class AllocationDecision:
    """Allocation decision result"""
    should_trade: bool
    allocation_size: Decimal
    reason: str
    confidence: Decimal  # 0-1 scale


class AllocationEngine:
    """Advanced allocation engine for determining trade sizes"""
    
    def __init__(self, base_capital: Decimal = Decimal("2000"),
                 base_risk: Decimal = Decimal("0.05"),
                 max_allocation: Decimal = Decimal("5000")):
        self.base_capital = base_capital
        self.base_risk = base_risk
        self.max_allocation = max_allocation
        
        # Router preferences and biases
        self.router_preferences = {
            "uniswap_v2": Decimal("0.8"),    # 20% discount for V2
            "uniswap_v3": Decimal("1.2"),    # 20% premium for V3
            "balancer": Decimal("1.0"),      # Neutral
            "sushiswap": Decimal("0.9")      # 10% discount
        }
        
        # Function preferences
        self.function_preferences = {
            "exactInputSingle": Decimal("1.5"),      # Prefer V3 single swaps
            "exactInput": Decimal("1.2"),            # V3 multi-hop
            "swapExactTokensForTokens": Decimal("1.0"),  # V2 token swaps
            "swapExactETHForTokens": Decimal("0.5"),     # Discourage ETH->token
            "swapTokensForExactTokens": Decimal("0.8")   # Slightly prefer exact input
        }
        
        # Token preferences (can be updated based on performance)
        self.token_preferences = {
            "WETH": Decimal("1.0"),
            "USDC": Decimal("1.1"),
            "USDT": Decimal("1.0"),
            "DAI": Decimal("1.0")
        }
    
    def decide_allocation(self, trade_data: Dict[str, Any], 
                         whale_stats: Optional[Dict] = None,
                         risk_multiplier: Decimal = Decimal("1.0")) -> AllocationDecision:
        """Make allocation decision for a trade"""
        
        # Extract trade information
        token_in = trade_data.get("token_in", {})
        token_out = trade_data.get("token_out", {})
        amount_in = Decimal(str(trade_data.get("amount_in", 0)))
        fn_name = trade_data.get("fn_name", "")
        router = trade_data.get("to", "").lower()
        
        # Basic validation
        if amount_in <= 0:
            return AllocationDecision(
                should_trade=False,
                allocation_size=Decimal("0"),
                reason="Invalid trade amount",
                confidence=Decimal("0")
            )
        
        # Skip dust trades
        if amount_in < 100:  # Less than 100 units
            return AllocationDecision(
                should_trade=False,
                allocation_size=Decimal("0"),
                reason="Trade amount too small (dust)",
                confidence=Decimal("0")
            )
        
        # Calculate base allocation
        base_allocation = self._calculate_base_allocation(amount_in, risk_multiplier)
        
        # Apply router bias
        router_bias = self._get_router_bias(router)
        base_allocation *= router_bias
        
        # Apply function bias
        function_bias = self._get_function_bias(fn_name)
        base_allocation *= function_bias
        
        # Apply token preferences
        token_bias = self._get_token_bias(token_in, token_out)
        base_allocation *= token_bias
        
        # Apply whale performance bias
        whale_bias = self._get_whale_bias(whale_stats)
        base_allocation *= whale_bias
        
        # Apply maximum allocation limit
        final_allocation = min(base_allocation, self.max_allocation)
        
        # Determine confidence based on various factors
        confidence = self._calculate_confidence(trade_data, whale_stats)
        
        # Final decision
        should_trade = final_allocation > 0 and confidence > Decimal("0.3")
        
        reason = self._generate_reason(should_trade, final_allocation, confidence, 
                                     router_bias, function_bias, token_bias, whale_bias)
        
        return AllocationDecision(
            should_trade=should_trade,
            allocation_size=final_allocation,
            reason=reason,
            confidence=confidence
        )
    
    def _calculate_base_allocation(self, whale_amount: Decimal, risk_multiplier: Decimal) -> Decimal:
        """Calculate base allocation size"""
        # Use 10% of whale's trade size as baseline
        base_scale = whale_amount * Decimal("0.1")
        
        # Apply risk multiplier
        risk_adjusted = base_scale * risk_multiplier
        
        # Apply base risk percentage
        return risk_adjusted * self.base_risk
    
    def _get_router_bias(self, router: str) -> Decimal:
        """Get bias multiplier for router type"""
        if "uniswap" in router:
            if "v3" in router or "0xe592427a" in router:
                return self.router_preferences["uniswap_v3"]
            else:
                return self.router_preferences["uniswap_v2"]
        elif "balancer" in router:
            return self.router_preferences["balancer"]
        elif "sushi" in router:
            return self.router_preferences["sushiswap"]
        else:
            return Decimal("1.0")  # Neutral for unknown routers
    
    def _get_function_bias(self, fn_name: str) -> Decimal:
        """Get bias multiplier for function type"""
        return self.function_preferences.get(fn_name, Decimal("1.0"))
    
    def _get_token_bias(self, token_in: Dict, token_out: Dict) -> Decimal:
        """Get bias multiplier for token pair"""
        symbol_in = token_in.get("symbol", "").upper()
        symbol_out = token_out.get("symbol", "").upper()
        
        bias_in = self.token_preferences.get(symbol_in, Decimal("1.0"))
        bias_out = self.token_preferences.get(symbol_out, Decimal("1.0"))
        
        # Average the biases
        return (bias_in + bias_out) / Decimal("2")
    
    def _get_whale_bias(self, whale_stats: Optional[Dict]) -> Decimal:
        """Get bias multiplier based on whale performance"""
        if not whale_stats:
            return Decimal("1.0")
        
        # Extract performance metrics
        score = Decimal(str(whale_stats.get("score", 0)))
        win_rate = Decimal(str(whale_stats.get("win_rate", 0.5)))
        trades = whale_stats.get("trades", 0)
        
        # Calculate bias based on performance
        if score > 100:  # High performing whale
            return Decimal("1.5")
        elif score > 50:
            return Decimal("1.2")
        elif score > 0:
            return Decimal("1.0")
        elif score > -50:
            return Decimal("0.8")
        else:
            return Decimal("0.5")  # Poor performing whale
    
    def _calculate_confidence(self, trade_data: Dict[str, Any], 
                            whale_stats: Optional[Dict]) -> Decimal:
        """Calculate confidence score for the trade"""
        confidence = Decimal("0.5")  # Base confidence
        
        # Increase confidence for larger trades (whales are more confident)
        amount_in = Decimal(str(trade_data.get("amount_in", 0)))
        if amount_in > 10000:
            confidence += Decimal("0.2")
        elif amount_in > 1000:
            confidence += Decimal("0.1")
        
        # Increase confidence for V3 trades (more sophisticated)
        fn_name = trade_data.get("fn_name", "")
        if "exactInput" in fn_name:
            confidence += Decimal("0.1")
        
        # Increase confidence based on whale performance
        if whale_stats:
            score = Decimal(str(whale_stats.get("score", 0)))
            if score > 100:
                confidence += Decimal("0.2")
            elif score > 50:
                confidence += Decimal("0.1")
            elif score < -50:
                confidence -= Decimal("0.2")
        
        # Cap confidence between 0 and 1
        return max(Decimal("0"), min(Decimal("1"), confidence))
    
    def _generate_reason(self, should_trade: bool, allocation: Decimal, 
                        confidence: Decimal, router_bias: Decimal,
                        function_bias: Decimal, token_bias: Decimal,
                        whale_bias: Decimal) -> str:
        """Generate human-readable reason for the decision"""
        if not should_trade:
            return f"Trade rejected: confidence {confidence:.2f} too low"
        
        reasons = []
        if router_bias != Decimal("1.0"):
            reasons.append(f"router_bias={router_bias:.2f}")
        if function_bias != Decimal("1.0"):
            reasons.append(f"function_bias={function_bias:.2f}")
        if token_bias != Decimal("1.0"):
            reasons.append(f"token_bias={token_bias:.2f}")
        if whale_bias != Decimal("1.0"):
            reasons.append(f"whale_bias={whale_bias:.2f}")
        
        reason = f"Allocation: {allocation:.2f} ETH, confidence: {confidence:.2f}"
        if reasons:
            reason += f" (factors: {', '.join(reasons)})"
        
        return reason
    
    def update_token_preference(self, token_symbol: str, preference: Decimal) -> None:
        """Update token preference"""
        self.token_preferences[token_symbol.upper()] = preference
        logger.info(f"Updated token preference for {token_symbol}: {preference}")
    
    def update_router_preference(self, router: str, preference: Decimal) -> None:
        """Update router preference"""
        self.router_preferences[router] = preference
        logger.info(f"Updated router preference for {router}: {preference}")
    
    def get_allocation_stats(self) -> Dict[str, Any]:
        """Get allocation engine statistics"""
        return {
            "base_capital": self.base_capital,
            "base_risk": self.base_risk,
            "max_allocation": self.max_allocation,
            "router_preferences": {k: float(v) for k, v in self.router_preferences.items()},
            "function_preferences": {k: float(v) for k, v in self.function_preferences.items()},
            "token_preferences": {k: float(v) for k, v in self.token_preferences.items()}
        }
"""
Trade execution engine for Allocator AI
"""

import time
import threading
import logging
from decimal import Decimal
from typing import Dict, Any, Optional, Tuple
from web3 import Web3
from web3.exceptions import TransactionNotFound
from eth_account import Account

from ..utils.web3_utils import TokenManager
from ..utils.validation import validate_trade_data, ValidationError

logger = logging.getLogger(__name__)


class TradeExecutor:
    """Advanced trade execution engine with error handling and optimization"""
    
    def __init__(self, w3: Web3, wallet_address: str, private_key: bytes, 
                 token_manager: TokenManager, gas_boost: Decimal = Decimal("1.1")):
        self.w3 = w3
        self.wallet_address = wallet_address
        self.private_key = private_key
        self.token_manager = token_manager
        self.gas_boost = gas_boost
        
        # Contract addresses
        self.uniswap_v2 = "0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D"
        self.uniswap_v3 = "0xE592427A0AEce92De3Edee1F18E0157C05861564"
        
        # Load contract ABIs
        self.v2_abi = self._load_abi("uniswap_v2_router")
        self.v3_abi = self._load_abi("uniswap_v3_router")
        self.erc20_abi = self._load_erc20_abi()
        
        # Create contract instances
        self.uni_v2_contract = w3.eth.contract(address=self.uniswap_v2, abi=self.v2_abi)
        self.uni_v3_contract = w3.eth.contract(address=self.uniswap_v3, abi=self.v3_abi)
        
        # Transaction management
        self.nonce_lock = threading.Lock()
        self.pending_txs = {}  # Track pending transactions
    
    def _load_abi(self, abi_name: str) -> list:
        """Load ABI from file"""
        import json
        import os
        
        abi_path = os.path.join("abis", f"{abi_name}.json")
        if os.path.exists(abi_path):
            with open(abi_path, 'r') as f:
                return json.load(f)
        else:
            logger.warning(f"ABI file not found: {abi_path}")
            return []
    
    def _load_erc20_abi(self) -> list:
        """Load ERC20 ABI"""
        return [
            {
                "constant": False,
                "inputs": [
                    {"name": "_spender", "type": "address"},
                    {"name": "_value", "type": "uint256"}
                ],
                "name": "approve",
                "outputs": [{"name": "", "type": "bool"}],
                "type": "function"
            },
            {
                "constant": True,
                "inputs": [
                    {"name": "_owner", "type": "address"},
                    {"name": "_spender", "type": "address"}
                ],
                "name": "allowance",
                "outputs": [{"name": "", "type": "uint256"}],
                "type": "function"
            }
        ]
    
    def execute_trade(self, trade_data: Dict[str, Any], 
                     allocation_size: Decimal) -> Optional[Tuple[str, Dict]]:
        """Execute a trade with the given allocation size"""
        
        # Validate trade data
        if not validate_trade_data(trade_data):
            logger.error("Invalid trade data provided")
            return None
        
        try:
            # Determine execution method based on router
            router = trade_data.get("to", "").lower()
            
            if "uniswap" in router:
                if "v3" in router or "0xe592427a" in router:
                    return self._execute_uniswap_v3(trade_data, allocation_size)
                else:
                    return self._execute_uniswap_v2(trade_data, allocation_size)
            else:
                logger.warning(f"Unsupported router: {router}")
                return None
                
        except Exception as e:
            logger.error(f"Trade execution failed: {e}", exc_info=True)
            return None
    
    def _execute_uniswap_v2(self, trade_data: Dict[str, Any], 
                           allocation_size: Decimal) -> Optional[Tuple[str, Dict]]:
        """Execute Uniswap V2 trade"""
        token_in = trade_data["token_in"]
        token_out = trade_data["token_out"]
        
        # Convert allocation to raw amount
        raw_amount = self.token_manager.parse_amount(
            allocation_size, 
            token_in["decimals"]
        )
        
        # Build transaction
        path = [token_in["address"], token_out["address"]]
        deadline = int(time.time()) + 600  # 10 minutes
        
        # Check if approval is needed
        if token_in["symbol"] != "ETH":
            self._ensure_approval(token_in["address"], self.uniswap_v2)
        
        # Build swap transaction
        tx = self.uni_v2_contract.functions.swapExactTokensForTokens(
            raw_amount,
            0,  # Minimum amount out (slippage handled separately)
            path,
            self.wallet_address,
            deadline
        ).build_transaction({
            'from': self.wallet_address,
            'value': 0
        })
        
        return self._send_transaction(tx)
    
    def _execute_uniswap_v3(self, trade_data: Dict[str, Any], 
                           allocation_size: Decimal) -> Optional[Tuple[str, Dict]]:
        """Execute Uniswap V3 trade"""
        token_in = trade_data["token_in"]
        token_out = trade_data["token_out"]
        
        # Convert allocation to raw amount
        raw_amount = self.token_manager.parse_amount(
            allocation_size, 
            token_in["decimals"]
        )
        
        # V3 parameters
        fee = 3000  # 0.3% fee tier
        deadline = int(time.time()) + 600
        
        # Check if approval is needed
        if token_in["symbol"] != "ETH":
            self._ensure_approval(token_in["address"], self.uniswap_v3)
        
        # Build swap parameters
        params = {
            'tokenIn': token_in["address"],
            'tokenOut': token_out["address"],
            'fee': fee,
            'recipient': self.wallet_address,
            'deadline': deadline,
            'amountIn': raw_amount,
            'amountOutMinimum': 0,  # Slippage handled separately
            'sqrtPriceLimitX96': 0
        }
        
        # Build transaction
        tx = self.uni_v3_contract.functions.exactInputSingle(params).build_transaction({
            'from': self.wallet_address,
            'value': raw_amount if token_in["symbol"] == "ETH" else 0
        })
        
        return self._send_transaction(tx)
    
    def _ensure_approval(self, token_address: str, spender: str) -> bool:
        """Ensure token approval for spender"""
        try:
            token_contract = self.w3.eth.contract(address=token_address, abi=self.erc20_abi)
            
            # Check current allowance
            allowance = token_contract.functions.allowance(
                self.wallet_address, 
                spender
            ).call()
            
            # If allowance is less than max, approve max
            if allowance < 2**255:
                approve_tx = token_contract.functions.approve(
                    spender, 
                    2**256 - 1
                ).build_transaction({
                    'from': self.wallet_address
                })
                
                tx_hash, receipt = self._send_transaction(approve_tx)
                if tx_hash:
                    logger.info(f"Approved {token_address} for {spender}")
                    return True
                else:
                    logger.error(f"Failed to approve {token_address}")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"Approval failed for {token_address}: {e}")
            return False
    
    def _send_transaction(self, tx_dict: Dict[str, Any]) -> Optional[Tuple[str, Dict]]:
        """Send transaction with proper gas estimation and error handling"""
        import threading
        
        with self.nonce_lock:
            try:
                # Set nonce
                tx_dict['nonce'] = self.w3.eth.get_transaction_count(self.wallet_address)
                
                # Set gas price with boost
                gas_price = int(self.w3.eth.gas_price * float(self.gas_boost))
                tx_dict['gasPrice'] = gas_price
                
                # Estimate gas
                if 'gas' not in tx_dict:
                    try:
                        gas_estimate = self.w3.eth.estimate_gas(tx_dict)
                        tx_dict['gas'] = int(gas_estimate * 1.2)  # 20% buffer
                    except Exception as e:
                        logger.warning(f"Gas estimation failed: {e}")
                        tx_dict['gas'] = 500000  # Fallback
                
                # Sign transaction
                signed_tx = self.w3.eth.account.sign_transaction(tx_dict, self.private_key)
                
                # Send transaction
                tx_hash = self.w3.eth.send_raw_transaction(signed_tx.rawTransaction)
                tx_hash_hex = tx_hash.hex()
                
                logger.info(f"Transaction sent: {tx_hash_hex}")
                
                # Wait for receipt
                try:
                    receipt = self.w3.eth.wait_for_transaction_receipt(tx_hash, timeout=300)
                    
                    if receipt.status == 1:
                        logger.info(f"Transaction successful: {tx_hash_hex}")
                        return tx_hash_hex, receipt
                    else:
                        logger.error(f"Transaction failed: {tx_hash_hex}")
                        return None
                        
                except Exception as e:
                    logger.error(f"Transaction receipt error: {e}")
                    return tx_hash_hex, None
                    
            except Exception as e:
                logger.error(f"Transaction send failed: {e}")
                return None
    
    def simulate_trade(self, trade_data: Dict[str, Any], 
                      allocation_size: Decimal) -> Optional[Dict[str, Any]]:
        """Simulate a trade to estimate output and costs"""
        try:
            token_in = trade_data["token_in"]
            token_out = trade_data["token_out"]
            
            # Convert to raw amount
            raw_amount = self.token_manager.parse_amount(
                allocation_size, 
                token_in["decimals"]
            )
            
            router = trade_data.get("to", "").lower()
            
            if "uniswap" in router:
                if "v3" in router:
                    return self._simulate_uniswap_v3(token_in, token_out, raw_amount)
                else:
                    return self._simulate_uniswap_v2(token_in, token_out, raw_amount)
            
            return None
            
        except Exception as e:
            logger.error(f"Trade simulation failed: {e}")
            return None
    
    def _simulate_uniswap_v2(self, token_in: Dict, token_out: Dict, 
                            raw_amount: int) -> Dict[str, Any]:
        """Simulate Uniswap V2 trade"""
        try:
            path = [token_in["address"], token_out["address"]]
            
            # Get amounts out
            amounts = self.uni_v2_contract.functions.getAmountsOut(
                raw_amount, path
            ).call()
            
            expected_out = self.token_manager.format_amount(
                amounts[-1], 
                token_out["decimals"]
            )
            
            return {
                "expected_out": expected_out,
                "path": path,
                "router": "uniswap_v2"
            }
            
        except Exception as e:
            logger.error(f"V2 simulation failed: {e}")
            return None
    
    def _simulate_uniswap_v3(self, token_in: Dict, token_out: Dict, 
                            raw_amount: int) -> Dict[str, Any]:
        """Simulate Uniswap V3 trade"""
        try:
            # For V3, we'd need a quoter contract
            # This is a simplified simulation
            fee = 3000
            
            # Placeholder calculation (in real implementation, use quoter)
            expected_out = allocation_size * Decimal("0.98")  # Assume 2% slippage
            
            return {
                "expected_out": expected_out,
                "fee": fee,
                "router": "uniswap_v3"
            }
            
        except Exception as e:
            logger.error(f"V3 simulation failed: {e}")
            return None
    
    def get_transaction_status(self, tx_hash: str) -> Optional[Dict[str, Any]]:
        """Get status of a transaction"""
        try:
            tx = self.w3.eth.get_transaction(tx_hash)
            receipt = self.w3.eth.get_transaction_receipt(tx_hash)
            
            return {
                "hash": tx_hash,
                "status": receipt.status,
                "gas_used": receipt.gasUsed,
                "gas_price": tx.gasPrice,
                "block_number": receipt.blockNumber
            }
            
        except TransactionNotFound:
            return {"hash": tx_hash, "status": "pending"}
        except Exception as e:
            logger.error(f"Failed to get transaction status: {e}")
            return None
"""
Core business logic for Allocator AI
"""

from .whale_tracker import WhaleTracker
from .trade_executor import TradeExecutor
from .risk_manager import RiskManager
from .allocation_engine import AllocationEngine

__all__ = [
    "WhaleTracker",
    "TradeExecutor",
    "RiskManager", 
    "AllocationEngine"
]
"""
Risk management system for Allocator AI
"""

import logging
from decimal import Decimal
from typing import Dict, Optional
from collections import defaultdict

logger = logging.getLogger(__name__)


class RiskManager:
    """Advanced risk management system with dynamic position sizing"""
    
    def __init__(self, base_risk: Decimal = Decimal("0.05"), 
                 max_risk_multiplier: Decimal = Decimal("3.0"),
                 min_risk_multiplier: Decimal = Decimal("0.25"),
                 db_manager=None):
        self.base_risk = base_risk
        self.max_risk_multiplier = max_risk_multiplier
        self.min_risk_multiplier = min_risk_multiplier
        self.db_manager = db_manager
        
        # Track PnL and risk multipliers per whale
        self.whale_pnl = defaultdict(lambda: Decimal("0"))
        self.risk_multipliers = defaultdict(lambda: Decimal("1.0"))
        
        # Risk limits
        self.max_position_size = Decimal("10000")  # Max 10k ETH per position
        self.max_daily_loss = Decimal("1000")      # Max 1k ETH daily loss
        self.max_total_exposure = Decimal("50000") # Max 50k ETH total exposure
        
        # Daily tracking
        self.daily_pnl = Decimal("0")
        self.daily_reset_time = 0
        
    def update_whale_pnl(self, whale_address: str, pnl: Decimal) -> None:
        """Update PnL for a whale and adjust risk multiplier"""
        whale_address = whale_address.lower()
        self.whale_pnl[whale_address] += pnl
        
        # Update daily PnL
        self._update_daily_pnl(pnl)
        
        # Calculate new risk multiplier based on performance
        self._calculate_risk_multiplier(whale_address)
        
        # Update database with new risk metrics
        if self.db_manager:
            self.db_manager.update_whale_performance(
                whale_address,
                cumulative_pnl=float(self.whale_pnl[whale_address]),
                risk_multiplier=float(self.risk_multipliers[whale_address])
            )
        
        logger.debug(f"Updated PnL for {whale_address}: {self.whale_pnl[whale_address]}, risk_mult: {self.risk_multipliers[whale_address]}")
    
    def _update_daily_pnl(self, pnl: Decimal) -> None:
        """Update daily PnL tracking"""
        import time
        current_time = time.time()
        
        # Reset daily PnL at midnight
        if current_time - self.daily_reset_time > 24 * 3600:
            self.daily_pnl = Decimal("0")
            self.daily_reset_time = current_time
        
        self.daily_pnl += pnl
    
    def _calculate_risk_multiplier(self, whale_address: str) -> None:
        """Calculate dynamic risk multiplier based on whale performance"""
        whale_pnl = self.whale_pnl[whale_address]
        
        if whale_pnl > 0:
            # Profitable whale - increase risk (capped at max)
            # Risk increases by 0.1x for every 1000 ETH profit
            risk_boost = whale_pnl / Decimal("1000") * Decimal("0.1")
            new_multiplier = Decimal("1.0") + risk_boost
            self.risk_multipliers[whale_address] = min(new_multiplier, self.max_risk_multiplier)
        else:
            # Unprofitable whale - decrease risk (floored at min)
            # Risk decreases by 0.1x for every 1000 ETH loss
            risk_penalty = abs(whale_pnl) / Decimal("1000") * Decimal("0.1")
            new_multiplier = Decimal("1.0") - risk_penalty
            self.risk_multipliers[whale_address] = max(new_multiplier, self.min_risk_multiplier)
    
    def calculate_position_size(self, whale_address: str, base_capital: Decimal, 
                              whale_trade_amount: Decimal) -> Decimal:
        """Calculate position size for a whale trade"""
        whale_address = whale_address.lower()
        
        # Check daily loss limit
        if self.daily_pnl < -self.max_daily_loss:
            logger.warning(f"Daily loss limit reached: {self.daily_pnl}")
            return Decimal("0")
        
        # Get risk multiplier for this whale
        risk_mult = self.risk_multipliers[whale_address]
        
        # Calculate base position size
        base_position = base_capital * self.base_risk * risk_mult
        
        # Scale by whale trade size (but don't exceed whale's trade)
        # Use 10% of whale's trade size as baseline
        whale_scale = whale_trade_amount * Decimal("0.1")
        
        # Take the smaller of base position or whale scale
        position_size = min(base_position, whale_scale)
        
        # Apply maximum position size limit
        position_size = min(position_size, self.max_position_size)
        
        # Check total exposure limit
        current_exposure = sum(self.whale_pnl.values())
        if current_exposure + position_size > self.max_total_exposure:
            remaining_exposure = self.max_total_exposure - current_exposure
            position_size = max(Decimal("0"), remaining_exposure)
        
        return position_size
    
    def should_execute_trade(self, whale_address: str, trade_amount: Decimal) -> bool:
        """Determine if a trade should be executed based on risk criteria"""
        whale_address = whale_address.lower()
        
        # Check daily loss limit
        if self.daily_pnl < -self.max_daily_loss:
            logger.warning(f"Trade rejected: daily loss limit reached")
            return False
        
        # Check if whale is too risky
        if self.whale_pnl[whale_address] < -Decimal("5000"):  # -5k ETH loss
            logger.warning(f"Trade rejected: whale {whale_address} has too much loss")
            return False
        
        # Check position size limits
        base_capital = Decimal("2000")  # This should come from config
        position_size = self.calculate_position_size(whale_address, base_capital, trade_amount)
        
        if position_size <= 0:
            logger.warning(f"Trade rejected: position size too small or limits exceeded")
            return False
        
        return True
    
    def get_risk_metrics(self) -> Dict[str, Decimal]:
        """Get current risk metrics"""
        total_pnl = sum(self.whale_pnl.values())
        active_whales = len([pnl for pnl in self.whale_pnl.values() if pnl != 0])
        avg_risk_mult = sum(self.risk_multipliers.values()) / len(self.risk_multipliers) if self.risk_multipliers else Decimal("1")
        
        return {
            "total_pnl": total_pnl,
            "daily_pnl": self.daily_pnl,
            "active_whales": active_whales,
            "average_risk_multiplier": avg_risk_mult,
            "max_daily_loss": self.max_daily_loss,
            "max_total_exposure": self.max_total_exposure
        }
    
    def get_whale_risk_profile(self, whale_address: str) -> Dict[str, Decimal]:
        """Get risk profile for a specific whale"""
        whale_address = whale_address.lower()
        
        return {
            "pnl": self.whale_pnl[whale_address],
            "risk_multiplier": self.risk_multipliers[whale_address],
            "position_limit": self.max_position_size
        }
    
    def reset_whale_risk(self, whale_address: str) -> None:
        """Reset risk profile for a whale"""
        whale_address = whale_address.lower()
        self.whale_pnl[whale_address] = Decimal("0")
        self.risk_multipliers[whale_address] = Decimal("1.0")
        logger.info(f"Reset risk profile for whale {whale_address}")
    
    def emergency_stop(self) -> None:
        """Emergency stop - reset all risk profiles"""
        self.whale_pnl.clear()
        self.risk_multipliers.clear()
        self.daily_pnl = Decimal("0")
        logger.warning("Emergency stop: all risk profiles reset")
    
    def update_risk_limits(self, max_position: Optional[Decimal] = None,
                          max_daily_loss: Optional[Decimal] = None,
                          max_total_exposure: Optional[Decimal] = None) -> None:
        """Update risk limits"""
        if max_position is not None:
            self.max_position_size = max_position
        if max_daily_loss is not None:
            self.max_daily_loss = max_daily_loss
        if max_total_exposure is not None:
            self.max_total_exposure = max_total_exposure
        
        logger.info(f"Updated risk limits: max_position={self.max_position_size}, "
                   f"max_daily_loss={self.max_daily_loss}, max_total_exposure={self.max_total_exposure}")
"""
Whale tracking and scoring system for Allocator AI
"""

import time
import logging
import requests
import math
import decimal
from decimal import Decimal
from collections import defaultdict, deque
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

from ..utils.math_utils import calculate_win_rate, calculate_volatility, calculate_sharpe_ratio
from ..data.cache import CacheManager, RateLimiter
from ..analytics.market_conditions import MarketConditionAnalyzer
from ..analytics.adaptive_discovery import AdaptiveDiscoveryEngine
from ..analytics.moralis_feedback import MoralisFeedbackTracker

logger = logging.getLogger(__name__)


@dataclass
class WhaleStats:
    """Whale performance statistics"""
    address: str
    score: Decimal
    roi: Decimal
    trades: int
    win_rate: Decimal
    volatility: Decimal
    sharpe_ratio: Decimal
    moralis_roi_pct: Optional[Decimal] = None
    moralis_profit_usd: Optional[Decimal] = None
    moralis_trades: Optional[int] = None
    last_updated: float = 0


class WhaleTracker:
    """Advanced whale tracking and scoring system"""
    
    def __init__(self, moralis_api_key: str, cache_manager: CacheManager, db_manager, discovery_config=None):
        self.moralis_api_key = moralis_api_key
        self.cache = cache_manager
        self.db = db_manager
        self.rate_limiter = RateLimiter(max_calls=100, time_window=3600)  # 100 calls per hour
        
        # New adaptive components
        self.market_analyzer = None  # Will be initialized when needed
        self.adaptive_engine = None  # Will be initialized when needed
        self.moralis_feedback = MoralisFeedbackTracker(db_manager)
        
        # Whale performance tracking
        self.whale_history = defaultdict(lambda: deque(maxlen=50))  # Keep last 50 trades
        self.whale_scores = defaultdict(lambda: WhaleStats(
            address="",
            score=Decimal("0"),
            roi=Decimal("0"),
            trades=0,
            win_rate=Decimal("0"),
            volatility=Decimal("1"),
            sharpe_ratio=Decimal("0")
        ))
        
        # Tracked whales
        self.tracked_whales = set()
        
        # Discovery modes configuration (load from config or use defaults)
        if discovery_config and discovery_config.mode_settings:
            self.discovery_modes = discovery_config.mode_settings
        else:
            # Default fallback settings
            self.discovery_modes = {
                "bot_hunter": {
                    "blocks_back": 5000,
                    "min_trades": 15,
                    "min_pnl_threshold": 50
                },
                "active_whale": {
                    "blocks_back": 18000,
                    "min_trades": 8,
                    "min_pnl_threshold": 25
                },
                "lazy_whale": {
                    "blocks_back": 18500,
                    "min_trades": 6,
                    "min_pnl_threshold": 100
                },
                "quick_profit_whale": {
                    "blocks_back": 15000,
                    "min_trades": 5,
                    "min_pnl_threshold": 40,
                    "profit_window_hours": 72
                },
                "fast_mover_whale": {
                    "blocks_back": 17000,
                    "min_trades": 6,
                    "min_pnl_threshold": 35,
                    "min_roi": 0.15
                }
            }
    
    def update_whale_score(self, whale_address: str, pnl_eth: Decimal) -> WhaleStats:
        """Update whale performance after a mirrored trade settles"""
        whale_address = whale_address.lower()
        
        # Add to history
        self.whale_history[whale_address].append(pnl_eth)
        
        # Calculate statistics
        pnl_list = list(self.whale_history[whale_address])
        total_pnl = sum(pnl_list)
        win_rate = calculate_win_rate(pnl_list)
        volatility = calculate_volatility(pnl_list)
        sharpe_ratio = calculate_sharpe_ratio(pnl_list)
        
        # Calculate composite score
        # Higher PnL + higher win rate + lower volatility = better score
        if volatility > 0:
            score = (total_pnl * win_rate) / volatility
        else:
            score = total_pnl * win_rate
        
        # Update whale stats
        self.whale_scores[whale_address] = WhaleStats(
            address=whale_address,
            score=score,
            roi=total_pnl,
            trades=len(pnl_list),
            win_rate=win_rate,
            volatility=volatility,
            sharpe_ratio=sharpe_ratio,
            last_updated=time.time()
        )
        
        # Update database with new performance metrics
        self.db.update_whale_performance(
            whale_address,
            cumulative_pnl=float(total_pnl),
            score=float(score),
            win_rate=float(win_rate)
        )
        
        logger.debug(f"Updated whale {whale_address}: score={score:.4f}, roi={total_pnl:.4f}, win_rate={win_rate:.2%}")
        
        return self.whale_scores[whale_address]
    
    def should_follow_whale(self, whale_address: str, min_roi_pct: Decimal = Decimal("5"), 
                          min_profit_usd: Decimal = Decimal("500"), 
                          min_trades: int = 5) -> bool:
        """Determine if whale should be followed based on performance"""
        whale_address = whale_address.lower()
        stats = self.whale_scores.get(whale_address)
        
        if not stats:
            return True  # No info yet, default to follow
        
        # Check live performance
        if stats.roi < 0:
            logger.info(f"[CULL] Dropping whale {whale_address} - negative ROI")
            return False
        
        if stats.win_rate < Decimal("0.4"):  # Less than 40% win rate
            logger.info(f"[CULL] Dropping whale {whale_address} - low win rate: {stats.win_rate:.2%}")
            return False
        
        if stats.score < 0:
            logger.info(f"[CULL] Dropping whale {whale_address} - negative score")
            return False
        
        # Check Moralis bootstrap data if available
        if stats.moralis_roi_pct is not None:
            if stats.moralis_roi_pct < min_roi_pct:
                logger.info(f"[CULL] Dropping whale {whale_address} - low Moralis ROI: {stats.moralis_roi_pct}%")
                return False
            
            if stats.moralis_profit_usd is not None and stats.moralis_profit_usd < min_profit_usd:
                logger.info(f"[CULL] Dropping whale {whale_address} - low Moralis profit: ${stats.moralis_profit_usd}")
                return False
            
            if stats.moralis_trades is not None and stats.moralis_trades < min_trades:
                logger.info(f"[CULL] Dropping whale {whale_address} - insufficient trades: {stats.moralis_trades}")
                return False
        
        return True
    
    def get_whale_rankings(self, top_n: int = 10) -> List[Tuple[str, WhaleStats]]:
        """Get top N whales by score"""
        ranked = sorted(
            self.whale_scores.items(), 
            key=lambda kv: kv[1].score, 
            reverse=True
        )
        return ranked[:top_n]
    
    def fetch_moralis_data(self, whale_address: str) -> Optional[Dict]:
        """Fetch whale data from Moralis API with caching and rate limiting"""
        whale_address = whale_address.lower()
        
        # Check cache first
        cached_data = self.cache.get('moralis', whale_address)
        if cached_data:
            return cached_data
        
        # Check rate limiting
        if not self.rate_limiter.can_make_call("moralis_api"):
            logger.warning(f"Rate limited for Moralis API call for {whale_address}")
            return None
        
        try:
            headers = {"X-API-Key": self.moralis_api_key}
            url = f"https://deep-index.moralis.io/api/v2.2/wallets/{whale_address}/profitability/summary?chain=eth"
            
            response = requests.get(url, headers=headers, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                
                # Extract relevant data from the summary endpoint
                moralis_data = {
                    "realized_usd": Decimal(str(data.get("total_realized_profit_usd", 0))),
                    "realized_pct": Decimal(str(data.get("total_realized_profit_percentage", 0))),
                    "total_trades": data.get("total_count_of_trades", 0),
                    "timestamp": time.time()
                }
                
                # Cache the result
                self.cache.set('moralis', whale_address, moralis_data)
                self.rate_limiter.record_call("moralis_api")
                
                logger.debug(f"Fetched Moralis data for {whale_address}: ${moralis_data['realized_usd']} profit, {moralis_data['realized_pct']}% ROI")
                
                return moralis_data
            else:
                logger.warning(f"Moralis API error for {whale_address}: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"Failed to fetch Moralis data for {whale_address}: {e}")
            return None
    
    def bootstrap_whale_from_moralis(self, whale_address: str, min_roi_pct: Decimal = Decimal("5"),
                                   min_profit_usd: Decimal = Decimal("500"), 
                                   min_trades: int = 5) -> bool:
        """Bootstrap whale data from Moralis and add to tracking if meets criteria"""
        whale_address = whale_address.lower()
        
        # Check if already tracked
        if whale_address in self.tracked_whales:
            return True
        
        # Check database cache first
        db_data = self.db.get_whale(whale_address)
        if db_data:
            _, roi_pct, usd, trades, _, last_refresh = db_data
            if time.time() - (last_refresh or 0) < 24 * 3600:  # 24 hours
                # Use cached data
                self.whale_scores[whale_address].moralis_roi_pct = Decimal(str(roi_pct))
                self.whale_scores[whale_address].moralis_profit_usd = Decimal(str(usd))
                self.whale_scores[whale_address].moralis_trades = trades
                self.tracked_whales.add(whale_address)
                logger.info(f"Loaded whale {whale_address} from DB cache")
                return True
        
        # Fetch fresh data from Moralis
        logger.info(f"Fetching Moralis data for {whale_address[:10]}...")
        moralis_data = self.fetch_moralis_data(whale_address)
        if not moralis_data:
            logger.warning(f"Failed to fetch Moralis data for {whale_address[:10]}...")
            return False
        
        # Check if meets criteria
        logger.info(f"Validating whale {whale_address}: {moralis_data['realized_pct']}% ROI, ${moralis_data['realized_usd']} profit, {moralis_data['total_trades']} trades")
        if (moralis_data["realized_pct"] < min_roi_pct or 
            moralis_data["realized_usd"] < min_profit_usd or 
            moralis_data["total_trades"] < min_trades):
            logger.info(f"Whale {whale_address} doesn't meet criteria: {moralis_data['realized_pct']}% ROI, ${moralis_data['realized_usd']} profit, {moralis_data['total_trades']} trades")
            return False
        
        # Add to tracking
        self.whale_scores[whale_address].moralis_roi_pct = moralis_data["realized_pct"]
        self.whale_scores[whale_address].moralis_profit_usd = moralis_data["realized_usd"]
        self.whale_scores[whale_address].moralis_trades = moralis_data["total_trades"]
        self.tracked_whales.add(whale_address)
        
        # Calculate additional metrics for database storage
        # Get current whale stats (will be default/empty for new whales)
        whale_stats = self.get_whale_stats(whale_address)
        
        # Calculate more meaningful initial values based on Moralis data
        moralis_roi_pct = Decimal(str(moralis_data["realized_pct"]))
        moralis_profit_usd = Decimal(str(moralis_data["realized_usd"]))
        moralis_trades = moralis_data["total_trades"]
        
        # Estimate initial allocation size based on Moralis ROI and capital
        base_capital = Decimal("1000")  # Default base capital for calculation
        # Scale allocation based on Moralis performance (better whales get more allocation)
        roi_multiplier = min(max(moralis_roi_pct / Decimal("100"), Decimal("0.5")), Decimal("2.0"))
        initial_allocation = float(base_capital * Decimal("0.1") * roi_multiplier)
        
        # Initial risk multiplier based on Moralis performance
        if moralis_roi_pct > 50:
            initial_risk = 1.5  # High performing whale
        elif moralis_roi_pct > 20:
            initial_risk = 1.2  # Good performing whale
        elif moralis_roi_pct > 0:
            initial_risk = 1.0  # Positive whale
        else:
            initial_risk = 0.8  # Poor performing whale
        
        # Estimate initial score based on Moralis data
        # Simple heuristic: ROI% * sqrt(trades) / 10
        if moralis_trades > 0:
            estimated_score = float(moralis_roi_pct * Decimal(str(moralis_trades ** 0.5)) / Decimal("10"))
        else:
            estimated_score = 0.0
        
        # Estimate win rate based on ROI (rough approximation)
        if moralis_roi_pct > 30:
            estimated_win_rate = 0.7  # 70% win rate for high ROI
        elif moralis_roi_pct > 10:
            estimated_win_rate = 0.6  # 60% win rate
        elif moralis_roi_pct > 0:
            estimated_win_rate = 0.55  # 55% win rate
        else:
            estimated_win_rate = 0.4  # 40% win rate for losing whales
        
        # Convert Moralis USD profit to rough ETH estimate (assuming $2000/ETH)
        estimated_pnl_eth = float(moralis_profit_usd / Decimal("2000"))
        
        # Save to database with meaningful initial values
        logger.info(f"Saving whale {whale_address} to database...")
        db_start_time = time.time()
        self.db.save_whale(
            whale_address,
            float(moralis_data["realized_pct"]),
            float(moralis_data["realized_usd"]),
            moralis_data["total_trades"],
            cumulative_pnl=estimated_pnl_eth,  # Estimated ETH PnL from USD
            risk_multiplier=initial_risk,
            allocation_size=initial_allocation,
            score=estimated_score,
            win_rate=estimated_win_rate
        )
        db_elapsed = time.time() - db_start_time
        logger.info(f"Database save completed in {db_elapsed:.1f}s for {whale_address}")
        
        logger.info(f"Initialized whale {whale_address} metrics: risk={initial_risk:.2f}, allocation={initial_allocation:.2f} ETH, score={estimated_score:.2f}")        
        
        # Note: Token data fetching is now handled separately to avoid blocking the main discovery process
        # Use --fetch-tokens command or the test_adaptive_discovery.py script to fetch token data
        
        logger.info(f"Added whale {whale_address} to tracking: {moralis_data['realized_pct']}% ROI, ${moralis_data['realized_usd']} profit")
        logger.info(f"bootstrap_whale_from_moralis completed for {whale_address}")
        return True
    
    def discover_whales_from_blocks(self, w3, mode: str = "active_whale", 
                                  simulate: bool = False) -> List[str]:
        """Discover whales by scanning recent blocks"""
        if mode not in self.discovery_modes:
            logger.warning(f"Unknown discovery mode: {mode}")
            mode = "active_whale"
        
        params = self.discovery_modes[mode]
        blocks_back = params["blocks_back"]
        min_trades = params["min_trades"]
        min_pnl_thr = params["min_pnl_threshold"]
        
        logger.info(f"Discovering whales with mode {mode}: {blocks_back} blocks back, min {min_trades} trades, min {min_pnl_thr} ETH")
        
        start_block = max(0, w3.eth.block_number - blocks_back)
        end_block = w3.eth.block_number
        
        # Track candidate statistics
        candidate_stats = defaultdict(lambda: {"profit": Decimal(0), "trades": 0})
        
        # Scan blocks for whale candidates with progress logging
        total_blocks = end_block - start_block + 1
        logger.info(f"Scanning {total_blocks} blocks from {start_block} to {end_block}")
        
        for i, block_num in enumerate(range(start_block, end_block + 1)):
            try:
                # Progress logging every 500 blocks
                if i % 500 == 0 and i > 0:
                    progress = (i / total_blocks) * 100
                    logger.info(f"Mode {mode}: {progress:.1f}% complete ({i}/{total_blocks} blocks)")
                
                block = w3.eth.get_block(block_num, full_transactions=True)
                
                for tx in block.transactions:
                    # Check if transaction is to Uniswap
                    if tx.to and tx.to.lower() in [
                        "0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D".lower(),  # Uniswap V2
                        "0xE592427A0AEce92De3Edee1F18E0157C05861564".lower()   # Uniswap V3
                    ]:
                        actor = tx["from"].lower()
                        candidate_stats[actor]["trades"] += 1
                        candidate_stats[actor]["profit"] += Decimal(tx.value) / (10**18)
                        
            except Exception as e:
                logger.debug(f"Failed to process block {block_num}: {e}")
                continue
        
        logger.info(f"Completed scanning {total_blocks} blocks")
        
        # Filter candidates
        new_whales = []
        for addr, stats in candidate_stats.items():
            if (stats["trades"] >= min_trades and 
                stats["profit"] >= min_pnl_thr):
                new_whales.append(addr)
        
        logger.info(f"Found {len(new_whales)} whale candidates from {len(candidate_stats)} addresses")
        
        if simulate:
            return new_whales
        
        # Bootstrap candidates with Moralis data
        added_whales = []
        for whale in new_whales:
            if self.bootstrap_whale_from_moralis(whale):
                added_whales.append(whale)
        
        logger.info(f"Successfully added {len(added_whales)} whales to tracking")
        return added_whales
    
    def discover_whales_adaptive(self, w3, adaptive_config: Dict, simulate: bool = False) -> List[str]:
        """Run adaptive whale discovery using percentile-based thresholds"""
        try:
            # Initialize adaptive components if needed
            if self.market_analyzer is None:
                self.market_analyzer = MarketConditionAnalyzer(w3, self.cache)
            
            if self.adaptive_engine is None:
                self.adaptive_engine = AdaptiveDiscoveryEngine(w3, self.market_analyzer)
            
            # Get adaptive configuration
            percentile_config = getattr(adaptive_config, "percentile_mode", {}) or {}
            
            if not percentile_config.get("enabled", False):
                logger.info("Adaptive percentile discovery is disabled")
                return []
            
            activity_percentile = percentile_config.get("activity_percentile", 5.0)
            profit_percentile = percentile_config.get("profit_percentile", 25.0)
            blocks_back = percentile_config.get("blocks_back", 10000)
            
            logger.info(f"Running adaptive discovery: top {activity_percentile}% activity, "
                       f"top {profit_percentile}% profit over {blocks_back} blocks (sampling every 5th block)")
            
            # Run adaptive discovery
            result = self.adaptive_engine.discover_whales_percentile(
                activity_percentile=activity_percentile,
                profit_percentile=profit_percentile,
                blocks_back=blocks_back
            )
            
            candidates = result.get("candidates", [])
            
            if simulate:
                return candidates
            
            # Validate with Moralis
            validated_whales = []
            logger.info(f"Starting Moralis validation for {len(candidates)} adaptive candidates...")
            
            candidates_to_validate = candidates
            
            for i, whale_address in enumerate(candidates_to_validate):
                try:
                    start_time = time.time()
                    logger.info(f"Validating candidate {i+1}/{len(candidates_to_validate)}: {whale_address[:10]}...")
                    
                    if self.bootstrap_whale_from_moralis(whale_address):
                        validated_whales.append(whale_address)
                        elapsed = time.time() - start_time
                        logger.info(f"✅ Candidate {whale_address[:10]}... validated and added ({elapsed:.1f}s)")
                        # Track acceptance
                        self.moralis_feedback.track_moralis_acceptance(
                            address=whale_address,
                            roi_pct=0.0,  # Will be updated with actual values
                            profit_usd=0.0,
                            trades=0,
                            discovery_mode="adaptive_percentile"
                        )
                    else:
                        elapsed = time.time() - start_time
                        logger.info(f"❌ Candidate {whale_address[:10]}... rejected by Moralis ({elapsed:.1f}s)")
                        # Track rejection (reason will be determined in bootstrap_whale_from_moralis)
                        self.moralis_feedback.track_moralis_rejection(
                            address=whale_address,
                            reason="failed_validation",
                            discovery_mode="adaptive_percentile"
                        )
                    
                    # Add small delay to prevent overwhelming the API
                    time.sleep(0.5)
                    
                except Exception as e:
                    elapsed = time.time() - start_time
                    logger.warning(f"Failed to validate adaptive candidate {whale_address[:10]}...: {e} ({elapsed:.1f}s)")
                    self.moralis_feedback.track_moralis_rejection(
                        address=whale_address,
                        reason="api_error",
                        discovery_mode="adaptive_percentile"
                    )
            
            logger.info(f"Adaptive discovery: {len(validated_whales)}/{len(candidates)} whales validated")
            return validated_whales
            
        except Exception as e:
            logger.error(f"Adaptive discovery failed: {e}")
            return []
    
    def get_adaptive_suggestions(self, mode: str, current_thresholds: Dict) -> Dict:
        """Get adjustment suggestions based on Moralis feedback"""
        return self.moralis_feedback.get_adjustment_suggestions(mode, current_thresholds)
    
    def get_moralis_feedback_summary(self) -> Dict:
        """Get summary of Moralis feedback for dashboard"""
        return self.moralis_feedback.get_rejection_summary()
    
    def simulate_whale_trades(self, whale_address: str, num_trades: int = 5) -> None:
        """Simulate some trade history for a whale (useful for DRY_RUN mode testing)"""
        import random
        whale_address = whale_address.lower()
        
        logger.info(f"Simulating {num_trades} trades for whale {whale_address}")
        
        # Common tokens to simulate trading
        tokens = ["ETH", "WBTC", "USDC", "LINK", "UNI", "AAVE", "PEPE", "SHIB", "DOGE"]
        
        for i in range(num_trades):
            # Generate random PnL based on whale's Moralis performance
            whale_stats = self.whale_scores.get(whale_address)
            if whale_stats and whale_stats.moralis_roi_pct:
                # Base PnL on historical performance with some randomness
                base_performance = float(whale_stats.moralis_roi_pct) / 100
                random_factor = random.uniform(0.5, 1.5)
                simulated_pnl = base_performance * random_factor * random.uniform(0.1, 2.0)
            else:
                # Random PnL between -1 and +2 ETH
                simulated_pnl = random.uniform(-1.0, 2.0)
            
            # Pick a random token for this trade
            token = random.choice(tokens)
            
            # Update token-level PnL (this will also recalculate Score v2.0)
            self.update_whale_token_trade(whale_address, token, simulated_pnl)
            
            # Also update the traditional whale score for backward compatibility
            self.update_whale_score(whale_address, Decimal(str(simulated_pnl)))
            
        logger.info(f"Completed simulation for whale {whale_address}")
    
    def get_whale_stats(self, whale_address: str) -> Optional[WhaleStats]:
        """Get current stats for a whale"""
        return self.whale_scores.get(whale_address.lower())
    
    def get_all_tracked_whales(self) -> List[str]:
        """Get list of all tracked whale addresses"""
        return list(self.tracked_whales)
    
    def remove_whale(self, whale_address: str) -> bool:
        """Remove whale from tracking"""
        whale_address = whale_address.lower()
        if whale_address in self.tracked_whales:
            self.tracked_whales.remove(whale_address)
            logger.info(f"Removed whale {whale_address} from tracking")
            return True
        return False
    
    def refresh_all_whale_metrics(self, simulate_trades: bool = False) -> None:
        """Refresh metrics for all tracked whales (useful for DRY_RUN mode)"""
        logger.info("Refreshing metrics for all tracked whales")
        
        for whale_address in list(self.tracked_whales):
            try:
                # Get existing whale data from database
                whale_data = self.db.get_whale(whale_address)
                if not whale_data:
                    continue
                
                # whale_data columns: address, moralis_roi_pct, roi_usd, trades, cumulative_pnl, 
                # risk_multiplier, allocation_size, score, win_rate, bootstrap_time, last_refresh
                moralis_roi_pct = whale_data[1] if whale_data[1] is not None else 0
                moralis_profit_usd = whale_data[2] if whale_data[2] is not None else 0
                moralis_trades = whale_data[3] if whale_data[3] is not None else 0
                
                # If the performance fields are still 0/default, refresh them
                if (whale_data[4] == 0 and whale_data[7] == 0):  # cumulative_pnl and score are 0
                    logger.info(f"Refreshing metrics for whale {whale_address}")
                    
                    # Recalculate initial values (same logic as bootstrap)
                    moralis_roi_decimal = Decimal(str(moralis_roi_pct))
                    moralis_profit_decimal = Decimal(str(moralis_profit_usd))
                    
                    # Calculate improved metrics
                    base_capital = Decimal("1000")
                    roi_multiplier = min(max(moralis_roi_decimal / Decimal("100"), Decimal("0.5")), Decimal("2.0"))
                    new_allocation = float(base_capital * Decimal("0.1") * roi_multiplier)
                    
                    if moralis_roi_pct > 50:
                        new_risk = 1.5
                    elif moralis_roi_pct > 20:
                        new_risk = 1.2
                    elif moralis_roi_pct > 0:
                        new_risk = 1.0
                    else:
                        new_risk = 0.8
                    
                    if moralis_trades > 0:
                        new_score = float(moralis_roi_decimal * Decimal(str(moralis_trades ** 0.5)) / Decimal("10"))
                    else:
                        new_score = 0.0
                    
                    if moralis_roi_pct > 30:
                        new_win_rate = 0.7
                    elif moralis_roi_pct > 10:
                        new_win_rate = 0.6
                    elif moralis_roi_pct > 0:
                        new_win_rate = 0.55
                    else:
                        new_win_rate = 0.4
                    
                    new_pnl_eth = float(moralis_profit_decimal / Decimal("2000"))
                    
                    # Update database with calculated values
                    self.db.update_whale_performance(
                        whale_address,
                        cumulative_pnl=new_pnl_eth,
                        risk_multiplier=new_risk,
                        allocation_size=new_allocation,
                        score=new_score,
                        win_rate=new_win_rate
                    )
                    
                    # Optionally simulate some trade history
                    if simulate_trades:
                        self.simulate_whale_trades(whale_address, num_trades=3)
                        
            except Exception as e:
                logger.error(f"Error refreshing whale {whale_address}: {e}")
        
        logger.info("Completed refreshing whale metrics")
    
    def calculate_diversity_factor(self, whale_address: str) -> float:
        """Calculate diversity factor based on token concentration (0=concentrated, 1=diverse)"""
        whale_address = whale_address.lower()
        
        # Get token breakdown from database
        token_breakdown = self.db.get_whale_token_breakdown(whale_address)
        
        if not token_breakdown or len(token_breakdown) < 2:
            # Only 1 token or no data = maximum concentration penalty
            return 0.1
        
        # Build pnl_by_token dict
        pnl_by_token = {}
        total_pnl = 0
        
        for token_symbol, token_address, cumulative_pnl, trade_count, last_updated in token_breakdown:
            # Skip the PROCESSED marker token
            if token_symbol == "PROCESSED":
                continue
            try:
                # Handle various data types and invalid values
                if cumulative_pnl is None or cumulative_pnl == '':
                    pnl_value = 0.0
                elif isinstance(cumulative_pnl, (int, float)):
                    pnl_value = float(cumulative_pnl)
                elif isinstance(cumulative_pnl, str):
                    # Check for obviously invalid strings
                    if cumulative_pnl.strip() in ['', 'None', 'null', 'NULL']:
                        pnl_value = 0.0
                    else:
                        # Try to convert string to float
                        pnl_value = float(cumulative_pnl)
                else:
                    logger.warning(f"Unexpected cumulative_pnl type for {token_symbol}: {type(cumulative_pnl)} = {cumulative_pnl}")
                    pnl_value = 0.0
                
                # Check for reasonable bounds to prevent overflow
                if abs(pnl_value) > 1e12:  # Cap at 1 trillion
                    logger.warning(f"Extremely large PnL value for {token_symbol}: {pnl_value}, capping to 0")
                    pnl_value = 0.0
                
                if pnl_value > 0:  # Only count profitable tokens for concentration calc
                    pnl_by_token[token_symbol] = pnl_value
                    total_pnl += pnl_value
            except (ValueError, TypeError, decimal.ConversionSyntax) as e:
                # Skip tokens with invalid PnL data
                logger.warning(f"Skipping token {token_symbol} due to invalid PnL data: {cumulative_pnl} (error: {e})")
                continue
        
        if total_pnl <= 0 or len(pnl_by_token) == 0:
            return 0.1  # No profitable tokens = max penalty
        
        # Calculate Herfindahl-Hirschman Index (HHI)
        concentration = 0
        for token_pnl in pnl_by_token.values():
            weight = token_pnl / total_pnl
            concentration += weight ** 2
        
        # Diversity factor = 1 - concentration
        diversity_factor = 1 - concentration
        
        # Cap at 0.6 as "solidly diverse" as mentioned
        diversity_factor = min(diversity_factor, 0.6)
        
        logger.debug(f"Whale {whale_address} diversity: {len(pnl_by_token)} tokens, "
                    f"concentration={concentration:.3f}, diversity_factor={diversity_factor:.3f}")
        
        return diversity_factor
    
    def calculate_score_v2(self, whale_address: str) -> float:
        """Calculate Score Formula 2.0 with diversity penalty"""
        whale_address = whale_address.lower()
        
        try:
            # Get current whale stats
            whale_stats = self.get_whale_stats(whale_address)
            if not whale_stats:
                logger.warning(f"No whale stats found for {whale_address}")
                return 0.0
            
            # Get whale data from database for additional metrics
            whale_data = self.db.get_whale(whale_address)
            if not whale_data:
                logger.warning(f"No whale data found for {whale_address}")
                return 0.0
            
            logger.debug(f"Processing whale {whale_address}: whale_data={whale_data}")
            logger.debug(f"Whale data types: {[type(x) for x in whale_data]}")
            logger.debug(f"Whale data values: {whale_data}")
            logger.debug(f"Whale stats for {whale_address}: score={whale_stats.score}, roi={whale_stats.roi}, trades={whale_stats.trades}, win_rate={whale_stats.win_rate}")
            logger.debug(f"Whale stats types: score={type(whale_stats.score)}, roi={type(whale_stats.roi)}, trades={type(whale_stats.trades)}, win_rate={type(whale_stats.win_rate)}")
            
        except Exception as e:
            logger.error(f"Error getting whale data for {whale_address}: {e}")
            return 0.0
        
        # Extract metrics with safe conversion
        # whale_data[1] = moralis_roi_pct (correct)
        try:
            if whale_data[1] is None or whale_data[1] == '':
                roi_pct = 0.0
            elif isinstance(whale_data[1], (int, float)):
                roi_pct = float(whale_data[1])
            else:
                roi_pct = float(str(whale_data[1]))
        except (ValueError, TypeError, decimal.ConversionSyntax):
            logger.warning(f"Invalid ROI data for {whale_address}: {whale_data[1]}")
            roi_pct = 0.0
            
        try:
            if whale_stats.win_rate is None or whale_stats.win_rate == '':
                win_rate = 0.0
            elif isinstance(whale_stats.win_rate, Decimal):
                win_rate = float(whale_stats.win_rate)
            elif isinstance(whale_stats.win_rate, (int, float)):
                win_rate = float(whale_stats.win_rate)
            else:
                win_rate = float(str(whale_stats.win_rate))
        except (ValueError, TypeError, decimal.ConversionSyntax, decimal.InvalidOperation) as e:
            logger.warning(f"Invalid win_rate data for {whale_address}: {whale_stats.win_rate} (type: {type(whale_stats.win_rate)}, error: {e})")
            win_rate = 0.0
            
        try:
            if whale_stats.trades is None or whale_stats.trades == '':
                trades = 0
            elif isinstance(whale_stats.trades, (int, float)):
                trades = int(whale_stats.trades)
            elif isinstance(whale_stats.trades, Decimal):
                trades = int(whale_stats.trades)
            else:
                trades = int(float(str(whale_stats.trades)))
        except (ValueError, TypeError, decimal.ConversionSyntax, decimal.InvalidOperation) as e:
            logger.warning(f"Invalid trades data for {whale_address}: {whale_stats.trades} (type: {type(whale_stats.trades)}, error: {e})")
            trades = 0
            
        try:
            if whale_stats.roi is None or whale_stats.roi == '':
                cumulative_pnl = 0.0
            elif isinstance(whale_stats.roi, Decimal):
                cumulative_pnl = float(whale_stats.roi)
            elif isinstance(whale_stats.roi, (int, float)):
                cumulative_pnl = float(whale_stats.roi)
            else:
                cumulative_pnl = float(str(whale_stats.roi))
        except (ValueError, TypeError, decimal.ConversionSyntax, decimal.InvalidOperation) as e:
            logger.warning(f"Invalid ROI data for {whale_address}: {whale_stats.roi} (type: {type(whale_stats.roi)}, error: {e})")
            cumulative_pnl = 0.0
        
        # Calculate base score using the new formula
        base_score = (
            roi_pct * 0.35 +
            win_rate * 100 * 0.25 +  # Convert win_rate to percentage
            math.log(trades + 1) * 0.15 +
            cumulative_pnl * 0.15
        )
        
        # Calculate diversity factor
        try:
            diversity_factor = self.calculate_diversity_factor(whale_address)
            logger.debug(f"Diversity factor calculated for {whale_address}: {diversity_factor}")
        except Exception as e:
            logger.error(f"Error calculating diversity factor for {whale_address}: {e}")
            diversity_factor = 0.1  # Default to minimum diversity
        
        # Check minimum requirements for valid whale
        MIN_TRADES = 20
        MIN_TOKENS = 5
        
        # Get token count for this whale
        token_breakdown = self.db.get_whale_token_breakdown(whale_address)
        token_count = len([t for t in token_breakdown if t[0] != "PROCESSED"])  # Exclude PROCESSED marker
        
        # Check if whale meets minimum requirements
        if trades < MIN_TRADES or token_count < MIN_TOKENS:
            reason = f"< {MIN_TRADES} trades ({trades}) or < {MIN_TOKENS} tokens ({token_count})"
            logger.info(f"Whale {whale_address} does not meet minimum requirements: {reason}")
            
            # Mark as discarded
            self.db.mark_whale_discarded(whale_address, reason)
            return 0.0  # Return 0 score for discarded whales
        
        # Apply diversity adjustment
        try:
            adjusted_score = base_score * (0.1 + 0.9 * diversity_factor)
        except Exception as e:
            logger.error(f"Error calculating adjusted score for {whale_address}: {e}")
            adjusted_score = base_score
        
        logger.info(f"Whale {whale_address} Score v2.0: base={base_score:.2f}, "
                   f"diversity={diversity_factor:.3f}, adjusted={adjusted_score:.2f}, "
                   f"trades={trades}, tokens={token_count}")
        
        return adjusted_score
    
    def update_whale_token_trade(self, whale_address: str, token_symbol: str, 
                                pnl_change: float, token_address: str = None) -> None:
        """Update token-level PnL and recalculate whale score"""
        whale_address = whale_address.lower()
        
        # Update token-level PnL in database
        self.db.update_whale_token_pnl(whale_address, token_symbol, pnl_change, token_address)
        
        # Recalculate Score v2.0
        new_score = self.calculate_score_v2(whale_address)
        
        # Update whale's overall score in database
        self.db.update_whale_performance(whale_address, score=new_score)
        
        # Update in-memory whale stats
        if whale_address in self.whale_scores:
            self.whale_scores[whale_address].score = Decimal(str(new_score))
        
        logger.info(f"Updated whale {whale_address} token {token_symbol}: PnL {pnl_change:+.4f}, new score: {new_score:.2f}")
    
    def fetch_token_data_from_moralis(self, whale_address: str) -> None:
        """Fetch real token-level data from Moralis for existing whales"""
        whale_address = whale_address.lower()
        
        # Check if whale already has token data (including "PROCESSED" marker)
        existing_tokens = self.db.get_whale_token_breakdown(whale_address)
        if existing_tokens:
            # Filter out the PROCESSED marker for counting
            real_tokens = [t for t in existing_tokens if t[0] != "PROCESSED"]
            if real_tokens or any(t[0] == "PROCESSED" for t in existing_tokens):
                logger.debug(f"Whale {whale_address} already processed ({len(real_tokens)} real tokens)")
                return
        
        logger.info(f"Fetching token-level data from Moralis for whale {whale_address}")
        
        try:
            # Check rate limiting
            if not self.rate_limiter.can_make_call("moralis_api"):
                logger.warning(f"Rate limited for Moralis API call for {whale_address}")
                return
            
            # Use the full profitability endpoint for token data
            profitability_url = f"https://deep-index.moralis.io/api/v2.2/wallets/{whale_address}/profitability?chain=eth"
            
            headers = {
                "X-API-Key": self.moralis_api_key
            }
            
            # Call the full profitability endpoint to get the token breakdown
            logger.info(f"Calling Moralis full profitability API for {whale_address}")
            api_start_time = time.time()
            response = requests.get(profitability_url, headers=headers, timeout=30)
            api_elapsed = time.time() - api_start_time
            logger.info(f"Moralis API call completed in {api_elapsed:.1f}s for {whale_address}")
            
            if response.status_code == 200:
                data = response.json()
                logger.debug(f"Full profitability response keys: {list(data.keys()) if isinstance(data, dict) else type(data)}")
                
                # The full profitability endpoint returns: {"result": [array of token objects]}
                if "result" in data and isinstance(data["result"], list):
                    # Process the token breakdown from the result array
                    logger.info(f"Processing {len(data['result'])} tokens for {whale_address}")
                    processing_start_time = time.time()
                    if self._process_profitability_breakdown(whale_address, data):
                        processing_elapsed = time.time() - processing_start_time
                        logger.info(f"Token processing completed in {processing_elapsed:.1f}s for {whale_address}")
                        return
                else:
                    logger.warning(f"Unexpected profitability structure for {whale_address}: {list(data.keys())}")
                
                logger.warning(f"Could not process profitability data for {whale_address}")
            else:
                logger.warning(f"Profitability API failed ({response.status_code}) for {whale_address}: {response.text}")
            
            # Fallback to token transfers method (commented out for debugging)
            # 
            # token_transfers_url = f"https://deep-index.moralis.io/api/v2.2/{whale_address}/erc20/transfers"
            # params = {
            #     "chain": "eth", 
            #     "from_date": "2024-08-01",  # Adjust based on your needs
            #     "limit": 50  # Conservative limit to avoid API errors
            # }
            # 
            # logger.info(f"Calling Moralis token transfers API for {whale_address}")
            # response = requests.get(token_transfers_url, headers=headers, params=params, timeout=30)
            
            # Skip fallback processing for debugging
            logger.warning(f"Could not process token data for {whale_address} - profitability endpoint failed")
            return
            
        except Exception as e:
            logger.error(f"Error fetching token data from Moralis for {whale_address}: {e}")
            return
    
    def _process_profitability_breakdown(self, whale_address: str, data) -> bool:
        """Process the profitability breakdown API response"""
        try:
            logger.info(f"Profitability breakdown response: {len(data.get('result', []))} tokens")
            
            # The breakdown endpoint returns: {"result": [array of token objects]}
            tokens = data.get("result", [])
            if not tokens:
                logger.warning("No tokens found in profitability breakdown response")
                return False
            
            meaningful_tokens = 0
            
            for token_data in tokens:
                try:
                    # Extract data from the breakdown response
                    token_symbol = token_data.get("symbol", "UNKNOWN")
                    token_address = token_data.get("token_address", "")
                    realized_profit_usd = float(token_data.get("realized_profit_usd", 0))
                    trade_count = int(token_data.get("count_of_trades", 0))
                    
                    # Convert USD to ETH (rough approximation - could be improved with price feeds)
                    # Using ~$2000/ETH as rough conversion
                    realized_profit_eth = realized_profit_usd / 2000.0
                    
                    # Store if meaningful activity (realized profit or multiple trades)
                    if abs(realized_profit_eth) > 0.001 or trade_count >= 2:  # $2+ profit or 2+ trades
                        db_start_time = time.time()
                        self.db.update_whale_token_pnl(whale_address, token_symbol, realized_profit_eth, token_address, trade_count)
                        db_elapsed = time.time() - db_start_time
                        meaningful_tokens += 1
                        logger.debug(f"Stored {token_symbol}: ${realized_profit_usd:.2f} ({realized_profit_eth:.6f} ETH), {trade_count} trades (DB: {db_elapsed:.3f}s)")
                    else:
                        logger.debug(f"Skipped {token_symbol}: too small profit (${realized_profit_usd:.2f})")
                        
                except Exception as e:
                    logger.error(f"Error processing token data: {e}")
                    continue
            
            if meaningful_tokens == 0:
                # Add a marker to indicate this whale has been processed (no meaningful tokens)
                self.db.update_whale_token_pnl(whale_address, "PROCESSED", 0.0, "")
                logger.info(f"No meaningful token activity found for whale {whale_address}")
            else:
                logger.info(f"Stored {meaningful_tokens} tokens from profitability data for whale {whale_address}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error processing profitability breakdown: {e}")
            return False
    
    def _store_profitability_token(self, whale_address: str, token_key: str, token_info) -> bool:
        """Store a single token's profitability data"""
        try:
            # Extract token information
            if isinstance(token_info, dict):
                # Extract common fields (structure to be determined from actual API response)
                token_symbol = token_info.get("symbol", token_info.get("token_symbol", token_key if token_key and not token_key.startswith('0x') else "UNKNOWN"))
                token_address = token_info.get("address", token_info.get("token_address", token_key if token_key and token_key.startswith('0x') else ""))
                
                # Look for PnL/profit fields - try various common field names
                pnl = None
                for pnl_field in ["pnl", "profit", "total_pnl", "realized_pnl", "unrealized_pnl", "profit_loss", "net_profit", "total_profit"]:
                    if pnl_field in token_info:
                        try:
                            pnl = float(token_info[pnl_field])
                            break
                        except (ValueError, TypeError):
                            continue
                
                # Look for trade count fields
                trade_count = 1  # Default
                for count_field in ["trades", "trade_count", "count", "transactions", "tx_count"]:
                    if count_field in token_info:
                        try:
                            trade_count = int(token_info[count_field])
                            break
                        except (ValueError, TypeError):
                            continue
                
                # Convert to ETH if needed (assuming USD values)
                if pnl is not None:
                    # Rough conversion - could be improved with price feeds
                    pnl_eth = pnl / 2000.0  # Assuming ~$2000/ETH
                    
                    # Store the token data
                    self.db.update_whale_token_pnl(whale_address, token_symbol, pnl_eth, token_address, trade_count)
                    logger.debug(f"Stored {token_symbol}: {pnl_eth:.6f} ETH, {trade_count} trades")
                    return True
                else:
                    logger.debug(f"No PnL data found for token {token_symbol}")
                    return False
            else:
                logger.warning(f"Unexpected token_info type: {type(token_info)}")
                return False
                
        except Exception as e:
            logger.error(f"Error storing profitability token data: {e}")
            return False
            
            logger.info(f"Moralis returned {len(transfers)} transfers for whale {whale_address}")
            
            if not transfers:
                logger.info(f"No token transfers found for whale {whale_address}")
                return
            
            # Analyze transfers to build token PnL estimates
            token_activity = defaultdict(lambda: {"in_value": 0, "out_value": 0, "trades": 0, "address": ""})
            
            processed_transfers = 0
            skipped_dust = 0
            skipped_unrelated = 0
            
            for transfer in transfers:
                try:
                    token_symbol = transfer.get("token_symbol", "UNKNOWN")
                    token_address = transfer.get("token_address", "")
                    from_address = transfer.get("from_address", "").lower()
                    to_address = transfer.get("to_address", "").lower()
                    
                    # Try multiple value fields - Moralis API might use different field names
                    value = None
                    for value_field in ["value_formatted", "value", "amount"]:
                        raw_value = transfer.get(value_field)
                        if raw_value is not None:
                            try:
                                value = float(raw_value)
                                break
                            except (ValueError, TypeError):
                                continue
                    
                    if value is None:
                        value = 0.0
                    
                    # Debug first few transfers to understand the data format
                    if processed_transfers + skipped_dust < 5:
                        logger.info(f"Transfer sample: {token_symbol} from {from_address[:10]}... to {to_address[:10]}... value: {value}")
                        logger.info(f"  Whale address: {whale_address[:10]}...")
                        if processed_transfers + skipped_dust == 0:
                            logger.debug(f"  Raw transfer data: {transfer}")
                    
                    # More lenient dust filter - tokens might have different decimal places
                    if value < 0.000001:  # Much lower threshold
                        skipped_dust += 1
                        continue
                    
                    # Track inflows and outflows
                    if from_address == whale_address:
                        # Whale selling/sending tokens
                        token_activity[token_symbol]["out_value"] += value
                        token_activity[token_symbol]["trades"] += 1
                        token_activity[token_symbol]["address"] = token_address
                        processed_transfers += 1
                    elif to_address == whale_address:
                        # Whale buying/receiving tokens
                        token_activity[token_symbol]["in_value"] += value
                        token_activity[token_symbol]["trades"] += 1
                        token_activity[token_symbol]["address"] = token_address
                        processed_transfers += 1
                    else:
                        skipped_unrelated += 1
                        
                except Exception as e:
                    logger.debug(f"Error processing transfer: {e}")
                    continue
            
            logger.info(f"Processed {processed_transfers} transfers, skipped {skipped_dust} dust, {skipped_unrelated} unrelated")
            
            # Convert activity to PnL estimates and store in database
            tokens_added = 0
            total_estimated_pnl = 0
            
            for token_symbol, activity in token_activity.items():
                if activity["trades"] == 0:
                    continue
                
                # Simple PnL estimation: assume whale is net positive on tokens they're actively trading
                # This is a rough heuristic - real PnL would need price data at trade time
                net_volume = abs(activity["in_value"] - activity["out_value"])
                trade_count = activity["trades"]
                
                # Estimate PnL as a percentage of volume (crude approximation)
                # Active traders might make 5-20% on their trades
                estimated_pnl_pct = min(0.15, max(0.01, trade_count / 100))  # 1-15% based on activity
                estimated_pnl = net_volume * estimated_pnl_pct
                
                logger.debug(f"Token {token_symbol}: volume={net_volume:.4f}, trades={trade_count}, est_pnl={estimated_pnl:.6f}")
                
                if estimated_pnl > 0.0001:  # Lower threshold to catch more activity
                    # Convert to ETH equivalent (rough approximation)
                    if token_symbol in ["USDC", "USDT", "DAI"]:
                        estimated_pnl_eth = estimated_pnl / 2000  # USD to ETH
                    elif token_symbol == "WBTC":
                        estimated_pnl_eth = estimated_pnl * 15    # BTC to ETH (rough ratio)
                    elif token_symbol == "ETH" or token_symbol == "WETH":
                        estimated_pnl_eth = estimated_pnl
                    else:
                        estimated_pnl_eth = estimated_pnl * 0.001  # Alt coins to ETH (very rough)
                    
                    # Store in database
                    token_address = activity.get('address', '')
                    self.db.update_whale_token_pnl(whale_address, token_symbol, estimated_pnl_eth, token_address)
                    
                    tokens_added += 1
                    total_estimated_pnl += estimated_pnl_eth
                    
                    logger.debug(f"  {token_symbol}: {estimated_pnl_eth:.6f} ETH PnL ({trade_count} trades)")
                else:
                    logger.debug(f"  {token_symbol}: Skipped - PnL too small ({estimated_pnl:.6f})")
            
            if tokens_added > 0:
                logger.info(f"Fetched token data for whale {whale_address}: "
                           f"{tokens_added} tokens, {total_estimated_pnl:.4f} ETH total estimated PnL")
            else:
                logger.info(f"No meaningful token activity found for whale {whale_address}")
                # Even if no tokens found, mark as processed by adding a dummy record
                self.db.update_whale_token_pnl(whale_address, "PROCESSED", 0.0, "0x0")
            
        except Exception as e:
            logger.error(f"Error fetching token data from Moralis for {whale_address}: {e}")
            return
    
    def _process_profitability_breakdown(self, whale_address: str, data) -> bool:
        """Process the profitability breakdown API response"""
        try:
            logger.info(f"Profitability breakdown response: {len(data.get('result', []))} tokens")
            
            # The breakdown endpoint returns: {"result": [array of token objects]}
            tokens = data.get("result", [])
            if not tokens:
                logger.warning("No tokens found in profitability breakdown response")
                return False
            
            meaningful_tokens = 0
            
            for token_data in tokens:
                try:
                    # Extract data from the breakdown response
                    token_symbol = token_data.get("symbol", "UNKNOWN")
                    token_address = token_data.get("token_address", "")
                    realized_profit_usd = float(token_data.get("realized_profit_usd", 0))
                    trade_count = int(token_data.get("count_of_trades", 0))
                    
                    # Convert USD to ETH (rough approximation - could be improved with price feeds)
                    # Using ~$2000/ETH as rough conversion
                    realized_profit_eth = realized_profit_usd / 2000.0
                    
                    # Store if meaningful activity (realized profit or multiple trades)
                    if abs(realized_profit_eth) > 0.001 or trade_count >= 2:  # $2+ profit or 2+ trades
                        db_start_time = time.time()
                        self.db.update_whale_token_pnl(whale_address, token_symbol, realized_profit_eth, token_address, trade_count)
                        db_elapsed = time.time() - db_start_time
                        meaningful_tokens += 1
                        logger.debug(f"Stored {token_symbol}: ${realized_profit_usd:.2f} ({realized_profit_eth:.6f} ETH), {trade_count} trades (DB: {db_elapsed:.3f}s)")
                    else:
                        logger.debug(f"Skipped {token_symbol}: too small profit (${realized_profit_usd:.2f})")
                        
                except Exception as e:
                    logger.error(f"Error processing token data: {e}")
                    continue
            
            if meaningful_tokens == 0:
                # Add a marker to indicate this whale has been processed (no meaningful tokens)
                self.db.update_whale_token_pnl(whale_address, "PROCESSED", 0.0, "")
                logger.info(f"No meaningful token activity found for whale {whale_address}")
            else:
                logger.info(f"Stored {meaningful_tokens} tokens from profitability data for whale {whale_address}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error processing profitability breakdown: {e}")
            return False
    
    def _store_profitability_token(self, whale_address: str, token_key: str, token_info) -> bool:
        """Store a single token's profitability data"""
        try:
            # Extract token information
            if isinstance(token_info, dict):
                # Extract common fields (structure to be determined from actual API response)
                token_symbol = token_info.get("symbol", token_info.get("token_symbol", token_key if token_key and not token_key.startswith('0x') else "UNKNOWN"))
                token_address = token_info.get("address", token_info.get("token_address", token_key if token_key and token_key.startswith('0x') else ""))
                
                # Look for PnL/profit fields - try various common field names
                pnl = None
                for pnl_field in ["pnl", "profit", "total_pnl", "realized_pnl", "unrealized_pnl", "profit_loss", "net_profit", "total_profit"]:
                    if pnl_field in token_info:
                        try:
                            pnl = float(token_info[pnl_field])
                            break
                        except (ValueError, TypeError):
                            continue
                
                # Look for trade count
                trades = token_info.get("trades", token_info.get("trade_count", token_info.get("transactions", token_info.get("tx_count", 1))))
                try:
                    trades = int(trades)
                except (ValueError, TypeError):
                    trades = 1
                
                # If no direct PnL, try to calculate from buy/sell values
                if pnl is None:
                    buy_value = token_info.get("buy_value", token_info.get("total_buy", token_info.get("invested", 0)))
                    sell_value = token_info.get("sell_value", token_info.get("total_sell", token_info.get("realized", 0)))
                    try:
                        buy_value = float(buy_value) if buy_value else 0
                        sell_value = float(sell_value) if sell_value else 0
                        if buy_value > 0 or sell_value > 0:
                            pnl = sell_value - buy_value
                    except (ValueError, TypeError):
                        pass
                
            elif isinstance(token_info, (int, float)):
                # Simple value, assume it's the PnL
                pnl = float(token_info)
                token_symbol = token_key if token_key and not token_key.startswith('0x') else "UNKNOWN"
                token_address = token_key if token_key and token_key.startswith('0x') else ""
                trades = 1
            else:
                logger.warning(f"Unexpected token_info type: {type(token_info)}")
                return False
            
            # Store if meaningful
            if pnl is not None and (abs(pnl) > 0.0001 or trades >= 2):
                self.db.update_whale_token_pnl(whale_address, token_symbol, pnl, token_address, trades)
                logger.debug(f"Stored {token_symbol}: PnL={pnl:.6f}, trades={trades}")
                return True
                
            return False
            
        except Exception as e:
            logger.error(f"Error storing profitability token data: {e}")
            return False
    """
Web interface and API for Allocator AI
"""

from .dashboard import create_app

__all__ = [
    "create_app"
]
"""
Web dashboard for Allocator AI
"""

import logging
import time
from flask import Flask, render_template_string, jsonify, request, make_response
from typing import Dict, Any, List
from decimal import Decimal
from datetime import datetime

logger = logging.getLogger(__name__)

# Dashboard HTML template
DASHBOARD_TEMPLATE = """
<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Allocator AI - {{ mode }} Mode</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
            color: #333;
        }
        .header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 30px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }
        .header h1 {
            margin: 0;
            font-size: 2.5em;
            font-weight: 300;
        }
        .mode-badge {
            background: rgba(255,255,255,0.2);
            padding: 8px 16px;
            border-radius: 20px;
            font-weight: bold;
            font-size: 0.9em;
        }
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        .stat-card {
            background: white;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            text-align: center;
            transition: transform 0.2s ease;
        }
        .stat-card:hover {
            transform: translateY(-2px);
        }
        .stat-value {
            font-size: 2.5em;
            font-weight: bold;
            margin: 10px 0;
        }
        .positive { color: #28a745; }
        .negative { color: #dc3545; }
        .neutral { color: #007bff; }
        .stat-label {
            color: #666;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        .table-container {
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            overflow: hidden;
            margin-bottom: 30px;
        }
        /* Global table styles removed to prevent conflicts with inline styles */
        .whale-row-profitable { background-color: rgba(40,167,69,0.05); }
        .whale-row-medium { background-color: rgba(255,193,7,0.05); }
        .whale-row-risky { background-color: rgba(220,53,69,0.05); }
        .status-indicator {
            display: inline-block;
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-right: 8px;
        }
        .status-online { background-color: #28a745; }
        .status-offline { background-color: #dc3545; }
        .refresh-btn {
            background: #007bff;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 14px;
        }
        .refresh-btn:hover {
            background: #0056b3;
        }
        .btn-expand {
            background: #28a745;
            color: white;
            border: none;
            padding: 5px 10px;
            border-radius: 3px;
            cursor: pointer;
            font-size: 12px;
        }
        .btn-expand:hover {
            background: #1e7e34;
        }
        .token-breakdown {
            background-color: #f8f9fa;
        }
        .token-details {
            padding: 20px;
        }
        .token-table-div {
            width: 100%;
            margin: 10px 0;
            border: 1px solid #dee2e6;
            border-radius: 4px;
            overflow: hidden;
            font-size: 0.9em;
        }
        .token-header {
            display: flex;
            background: #e9ecef;
            font-weight: bold;
            border-bottom: 1px solid #dee2e6;
        }
        .token-row {
            display: flex;
            border-bottom: 1px solid #dee2e6;
        }
        .token-row:last-child {
            border-bottom: none;
        }
        .token-col {
            flex: 1;
            padding: 8px;
            text-align: left;
        }
        .token-col:first-child {
            flex: 1.5;
        }
        @media (max-width: 768px) {
            .header {
                flex-direction: column;
                text-align: center;
            }
            .stats-grid {
                grid-template-columns: 1fr;
            }
            table {
                font-size: 0.9em;
            }
        }
        
    </style>
</head>
<body>
    <div class="header">
        <h1>🐋 Allocator AI</h1>
        <div>
            <span class="mode-badge">{{ mode }} MODE</span>
            <a href="/analysis" style="background: #28a745; color: white; padding: 8px 16px; text-decoration: none; border-radius: 4px; margin-right: 10px;">📊 Whale Analysis</a>
            <button class="refresh-btn" onclick="location.reload()">Refresh</button>
        </div>
    </div>

    <div class="stats-grid">
        <div class="stat-card">
            <div class="stat-label">Total PnL</div>
            <div class="stat-value {% if total_pnl > 0 %}positive{% elif total_pnl < 0 %}negative{% else %}neutral{% endif %}">
                {{ '%.4f' | format(total_pnl) }} ETH
            </div>
        </div>
        <div class="stat-card">
            <div class="stat-label">Active Capital</div>
            <div class="stat-value neutral">{{ '%.4f' | format(capital) }} ETH</div>
        </div>
        <div class="stat-card">
            <div class="stat-label">Tracked Whales</div>
            <div class="stat-value neutral">{{ whale_count }}</div>
        </div>
        <div class="stat-card">
            <div class="stat-label">Total Trades</div>
            <div class="stat-value neutral">{{ trade_count }}</div>
        </div>
    </div>

    <div class="table-container">
        <h2 style="margin: 0; padding: 20px; background: #f8f9fa; border-bottom: 1px solid #dee2e6;">Discovery Status</h2>
        <table style="width: 100%; border-collapse: collapse;">
            <thead>
                <tr>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Mode</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Status</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Blocks to Scan</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Min Trades</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Min PnL Threshold</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Candidates Found</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Validated Whales</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Last Run Time</th>
                </tr>
            </thead>
            <tbody>
                {% for discovery in discovery_status %}
                <tr>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;"><strong>{{ discovery.mode }}</strong></td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">
                        <span class="status-indicator {{ 'status-online' if discovery.status == 'running' else 'status-idle' if discovery.status == 'completed' else 'status-offline' }}"></span>
                        {{ discovery.status.title() }}
                    </td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ '{:,}'.format(discovery.blocks_back|int) if discovery.blocks_back else 'N/A' }}</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ discovery.min_trades }}</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ discovery.min_pnl_threshold }} ETH</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;" class="neutral">{{ discovery.candidates_found if discovery.candidates_found is not none else 'N/A' }}</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;" class="{{ 'positive' if discovery.validated_whales and discovery.validated_whales > 0 else 'neutral' }}">
                        {{ discovery.validated_whales if discovery.validated_whales is not none else 'N/A' }}
                    </td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ discovery.last_run_duration if discovery.last_run_duration else 'N/A' }}</td>
                </tr>
                {% endfor %}
            </tbody>
        </table>
    </div>

    <div class="table-container">
        <h2 style="margin: 0; padding: 20px; background: #f8f9fa; border-bottom: 1px solid #dee2e6;">Whale Performance</h2>
        <div style="overflow-x: auto;">
            <table id="whale-performance-table" style="width: 100%; min-width: 1200px; border-collapse: collapse;">
                <thead>
                    <tr style="background: #f8f9fa;">
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap;">Whale Address</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap;">Cumulative PnL</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap;">Risk Multiplier</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap;">Allocation Size</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap;">Trade Count</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap;">Score v2.0 ↓</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap;">Win Rate</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap; width: 100px;">Moralis ROI%</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap; width: 120px;">Moralis PnL $</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap; width: 80px;">Tokens</th>
                        <th style="padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6; white-space: nowrap; width: 100px;">Actions</th>
                    </tr>
                </thead>
                <tbody>
                    {% for w in whales %}
                    <tr style="border-bottom: 1px solid #dee2e6; {% if w.moralis_roi is not none and w.moralis_roi >= 20 %}background-color: rgba(40,167,69,0.05);{% elif w.moralis_roi is not none and w.moralis_roi > 0 %}background-color: rgba(255,193,7,0.05);{% else %}background-color: rgba(220,53,69,0.05);{% endif %}">
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">
                            <span style="display: inline-block; width: 10px; height: 10px; border-radius: 50%; background-color: #28a745; margin-right: 8px;"></span>
                            {{ w.address[:6] }}...{{ w.address[-4:] }}
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6; {% if w.pnl > 0 %}color: #28a745;{% elif w.pnl < 0 %}color: #dc3545;{% else %}color: #007bff;{% endif %}">
                            {{ '%.4f' | format(w.pnl) }}
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">
                            {{ '%.2f' | format(w.risk) }}x
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">
                            {{ '%.4f' | format(w.allocation) }} ETH
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">
                            {{ w.count }}
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6; font-weight: bold;">
                            {{ '%.2f' | format(w.score) }}
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">
                            {{ '%.0f' | format(w.winrate) }}%
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6; width: 100px; text-align: center; overflow: hidden; text-overflow: ellipsis;">
                            {% if w.moralis_roi is not none %}
                                {% if w.moralis_roi > 999999 or w.moralis_roi < -999999 %}
                                    {{ 'ERROR' }}
                                {% else %}
                                    {{ '%.2f' | format(w.moralis_roi) }}%
                                {% endif %}
                            {% else %}
                                N/A
                            {% endif %}
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6; width: 120px; text-align: center; overflow: hidden; text-overflow: ellipsis;">
                            {% if w.moralis_profit_usd is not none %}
                                {% if w.moralis_profit_usd > 999999999 or w.moralis_profit_usd < -999999999 %}
                                    {{ 'ERROR' }}
                                {% else %}
                                    {{ '%.2f' | format(w.moralis_profit_usd) }}$
                                {% endif %}
                            {% else %}
                                N/A
                            {% endif %}
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6; width: 80px; text-align: center;">
                            {{ w.tokens|length }} tokens
                        </td>
                        <td style="padding: 15px; border-bottom: 1px solid #dee2e6; width: 100px; text-align: center;">
                            <button style="background: #28a745; color: white; border: none; padding: 5px 10px; border-radius: 3px; cursor: pointer; font-size: 12px; margin-right: 5px;" onclick="toggleTokens('{{ w.address }}')">Show Tokens</button>
                            <button style="background: #007bff; color: white; border: none; padding: 5px 10px; border-radius: 3px; cursor: pointer; font-size: 12px;" onclick="copyAddress('{{ w.address }}')">Copy</button>
                        </td>
                    </tr>
                    <!-- Token breakdown row (hidden by default) -->
                    <tr id="tokens-{{ w.address }}" style="display: none; background-color: #f8f9fa;">
                        <td colspan="11" style="padding: 20px; border-bottom: 1px solid #dee2e6;">
                            <h4 style="margin: 0 0 15px 0; color: #495057;">Token Breakdown for {{ w.address[:6] }}...{{ w.address[-4:] }}</h4>
                            {% if w.tokens %}
                            <table style="width: 100%; border-collapse: collapse; background: white; border: 1px solid #dee2e6; border-radius: 4px;">
                                <thead>
                                    <tr style="background: #e9ecef;">
                                        <th style="padding: 10px; text-align: left; border-bottom: 1px solid #dee2e6; font-weight: 600;">Token</th>
                                        <th style="padding: 10px; text-align: left; border-bottom: 1px solid #dee2e6; font-weight: 600;">PnL (ETH)</th>
                                        <th style="padding: 10px; text-align: left; border-bottom: 1px solid #dee2e6; font-weight: 600;">Trades</th>
                                        <th style="padding: 10px; text-align: left; border-bottom: 1px solid #dee2e6; font-weight: 600;">Weight</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    {% for token in w.tokens %}
                                    <tr>
                                        <td style="padding: 10px; border-bottom: 1px solid #dee2e6;"><strong>{{ token.symbol }}</strong></td>
                                        <td style="padding: 10px; border-bottom: 1px solid #dee2e6; {% if token.pnl > 0 %}color: #28a745;{% elif token.pnl < 0 %}color: #dc3545;{% else %}color: #007bff;{% endif %}">
                                            {{ '%.4f' | format(token.pnl) }}
                                        </td>
                                        <td style="padding: 10px; border-bottom: 1px solid #dee2e6;">{{ token.trades }}</td>
                                        <td style="padding: 10px; border-bottom: 1px solid #dee2e6;">
                                            {% if w.pnl > 0 %}
                                                {{ '%.1f' | format((token.pnl / w.pnl) * 100) }}%
                                            {% else %}
                                                N/A
                                            {% endif %}
                                        </td>
                                    </tr>
                                    {% endfor %}
                                </tbody>
                            </table>
                            {% else %}
                            <p style="color: #6c757d; font-style: italic;">No token-level data available yet.</p>
                            {% endif %}
                        </td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>
        </div>
    </div>

    <div class="table-container">
        <h2 style="margin: 0; padding: 20px; background: #f8f9fa; border-bottom: 1px solid #dee2e6;">Recent Trades</h2>
        <table style="width: 100%; border-collapse: collapse;">
            <thead>
                <tr>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Time</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Actor</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Direction</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Amount In</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Amount Out</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">PnL</th>
                    <th style="background: #f8f9fa; padding: 15px; text-align: left; font-weight: 600; color: #495057; border-bottom: 2px solid #dee2e6;">Mode</th>
                </tr>
            </thead>
            <tbody>
                {% for t in trades %}
                <tr>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ t.timestamp }}</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ t.actor }}</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ t.token_in }} → {{ t.token_out }}</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ '%.4f' | format(t.amount_in) }}</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ '%.4f' | format(t.amount_out) }}</td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;" class="{% if t.pnl > 0 %}positive{% elif t.pnl < 0 %}negative{% else %}neutral{% endif %}">
                        {{ '%.4f' | format(t.pnl) }}
                    </td>
                    <td style="padding: 15px; border-bottom: 1px solid #dee2e6;">{{ t.mode }}</td>
                </tr>
                {% endfor %}
            </tbody>
        </table>
    </div>

    <script>
        // Toggle token breakdown display
        function toggleTokens(whaleAddress) {
            const row = document.getElementById('tokens-' + whaleAddress);
            const button = document.querySelector(`button[onclick="toggleTokens('${whaleAddress}')"]`);
            
            if (row && button) {
                if (row.style.display === 'none' || row.style.display === '') {
                    row.style.display = 'table-row';
                    button.textContent = 'Hide Tokens';
                    button.style.background = '#dc3545';
                } else {
                    row.style.display = 'none';
                    button.textContent = 'Show Tokens';
                    button.style.background = '#28a745';
                }
            }
        }
        
        // Copy whale address to clipboard
        function copyAddress(whaleAddress) {
            navigator.clipboard.writeText(whaleAddress).then(function() {
                // Show feedback
                const button = document.querySelector(`button[onclick="copyAddress('${whaleAddress}')"]`);
                const originalText = button.textContent;
                button.textContent = 'Copied!';
                button.style.background = '#28a745';
                
                setTimeout(function() {
                    button.textContent = originalText;
                    button.style.background = '#007bff';
                }, 1500);
            }).catch(function(err) {
                console.error('Failed to copy address: ', err);
                alert('Failed to copy address to clipboard');
            });
        }

        // Table sorting removed - using database-level sorting by Score v2.0
    </script>
</body>
</html>
"""

# Analysis HTML template
ANALYSIS_TEMPLATE = """
<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Whale Copy Trading Analysis - Allocator AI</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
            color: #333;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
            text-align: center;
        }
        .header h1 {
            margin: 0;
            font-size: 2.5em;
        }
        .header p {
            margin: 10px 0 0 0;
            font-size: 1.2em;
            opacity: 0.9;
        }
        .nav {
            text-align: center;
            margin-bottom: 30px;
        }
        .nav a {
            display: inline-block;
            background: #007bff;
            color: white;
            padding: 10px 20px;
            text-decoration: none;
            border-radius: 5px;
            margin: 0 10px;
        }
        .nav a:hover {
            background: #0056b3;
        }
        .summary {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        .summary-card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            text-align: center;
        }
        .summary-card h3 {
            margin: 0 0 10px 0;
            color: #667eea;
        }
        .summary-card .number {
            font-size: 2em;
            font-weight: bold;
            color: #333;
        }
        .whale-card {
            background: white;
            border-radius: 10px;
            padding: 25px;
            margin-bottom: 20px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            border-left: 5px solid #ddd;
        }
        .whale-card.excellent { border-left-color: #28a745; }
        .whale-card.good { border-left-color: #17a2b8; }
        .whale-card.fair { border-left-color: #ffc107; }
        .whale-card.poor { border-left-color: #fd7e14; }
        .whale-card.avoid { border-left-color: #dc3545; }
        .whale-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
        }
        .whale-address {
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            font-weight: bold;
            color: #333;
        }
        .copy-btn {
            background: #007bff;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 0.9em;
        }
        .copy-btn:hover {
            background: #0056b3;
        }
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }
        .metric {
            text-align: center;
            padding: 10px;
            background: #f8f9fa;
            border-radius: 5px;
        }
        .metric-label {
            font-size: 0.9em;
            color: #666;
            margin-bottom: 5px;
        }
        .metric-value {
            font-size: 1.2em;
            font-weight: bold;
            color: #333;
        }
        .recommendation {
            background: #e9ecef;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 15px;
        }
        .recommendation.excellent { background: #d4edda; color: #155724; }
        .recommendation.good { background: #d1ecf1; color: #0c5460; }
        .recommendation.fair { background: #fff3cd; color: #856404; }
        .recommendation.poor { background: #f8d7da; color: #721c24; }
        .recommendation.avoid { background: #f5c6cb; color: #721c24; }
        .reasons {
            margin-top: 15px;
        }
        .reasons h4 {
            margin: 0 0 10px 0;
            color: #333;
        }
        .reasons ul {
            margin: 0;
            padding-left: 20px;
        }
        .reasons li {
            margin-bottom: 5px;
        }
        .token-breakdown {
            margin-top: 20px;
        }
        .token-breakdown h4 {
            margin: 0 0 10px 0;
            color: #333;
        }
        .token-list {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
        }
        .token {
            background: #e9ecef;
            padding: 4px 8px;
            border-radius: 3px;
            font-size: 0.9em;
        }
        .token.positive { background: #d4edda; color: #155724; }
        .token.negative { background: #f8d7da; color: #721c24; }
        .risk-indicator {
            display: inline-block;
            padding: 4px 8px;
            border-radius: 3px;
            font-size: 0.8em;
            font-weight: bold;
            text-transform: uppercase;
        }
        .risk-low { background: #d4edda; color: #155724; }
        .risk-medium { background: #fff3cd; color: #856404; }
        .risk-high { background: #f8d7da; color: #721c24; }
        .risk-very-high { background: #f5c6cb; color: #721c24; }
        .footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            color: #666;
            border-top: 1px solid #dee2e6;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>🐋 Whale Copy Trading Analysis</h1>
        <p>Generated on {{ moment }} | Mode: {{ mode }}</p>
    </div>
    
    <div class="nav">
        <a href="/">← Back to Dashboard</a>
        <a href="/analysis">Refresh Analysis</a>
    </div>
    
    <div class="summary">
        <div class="summary-card">
            <h3>Total Whales</h3>
            <div class="number">{{ total_whales }}</div>
        </div>
        <div class="summary-card">
            <h3>Excellent</h3>
            <div class="number">{{ excellent_count }}</div>
        </div>
        <div class="summary-card">
            <h3>Good</h3>
            <div class="number">{{ good_count }}</div>
        </div>
        <div class="summary-card">
            <h3>Fair</h3>
            <div class="number">{{ fair_count }}</div>
        </div>
        <div class="summary-card">
            <h3>Poor/Avoid</h3>
            <div class="number">{{ poor_count }}</div>
        </div>
    </div>
    
    <div class="whales">
        {% for whale in analyses %}
        <div class="whale-card {{ whale.recommendation.lower() }}">
            <div class="whale-header">
                <div>
                    <div class="whale-address">{{ whale.address }}</div>
                    <div style="font-size: 0.9em; color: #666; margin-top: 5px;">
                        Rank #{{ loop.index }} | Copy Trading Score: {{ "%.1f"|format(whale.copy_trading_score) }}/100
                    </div>
                </div>
                <button class="copy-btn" onclick="copyAddress('{{ whale.address }}')">Copy Address</button>
            </div>
            
            <div class="metrics-grid">
                <div class="metric">
                    <div class="metric-label">Score v2.0</div>
                    <div class="metric-value">{{ "%.2f"|format(whale.score_v2) }}</div>
                </div>
                <div class="metric">
                    <div class="metric-label">ROI</div>
                    <div class="metric-value">{{ "%.1f"|format(whale.roi_pct) }}%</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Profit</div>
                    <div class="metric-value">${{ "%.0f"|format(whale.profit_usd) }}</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Trades</div>
                    <div class="metric-value">{{ whale.trades }}</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Win Rate</div>
                    <div class="metric-value">{{ "%.1f"|format(whale.win_rate*100) }}%</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Tokens</div>
                    <div class="metric-value">{{ whale.token_count }}</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Diversification</div>
                    <div class="metric-value">{{ "%.1f"|format(whale.diversification_score) }}/100</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Risk Level</div>
                    <div class="metric-value">
                        <span class="risk-indicator risk-{{ whale.risk_level.lower().replace(' ', '-') }}">{{ whale.risk_level }}</span>
                    </div>
                </div>
            </div>
            
            <div class="recommendation {{ whale.recommendation.lower() }}">
                <strong>Recommendation: {{ whale.recommendation }}</strong>
            </div>
            
            <div class="reasons">
                <h4>Analysis:</h4>
                <ul>
                    {% for reason in whale.reasons %}
                    <li>{{ reason }}</li>
                    {% endfor %}
                </ul>
            </div>
            
            <div class="token-breakdown">
                <h4>Top Tokens:</h4>
                <div class="token-list">
                    {% for token_row in whale.token_breakdown %}
                    {% if loop.index <= 5 %}
                    {% if token_row[0] != 'PROCESSED' %}
                    <span class="token {% if token_row[2] > 0 %}positive{% else %}negative{% endif %}">{{ token_row[0] }}: {{ "%.2f"|format(token_row[2]) }} ETH ({{ token_row[3] }} trades)</span>
                    {% endif %}
                    {% endif %}
                    {% endfor %}
                </div>
            </div>
        </div>
        {% endfor %}
    </div>
    
    <div class="footer">
        <p>Generated by Whale Analyzer - Allocator AI</p>
        <p>Higher scores indicate better copy trading suitability</p>
    </div>
    
    <script>
        function copyAddress(address) {
            navigator.clipboard.writeText(address).then(function() {
                // Show feedback
                event.target.textContent = 'Copied!';
                event.target.style.background = '#28a745';
                
                setTimeout(function() {
                    event.target.textContent = 'Copy Address';
                    event.target.style.background = '#007bff';
                }, 1500);
            }).catch(function(err) {
                console.error('Failed to copy address: ', err);
                alert('Failed to copy address to clipboard');
            });
        }
    </script>
</body>
</html>
"""


def create_app(whale_tracker, risk_manager, db_manager, mode: str = "LIVE") -> Flask:
    """Create Flask application for the dashboard"""
    
    app = Flask(__name__)
    
    @app.route("/")
    def index():
        """Main dashboard page"""
        import time
        request_time = time.time()
        print(f"=== DASHBOARD REQUEST [{request_time}] ===")
        print(f"Method: {request.method}")
        print(f"URL: {request.url}")
        print(f"User-Agent: {request.headers.get('User-Agent', 'Unknown')}")
        print(f"Referrer: {request.referrer}")
        print(f"Args: {request.args}")
        print(f"Headers: {dict(request.headers)}")
        print(f"=== END REQUEST [{request_time}] ===")
        try:
            # Get whale data from database, sorted by Score v2.0 (descending)
            whale_data = []
            db_whales = db_manager.get_all_whales_sorted_by_score()
            
            for whale_row in db_whales:
                # Database columns: 0=address, 1=moralis_roi_pct, 2=roi_usd, 3=trades, 4=bootstrap_time, 
                # 5=last_refresh, 6=cumulative_pnl, 7=risk_multiplier, 8=allocation_size, 9=score, 10=win_rate
                try:
                    def safe_float(value, default=0.0):
                        """Safely convert to float with default fallback"""
                        if value is None:
                            return default
                        try:
                            return float(value)
                        except (ValueError, TypeError):
                            return default
                    
                    def safe_int(value, default=0):
                        """Safely convert to int with default fallback"""
                        if value is None:
                            return default
                        try:
                            return int(float(value))  # Convert via float first to handle string numbers
                        except (ValueError, TypeError):
                            return default
                    
                    # Get token breakdown for this whale
                    token_breakdown = db_manager.get_whale_token_breakdown(whale_row[0])
                    tokens_data = []
                    for token_symbol, token_address, token_pnl, trade_count, last_updated in token_breakdown:
                        # Skip the PROCESSED marker token
                        if token_symbol == "PROCESSED":
                            continue
                        tokens_data.append({
                            "symbol": token_symbol,
                            "address": token_address,
                            "pnl": safe_float(token_pnl),
                            "trades": safe_int(trade_count)
                        })
                    
                    whale_data.append({
                        "address": whale_row[0] if whale_row[0] is not None else "unknown",  # address (index 0)
                        "pnl": safe_float(whale_row[6]),  # cumulative_pnl (index 6)
                        "risk": safe_float(whale_row[7], 1.0),  # risk_multiplier (index 7)
                        "allocation": safe_float(whale_row[8]),  # allocation_size (index 8)
                        "count": safe_int(whale_row[3]),  # trades (index 3)
                        "score": safe_float(whale_row[9]),  # score (index 9)
                        "winrate": safe_float(whale_row[10]) * 100,  # win_rate (index 10, convert to percentage)
                        "moralis_roi": safe_float(whale_row[1]) if whale_row[1] is not None else None,  # moralis_roi_pct (index 1)
                        "moralis_profit_usd": safe_float(whale_row[2]) if whale_row[2] is not None else None,  # roi_usd (index 2)
                        "moralis_trades": safe_int(whale_row[3]) if whale_row[3] is not None else None,  # trades (index 3)
                        "bootstrap_time": whale_row[4] if whale_row[4] is not None else None,  # bootstrap_time (index 4)
                        "last_refresh": whale_row[5] if whale_row[5] is not None else None,  # last_refresh (index 5)
                        "tokens": tokens_data  # Token breakdown
                    })
                except Exception as e:
                    logger.warning(f"Error processing whale row {whale_row}: {e}")
                    continue
            
            # Keep database sort order (already sorted by Score v2.0)
            # whale_data.sort(key=lambda x: x["pnl"], reverse=True)  # Removed - keeping DB sort order
            
            # Get recent trades
            recent_trades = db_manager.get_recent_trades(20)
            trades_data = []
            for trade in recent_trades:
                trades_data.append({
                    "timestamp": trade[1],  # timestamp column
                    "actor": trade[2],      # actor column
                    "token_in": trade[8],   # token_in column
                    "token_out": trade[9],  # token_out column
                    "amount_in": trade[6],  # amount_in column
                    "amount_out": trade[7], # amount_out column
                    "pnl": trade[12],       # pnl column
                    "mode": trade[15]       # mode column
                })
            
            # Get stats
            stats = db_manager.get_stats()
            
            # Get discovery status
            discovery_status = []
            
            # Add adaptive discovery status
            try:
                adaptive_stats = db_manager.conn.execute("""
                    SELECT 
                        COUNT(*) as total_candidates,
                        SUM(CASE WHEN moralis_validated = TRUE THEN 1 ELSE 0 END) as validated_candidates,
                        SUM(CASE WHEN status = 'tokens_fetched' THEN 1 ELSE 0 END) as tokens_fetched
                    FROM adaptive_candidates
                """).fetchone()
                
                discovery_status.append({
                    "mode": "adaptive_percentile",
                    "status": "running",
                    "blocks_back": "Dynamic",
                    "min_trades": "Adaptive",
                    "min_pnl_threshold": "Market-based",
                    "candidates_found": adaptive_stats[0] if adaptive_stats else 0,
                    "validated_whales": adaptive_stats[1] if adaptive_stats else 0,
                    "last_run_duration": f"{adaptive_stats[2] if adaptive_stats else 0} tokens fetched"
                })
            except Exception as e:
                logger.warning(f"Could not get adaptive discovery stats: {e}")
                discovery_status.append({
                    "mode": "adaptive_percentile",
                    "status": "error",
                    "blocks_back": "N/A",
                    "min_trades": "N/A",
                    "min_pnl_threshold": "N/A",
                    "candidates_found": 0,
                    "validated_whales": 0,
                    "last_run_duration": "Error"
                })
            
            # Add standard discovery modes (commented out for now)
            # if hasattr(whale_tracker, 'discovery_modes') and whale_tracker.discovery_modes:
            #     for mode_name, config in whale_tracker.discovery_modes.items():
            #         discovery_status.append({
            #             "mode": mode_name,
            #             "status": "disabled",
            #             "blocks_back": config.get("blocks_back", 0),
            #             "min_trades": config.get("min_trades", 0),
            #             "min_pnl_threshold": config.get("min_pnl_threshold", 0),
            #             "candidates_found": None,
            #             "validated_whales": None,
            #             "last_run_duration": "Disabled"
            #         })
            
            response = make_response(render_template_string(
                DASHBOARD_TEMPLATE,
                whales=whale_data,  # Use real whale data
                trades=trades_data,  # Use real trades data
                discovery_status=discovery_status,  # Use real discovery status
                total_pnl=stats["total_pnl"],
                capital=stats.get("capital", 0.0),  # Use capital from stats or default to 0
                whale_count=stats["whale_count"],
                trade_count=stats["trade_count"],
                mode=mode
            ))
            
            # Disable all caching to prevent browser issues
            response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            response.headers['Pragma'] = 'no-cache'
            response.headers['Expires'] = '0'
            
            page_id = int(time.time() * 1000)  # Unique timestamp
            print(f"Returning dashboard [ID:{page_id}] with {len(whale_data)} whales and {len(discovery_status)} discovery modes")
            
            # Add the page ID to the response as a comment for debugging
            response_data = response.get_data(as_text=True)
            response_data = response_data.replace("</body>", f"<!-- Page ID: {page_id} -->\n</body>")
            response.set_data(response_data)
            
            return response
            
        except Exception as e:
            logger.error(f"Dashboard error: {e}")
            return f"Dashboard error: {e}", 500
    
    @app.route("/api/stats")
    def api_stats():
        """API endpoint for stats"""
        try:
            stats = db_manager.get_stats()
            return jsonify({
                "total_pnl": stats["total_pnl"],
                "whale_count": stats["whale_count"],
                "trade_count": stats["trade_count"],
                "mode": mode
            })
        except Exception as e:
            logger.error(f"API stats error: {e}")
            return jsonify({"error": str(e)}), 500
    
    @app.route("/api/whales")
    def api_whales():
        """API endpoint for whale data"""
        print(f"=== API /api/whales CALLED ===")
        print(f"Time: {time.time()}")
        print(f"User-Agent: {request.headers.get('User-Agent', 'Unknown')}")
        print(f"Referrer: {request.referrer}")
        print(f"Request method: {request.method}")
        print(f"Request URL: {request.url}")
        print(f"Request args: {request.args}")
        print(f"=== END API CALL ===")
        try:
            whale_data = []
            db_whales = db_manager.get_all_whales()
            
            for whale_row in db_whales:
                # Database columns: 0=address, 1=moralis_roi_pct, 2=roi_usd, 3=trades, 4=bootstrap_time, 
                # 5=last_refresh, 6=cumulative_pnl, 7=risk_multiplier, 8=allocation_size, 9=score, 10=win_rate
                try:
                    def safe_float(value, default=0.0):
                        """Safely convert to float with default fallback"""
                        if value is None:
                            return default
                        try:
                            return float(value)
                        except (ValueError, TypeError):
                            return default
                    
                    def safe_int(value, default=0):
                        """Safely convert to int with default fallback"""
                        if value is None:
                            return default
                        try:
                            return int(float(value))  # Convert via float first to handle string numbers
                        except (ValueError, TypeError):
                            return default
                    
                    # Get token breakdown for this whale
                    token_breakdown = db_manager.get_whale_token_breakdown(whale_row[0])
                    tokens_data = []
                    for token_symbol, token_address, token_pnl, trade_count, last_updated in token_breakdown:
                        # Skip the PROCESSED marker token
                        if token_symbol == "PROCESSED":
                            continue
                        tokens_data.append({
                            "symbol": token_symbol,
                            "address": token_address,
                            "pnl": safe_float(token_pnl),
                            "trades": safe_int(trade_count)
                        })
                    
                    whale_data.append({
                        "address": whale_row[0] if whale_row[0] is not None else "unknown",  # address (index 0)
                        "pnl": safe_float(whale_row[6]),  # cumulative_pnl (index 6)
                        "risk": safe_float(whale_row[7], 1.0),  # risk_multiplier (index 7)
                        "allocation": safe_float(whale_row[8]),  # allocation_size (index 8)
                        "count": safe_int(whale_row[3]),  # trades (index 3)
                        "score": safe_float(whale_row[9]),  # score (index 9)
                        "winrate": safe_float(whale_row[10]) * 100,  # win_rate (index 10, convert to percentage)
                        "moralis_roi": safe_float(whale_row[1]) if whale_row[1] is not None else None,  # moralis_roi_pct (index 1)
                        "moralis_profit_usd": safe_float(whale_row[2]) if whale_row[2] is not None else None,  # roi_usd (index 2)
                        "moralis_trades": safe_int(whale_row[3]) if whale_row[3] is not None else None,  # trades (index 3)
                        "bootstrap_time": whale_row[4] if whale_row[4] is not None else None,  # bootstrap_time (index 4)
                        "last_refresh": whale_row[5] if whale_row[5] is not None else None,  # last_refresh (index 5)
                        "tokens": tokens_data  # Token breakdown
                    })
                except Exception as e:
                    logger.warning(f"Error processing whale row in API {whale_row}: {e}")
                    continue
            
            return jsonify(whale_data)
        except Exception as e:
            logger.error(f"API whales error: {e}")
            return jsonify({"error": str(e)}), 500
    
    @app.route("/health")
    def health():
        """Health check endpoint"""
        return jsonify({
            "status": "healthy",
            "mode": mode,
            "whales_tracked": len(whale_tracker.get_all_tracked_whales())
        })
    
    @app.route("/favicon.ico")
    def favicon():
        """Favicon handler to prevent 404s"""
        print("Favicon request intercepted")
        return "", 204
    
    @app.route("/analysis")
    def whale_analysis():
        """Whale copy trading analysis page"""
        try:
            # Import the analyzer
            import sys
            import os
            sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
            from whale_analyzer import WhaleAnalyzer
            
            # Create analyzer and run analysis
            analyzer = WhaleAnalyzer()
            analyses = analyzer.analyze_all_whales()
            
            # Generate summary stats
            total_whales = len(analyses)
            excellent_count = len([w for w in analyses if w.recommendation == 'EXCELLENT'])
            good_count = len([w for w in analyses if w.recommendation == 'GOOD'])
            fair_count = len([w for w in analyses if w.recommendation == 'FAIR'])
            poor_count = len([w for w in analyses if w.recommendation in ['POOR', 'AVOID']])
            
            return render_template_string(ANALYSIS_TEMPLATE, 
                                       analyses=analyses,
                                       total_whales=total_whales,
                                       excellent_count=excellent_count,
                                       good_count=good_count,
                                       fair_count=fair_count,
                                       poor_count=poor_count,
                                       mode=mode,
                                       moment=datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
        except Exception as e:
            logger.error(f"Error in whale analysis: {e}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")
            return f"Analysis error: {e}", 500
    
    # Add catch-all route for debugging  
    @app.route("/<path:path>")
    def catch_all(path):
        print(f"Unexpected route requested: {path}")
        return f"Path {path} not found", 404
    
    return app
"""
Analytics module for Allocator AI
"""

from .market_conditions import MarketConditionAnalyzer
from .adaptive_discovery import AdaptiveDiscoveryEngine
from .moralis_feedback import MoralisFeedbackTracker

__all__ = [
    'MarketConditionAnalyzer',
    'AdaptiveDiscoveryEngine', 
    'MoralisFeedbackTracker'
]
"""
Moralis feedback tracking and auto-adjustment system
"""

import logging
import json
import time
from decimal import Decimal
from typing import Dict, List, Optional, Tuple
from collections import defaultdict, deque
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)


@dataclass
class MoralisRejection:
    """Track a Moralis rejection event"""
    address: str
    timestamp: float
    reason: str
    roi_pct: Optional[float] = None
    profit_usd: Optional[float] = None
    trades: Optional[int] = None
    discovery_mode: str = ""
    stage1_trades: int = 0
    stage1_pnl: float = 0.0


@dataclass
class MoralisAcceptance:
    """Track a Moralis acceptance event"""
    address: str
    timestamp: float
    roi_pct: float
    profit_usd: float
    trades: int
    discovery_mode: str = ""
    stage1_trades: int = 0
    stage1_pnl: float = 0.0


class MoralisFeedbackTracker:
    """Track Moralis API feedback and auto-adjust discovery thresholds"""
    
    def __init__(self, db_manager=None):
        self.db = db_manager
        
        # In-memory tracking
        self.rejections = deque(maxlen=1000)  # Keep last 1000 rejections
        self.acceptances = deque(maxlen=1000)  # Keep last 1000 acceptances
        
        # Auto-adjustment settings
        self.min_samples_for_adjustment = 10
        self.adjustment_sensitivity = 0.1  # How aggressively to adjust (0.0-1.0)
        
        # Tracked rejection reasons
        self.rejection_categories = {
            "low_roi": "ROI below minimum threshold",
            "low_profit": "Profit USD below minimum threshold", 
            "low_trades": "Trade count below minimum threshold",
            "spam_detection": "Detected as spam/bot activity",
            "api_error": "Moralis API error",
            "data_quality": "Poor data quality",
            "duplicate": "Duplicate address"
        }
    
    def track_moralis_rejection(self, address: str, reason: str, 
                              roi_pct: Optional[float] = None,
                              profit_usd: Optional[float] = None,
                              trades: Optional[int] = None,
                              discovery_mode: str = "",
                              stage1_trades: int = 0,
                              stage1_pnl: float = 0.0) -> None:
        """Track a Moralis rejection"""
        rejection = MoralisRejection(
            address=address,
            timestamp=time.time(),
            reason=reason,
            roi_pct=roi_pct,
            profit_usd=profit_usd,
            trades=trades,
            discovery_mode=discovery_mode,
            stage1_trades=stage1_trades,
            stage1_pnl=stage1_pnl
        )
        
        self.rejections.append(rejection)
        
        # Save to database if available
        if self.db:
            try:
                self.db.save_moralis_feedback({
                    'type': 'rejection',
                    'data': asdict(rejection)
                })
            except Exception as e:
                logger.debug(f"Failed to save rejection to DB: {e}")
        
        logger.debug(f"Tracked Moralis rejection: {address[:10]}... - {reason}")
    
    def track_moralis_acceptance(self, address: str, roi_pct: float,
                               profit_usd: float, trades: int,
                               discovery_mode: str = "",
                               stage1_trades: int = 0,
                               stage1_pnl: float = 0.0) -> None:
        """Track a Moralis acceptance"""
        acceptance = MoralisAcceptance(
            address=address,
            timestamp=time.time(),
            roi_pct=roi_pct,
            profit_usd=profit_usd,
            trades=trades,
            discovery_mode=discovery_mode,
            stage1_trades=stage1_trades,
            stage1_pnl=stage1_pnl
        )
        
        self.acceptances.append(acceptance)
        
        # Save to database if available
        if self.db:
            try:
                self.db.save_moralis_feedback({
                    'type': 'acceptance',
                    'data': asdict(acceptance)
                })
            except Exception as e:
                logger.debug(f"Failed to save acceptance to DB: {e}")
        
        logger.debug(f"Tracked Moralis acceptance: {address[:10]}... - ROI: {roi_pct}%")
    
    def analyze_rejection_patterns(self, mode: str = "", hours_back: int = 24) -> Dict:
        """Analyze rejection patterns to identify adjustment opportunities"""
        cutoff_time = time.time() - (hours_back * 3600)
        
        # Filter recent rejections for this mode
        recent_rejections = [
            r for r in self.rejections 
            if r.timestamp >= cutoff_time and (not mode or r.discovery_mode == mode)
        ]
        
        recent_acceptances = [
            a for a in self.acceptances
            if a.timestamp >= cutoff_time and (not mode or a.discovery_mode == mode)
        ]
        
        if not recent_rejections and not recent_acceptances:
            return {"insufficient_data": True}
        
        total_attempts = len(recent_rejections) + len(recent_acceptances)
        acceptance_rate = len(recent_acceptances) / total_attempts if total_attempts > 0 else 0
        
        # Categorize rejections
        rejection_reasons = defaultdict(int)
        for rejection in recent_rejections:
            rejection_reasons[rejection.reason] += 1
        
        # Analyze threshold issues
        analysis = {
            "total_attempts": total_attempts,
            "acceptance_rate": acceptance_rate,
            "rejection_count": len(recent_rejections),
            "acceptance_count": len(recent_acceptances),
            "rejection_reasons": dict(rejection_reasons),
            "recommendations": self._generate_recommendations(recent_rejections, recent_acceptances),
            "mode": mode,
            "hours_analyzed": hours_back
        }
        
        return analysis
    
    def _generate_recommendations(self, rejections: List[MoralisRejection], 
                                acceptances: List[MoralisAcceptance]) -> Dict:
        """Generate threshold adjustment recommendations"""
        recommendations = {
            "stage1_adjustments": {},
            "moralis_adjustments": {},
            "confidence": 0.0
        }
        
        if len(rejections) + len(acceptances) < self.min_samples_for_adjustment:
            recommendations["confidence"] = 0.0
            return recommendations
        
        # Analyze stage-1 thresholds (pre-Moralis filtering)
        if rejections:
            # If high rejection rate due to low ROI/profit, increase stage-1 thresholds
            low_roi_rejections = [r for r in rejections if r.reason == "low_roi"]
            low_profit_rejections = [r for r in rejections if r.reason == "low_profit"]
            low_trades_rejections = [r for r in rejections if r.reason == "low_trades"]
            
            rejection_rate = len(rejections) / (len(rejections) + len(acceptances))
            
            if rejection_rate > 0.8:  # More than 80% rejection rate
                if len(low_roi_rejections) > len(rejections) * 0.5:
                    # Too many low ROI rejections - increase profit threshold
                    avg_rejected_pnl = sum(r.stage1_pnl for r in low_roi_rejections if r.stage1_pnl > 0)
                    if avg_rejected_pnl > 0:
                        avg_rejected_pnl /= len([r for r in low_roi_rejections if r.stage1_pnl > 0])
                        recommended_pnl = avg_rejected_pnl * 1.5
                        recommendations["stage1_adjustments"]["min_pnl_threshold"] = recommended_pnl
                
                if len(low_trades_rejections) > len(rejections) * 0.3:
                    # Too many low trade rejections - increase trade threshold
                    avg_rejected_trades = sum(r.stage1_trades for r in low_trades_rejections if r.stage1_trades > 0)
                    if avg_rejected_trades > 0:
                        avg_rejected_trades /= len([r for r in low_trades_rejections if r.stage1_trades > 0])
                        recommended_trades = int(avg_rejected_trades * 1.3)
                        recommendations["stage1_adjustments"]["min_trades"] = recommended_trades
            
            elif rejection_rate < 0.3:  # Less than 30% rejection rate
                # Low rejection rate - could potentially lower thresholds to find more candidates
                if acceptances:
                    avg_accepted_pnl = sum(a.stage1_pnl for a in acceptances if a.stage1_pnl > 0)
                    if avg_accepted_pnl > 0:
                        avg_accepted_pnl /= len([a for a in acceptances if a.stage1_pnl > 0])
                        recommended_pnl = avg_accepted_pnl * 0.8
                        recommendations["stage1_adjustments"]["min_pnl_threshold"] = recommended_pnl
        
        # Set confidence based on sample size
        total_samples = len(rejections) + len(acceptances)
        recommendations["confidence"] = min(1.0, total_samples / (self.min_samples_for_adjustment * 3))
        
        return recommendations
    
    def get_adjustment_suggestions(self, mode: str, current_thresholds: Dict) -> Dict:
        """Get specific adjustment suggestions for a discovery mode"""
        analysis = self.analyze_rejection_patterns(mode=mode)
        
        if analysis.get("insufficient_data"):
            return {"adjustments": {}, "confidence": 0.0, "reason": "insufficient_data"}
        
        recommendations = analysis.get("recommendations", {})
        stage1_adjustments = recommendations.get("stage1_adjustments", {})
        
        if not stage1_adjustments:
            return {"adjustments": {}, "confidence": recommendations.get("confidence", 0.0), 
                   "reason": "no_adjustments_needed"}
        
        # Apply sensitivity factor
        adjustments = {}
        for key, suggested_value in stage1_adjustments.items():
            if key in current_thresholds:
                current_value = current_thresholds[key]
                
                # Apply gradual adjustment based on sensitivity
                if isinstance(current_value, (int, float)):
                    adjustment = (suggested_value - current_value) * self.adjustment_sensitivity
                    new_value = current_value + adjustment
                    
                    # Ensure reasonable bounds
                    if key == "min_trades":
                        new_value = max(1, min(50, int(new_value)))
                    elif key == "min_pnl_threshold":
                        new_value = max(0.1, min(1000.0, new_value))
                    
                    adjustments[key] = new_value
        
        return {
            "adjustments": adjustments,
            "confidence": recommendations.get("confidence", 0.0),
            "analysis": analysis,
            "reason": "feedback_based"
        }
    
    def get_rejection_summary(self, hours_back: int = 24) -> Dict:
        """Get summary of rejections for logging/dashboard"""
        cutoff_time = time.time() - (hours_back * 3600)
        
        recent_rejections = [r for r in self.rejections if r.timestamp >= cutoff_time]
        recent_acceptances = [a for a in self.acceptances if a.timestamp >= cutoff_time]
        
        # Group by mode
        by_mode = defaultdict(lambda: {"rejections": 0, "acceptances": 0, "reasons": defaultdict(int)})
        
        for rejection in recent_rejections:
            mode = rejection.discovery_mode or "unknown"
            by_mode[mode]["rejections"] += 1
            by_mode[mode]["reasons"][rejection.reason] += 1
        
        for acceptance in recent_acceptances:
            mode = acceptance.discovery_mode or "unknown"
            by_mode[mode]["acceptances"] += 1
        
        # Calculate rates
        summary = {}
        for mode, data in by_mode.items():
            total = data["rejections"] + data["acceptances"]
            acceptance_rate = data["acceptances"] / total if total > 0 else 0
            
            summary[mode] = {
                "total_attempts": total,
                "acceptance_rate": acceptance_rate,
                "rejection_rate": 1.0 - acceptance_rate,
                "top_rejection_reasons": dict(data["reasons"].most_common(3)) if hasattr(data["reasons"], 'most_common') else dict(data["reasons"])
            }
        
        return summary
"""
Market condition analysis for adaptive whale discovery
"""

import logging
import statistics
from decimal import Decimal
from typing import Dict, List, Optional, Tuple
from collections import defaultdict, deque
from web3 import Web3

logger = logging.getLogger(__name__)


class MarketConditionAnalyzer:
    """Analyzes market conditions to adapt discovery thresholds"""
    
    def __init__(self, w3: Web3, cache_manager=None):
        self.w3 = w3
        self.cache = cache_manager
        
        # Cache for market data
        self.block_activity_cache = deque(maxlen=1000)
        self.price_volatility_cache = deque(maxlen=1000)
        self.transaction_volume_cache = deque(maxlen=1000)
        
    def analyze_market_conditions(self, blocks_back: int = 1000) -> Dict:
        """Analyze current market conditions"""
        try:
            current_block = self.w3.eth.block_number
            start_block = max(0, current_block - blocks_back)
            
            logger.info(f"Analyzing market conditions over {blocks_back} blocks ({start_block} to {current_block})")
            
            # Sample blocks for analysis (every 10th block to reduce load)
            sample_blocks = range(start_block, current_block, 10)
            
            block_data = []
            transaction_counts = []
            gas_prices = []
            
            for block_num in sample_blocks:
                try:
                    block = self.w3.eth.get_block(block_num, full_transactions=False)
                    
                    tx_count = len(block.transactions)
                    avg_gas_price = block.get('baseFeePerGas', 0) or 0
                    
                    transaction_counts.append(tx_count)
                    gas_prices.append(avg_gas_price)
                    
                    block_data.append({
                        'block': block_num,
                        'tx_count': tx_count,
                        'gas_price': avg_gas_price,
                        'timestamp': block.timestamp
                    })
                    
                except Exception as e:
                    logger.debug(f"Failed to analyze block {block_num}: {e}")
                    continue
            
            if not transaction_counts:
                logger.warning("No block data available for market analysis")
                return self._default_conditions()
            
            # Calculate market metrics
            conditions = {
                'activity_level': self._calculate_activity_level(transaction_counts),
                'volatility_index': self._calculate_volatility(gas_prices),
                'liquidity_score': self._calculate_liquidity_score(block_data),
                'market_regime': self._determine_market_regime(transaction_counts, gas_prices),
                'threshold_multiplier': self._calculate_threshold_multiplier(transaction_counts, gas_prices),
                'blocks_analyzed': len(block_data),
                'timestamp': self.w3.eth.get_block('latest').timestamp
            }
            
            logger.info(f"Market conditions: {conditions['market_regime']} regime, "
                       f"activity={conditions['activity_level']:.2f}, "
                       f"volatility={conditions['volatility_index']:.2f}, "
                       f"threshold_multiplier={conditions['threshold_multiplier']:.2f}")
            
            return conditions
            
        except Exception as e:
            logger.error(f"Market condition analysis failed: {e}")
            return self._default_conditions()
    
    def _calculate_activity_level(self, transaction_counts: List[int]) -> float:
        """Calculate network activity level (0.0 to 2.0+)"""
        if not transaction_counts:
            return 1.0
        
        mean_txs = statistics.mean(transaction_counts)
        median_txs = statistics.median(transaction_counts)
        
        # Activity level relative to historical average (assume ~150 tx/block baseline)
        baseline_activity = 150
        activity_ratio = mean_txs / baseline_activity
        
        return max(0.1, min(5.0, activity_ratio))
    
    def _calculate_volatility(self, gas_prices: List[int]) -> float:
        """Calculate gas price volatility (0.0 to 2.0+)"""
        if len(gas_prices) < 2:
            return 1.0
        
        # Convert to Gwei for easier calculation
        gas_prices_gwei = [price / 1e9 for price in gas_prices if price > 0]
        
        if len(gas_prices_gwei) < 2:
            return 1.0
        
        try:
            mean_gas = statistics.mean(gas_prices_gwei)
            stdev_gas = statistics.stdev(gas_prices_gwei)
            
            if mean_gas == 0:
                return 1.0
            
            # Coefficient of variation as volatility measure
            volatility = stdev_gas / mean_gas
            
            # Normalize to 0-2 range (typical CV for gas is 0.1-0.5)
            normalized_volatility = min(2.0, max(0.1, volatility * 4))
            
            return normalized_volatility
            
        except statistics.StatisticsError:
            return 1.0
    
    def _calculate_liquidity_score(self, block_data: List[Dict]) -> float:
        """Calculate liquidity score based on consistent block filling"""
        if not block_data:
            return 1.0
        
        # Measure consistency of transaction counts
        tx_counts = [block['tx_count'] for block in block_data]
        
        if len(tx_counts) < 2:
            return 1.0
        
        try:
            mean_txs = statistics.mean(tx_counts)
            stdev_txs = statistics.stdev(tx_counts)
            
            if mean_txs == 0:
                return 0.5
            
            # Lower coefficient of variation = higher liquidity (more consistent)
            consistency = 1.0 - min(1.0, stdev_txs / mean_txs)
            
            # Combine with absolute activity level
            activity_score = min(1.0, mean_txs / 200)  # 200 tx/block = high activity
            
            liquidity_score = (consistency * 0.6) + (activity_score * 0.4)
            
            return max(0.1, min(2.0, liquidity_score))
            
        except statistics.StatisticsError:
            return 1.0
    
    def _determine_market_regime(self, transaction_counts: List[int], gas_prices: List[int]) -> str:
        """Determine current market regime"""
        activity = self._calculate_activity_level(transaction_counts)
        volatility = self._calculate_volatility(gas_prices)
        
        if activity > 1.5 and volatility > 1.3:
            return "high_activity_volatile"
        elif activity > 1.2 and volatility < 0.8:
            return "high_activity_stable"
        elif activity < 0.7 and volatility > 1.2:
            return "low_activity_volatile"
        elif activity < 0.8 and volatility < 0.8:
            return "low_activity_stable"
        else:
            return "normal"
    
    def _calculate_threshold_multiplier(self, transaction_counts: List[int], gas_prices: List[int]) -> float:
        """Calculate multiplier for adjusting discovery thresholds"""
        activity = self._calculate_activity_level(transaction_counts)
        volatility = self._calculate_volatility(gas_prices)
        
        # Base multiplier
        base_multiplier = 1.0
        
        # Adjust based on activity (high activity = raise thresholds)
        activity_adjustment = (activity - 1.0) * 0.3
        
        # Adjust based on volatility (high volatility = slightly raise thresholds)
        volatility_adjustment = (volatility - 1.0) * 0.2
        
        # Combined multiplier (range: 0.3 to 2.0)
        multiplier = base_multiplier + activity_adjustment + volatility_adjustment
        
        return max(0.3, min(2.0, multiplier))
    
    def _default_conditions(self) -> Dict:
        """Return default market conditions when analysis fails"""
        return {
            'activity_level': 1.0,
            'volatility_index': 1.0,
            'liquidity_score': 1.0,
            'market_regime': 'normal',
            'threshold_multiplier': 1.0,
            'blocks_analyzed': 0,
            'timestamp': 0
        }
    
    def get_adaptive_thresholds(self, base_min_trades: int, base_min_pnl: float, 
                              conditions: Optional[Dict] = None) -> Tuple[int, float]:
        """Get adaptive thresholds based on market conditions"""
        if conditions is None:
            conditions = self.analyze_market_conditions()
        
        multiplier = conditions['threshold_multiplier']
        
        # Adjust thresholds
        adaptive_min_trades = max(1, int(base_min_trades * multiplier))
        adaptive_min_pnl = max(0.1, base_min_pnl * multiplier)
        
        logger.debug(f"Adaptive thresholds: trades {base_min_trades}→{adaptive_min_trades}, "
                    f"pnl {base_min_pnl}→{adaptive_min_pnl:.1f} (multiplier: {multiplier:.2f})")
        
        return adaptive_min_trades, adaptive_min_pnl
"""
Adaptive whale discovery using percentile-based thresholds
"""

import logging
import statistics
from decimal import Decimal
from typing import Dict, List, Tuple, Optional
from collections import defaultdict
from web3 import Web3

logger = logging.getLogger(__name__)


class AdaptiveDiscoveryEngine:
    """Percentile-based adaptive whale discovery"""
    
    def __init__(self, w3: Web3, market_analyzer=None):
        self.w3 = w3
        self.market_analyzer = market_analyzer
        
        # Uniswap router addresses
        self.monitored_routers = {
            "0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D".lower(),  # Uniswap V2
            "0xE592427A0AEce92De3Edee1F18E0157C05861564".lower()   # Uniswap V3
        }
    
    def discover_whales_percentile(self, activity_percentile: float = 5.0, 
                                 profit_percentile: float = 25.0,
                                 blocks_back: int = 10000) -> Dict:
        """
        Discover whales using percentile-based thresholds
        
        Args:
            activity_percentile: Top X% most active addresses (e.g., 5.0 = top 5%)
            profit_percentile: Top X% most profitable addresses (e.g., 25.0 = top 25%)
            blocks_back: Number of blocks to analyze
        """
        try:
            current_block = self.w3.eth.block_number
            start_block = max(0, current_block - blocks_back)
            
            logger.info(f"Adaptive discovery: analyzing {blocks_back} blocks for "
                       f"top {activity_percentile}% activity, top {profit_percentile}% profit")
            
            # Collect all address activity
            address_stats = defaultdict(lambda: {"trades": 0, "profit": Decimal(0), "volume": Decimal(0)})
            
            # Sample every 5th block for performance
            sample_blocks = range(start_block, current_block, 5)
            total_blocks = len(list(sample_blocks))
            processed = 0
            
            for block_num in sample_blocks:
                try:
                    block = self.w3.eth.get_block(block_num, full_transactions=True)
                    
                    for tx in block.transactions:
                        if tx.to and tx.to.lower() in self.monitored_routers:
                            actor = tx["from"].lower()
                            eth_value = Decimal(tx.value) / (10**18)
                            
                            address_stats[actor]["trades"] += 1
                            address_stats[actor]["profit"] += eth_value
                            address_stats[actor]["volume"] += eth_value
                    
                    processed += 1
                    if processed % 500 == 0:
                        progress = (processed / total_blocks) * 100
                        logger.info(f"Adaptive discovery: {progress:.1f}% complete ({processed}/{total_blocks} blocks)")
                        
                except Exception as e:
                    logger.debug(f"Failed to process block {block_num}: {e}")
                    continue
            
            if not address_stats:
                logger.warning("No address activity found for percentile analysis")
                return {
                    "candidates": [],
                    "thresholds": {"trades": 0, "profit": 0},
                    "total_addresses": 0,
                    "method": "percentile"
                }
            
            # Calculate percentile thresholds
            all_addresses = list(address_stats.values())
            trade_counts = [addr["trades"] for addr in all_addresses]
            profit_amounts = [float(addr["profit"]) for addr in all_addresses]
            
            # Calculate percentile thresholds
            activity_threshold = self._calculate_percentile(trade_counts, 100 - activity_percentile)
            profit_threshold = self._calculate_percentile(profit_amounts, 100 - profit_percentile)
            
            # Apply market condition adjustments if available
            if self.market_analyzer:
                market_conditions = self.market_analyzer.analyze_market_conditions()
                multiplier = market_conditions.get('threshold_multiplier', 1.0)
                
                activity_threshold = max(1, int(activity_threshold * multiplier))
                profit_threshold = max(0.1, profit_threshold * multiplier)
                
                logger.info(f"Market-adjusted thresholds: trades≥{activity_threshold}, profit≥{profit_threshold:.2f} ETH "
                           f"(multiplier: {multiplier:.2f})")
            else:
                logger.info(f"Percentile thresholds: trades≥{activity_threshold}, profit≥{profit_threshold:.2f} ETH")
            
            # Find candidates meeting both thresholds
            candidates = []
            for address, stats in address_stats.items():
                if (stats["trades"] >= activity_threshold and 
                    float(stats["profit"]) >= profit_threshold):
                    candidates.append(address)
            
            result = {
                "candidates": candidates,
                "thresholds": {
                    "trades": activity_threshold,
                    "profit": profit_threshold
                },
                "total_addresses": len(address_stats),
                "method": "percentile",
                "percentiles": {
                    "activity": activity_percentile,
                    "profit": profit_percentile
                },
                "blocks_analyzed": processed
            }
            
            logger.info(f"Adaptive discovery found {len(candidates)} candidates from {len(address_stats)} addresses "
                       f"(activity≥{activity_threshold} trades, profit≥{profit_threshold:.2f} ETH)")
            
            return result
            
        except Exception as e:
            logger.error(f"Adaptive discovery failed: {e}")
            return {
                "candidates": [],
                "thresholds": {"trades": 0, "profit": 0},
                "total_addresses": 0,
                "method": "percentile_failed",
                "error": str(e)
            }
    
    def _calculate_percentile(self, data: List[float], percentile: float) -> float:
        """Calculate percentile value from data"""
        if not data:
            return 0.0
        
        sorted_data = sorted(data)
        k = (len(sorted_data) - 1) * (percentile / 100.0)
        f = int(k)
        c = k - f
        
        if f + 1 < len(sorted_data):
            return sorted_data[f] + c * (sorted_data[f + 1] - sorted_data[f])
        else:
            return sorted_data[f]
    
    def discover_whales_adaptive_sliding(self, base_trades: int, base_pnl: float,
                                       blocks_back: int = 5000) -> Dict:
        """
        Sliding window adaptive discovery with volatility normalization
        """
        try:
            # Get market conditions
            if self.market_analyzer:
                conditions = self.market_analyzer.analyze_market_conditions()
                adaptive_trades, adaptive_pnl = self.market_analyzer.get_adaptive_thresholds(
                    base_trades, base_pnl, conditions
                )
                
                logger.info(f"Sliding adaptive: {base_trades}→{adaptive_trades} trades, "
                           f"{base_pnl}→{adaptive_pnl:.1f} ETH (regime: {conditions['market_regime']})")
            else:
                adaptive_trades, adaptive_pnl = base_trades, base_pnl
                conditions = {}
            
            # Use standard discovery with adaptive thresholds
            current_block = self.w3.eth.block_number
            start_block = max(0, current_block - blocks_back)
            
            candidate_stats = defaultdict(lambda: {"profit": Decimal(0), "trades": 0})
            
            for block_num in range(start_block, current_block + 1):
                try:
                    block = self.w3.eth.get_block(block_num, full_transactions=True)
                    
                    for tx in block.transactions:
                        if tx.to and tx.to.lower() in self.monitored_routers:
                            actor = tx["from"].lower()
                            candidate_stats[actor]["trades"] += 1
                            candidate_stats[actor]["profit"] += Decimal(tx.value) / (10**18)
                            
                except Exception as e:
                    logger.debug(f"Failed to process block {block_num}: {e}")
                    continue
            
            # Filter with adaptive thresholds
            candidates = []
            for addr, stats in candidate_stats.items():
                if (stats["trades"] >= adaptive_trades and 
                    float(stats["profit"]) >= adaptive_pnl):
                    candidates.append(addr)
            
            return {
                "candidates": candidates,
                "thresholds": {
                    "trades": adaptive_trades,
                    "profit": adaptive_pnl
                },
                "base_thresholds": {
                    "trades": base_trades,
                    "profit": base_pnl
                },
                "total_addresses": len(candidate_stats),
                "method": "adaptive_sliding",
                "market_conditions": conditions,
                "blocks_analyzed": blocks_back
            }
            
        except Exception as e:
            logger.error(f"Adaptive sliding discovery failed: {e}")
            return {
                "candidates": [],
                "thresholds": {"trades": base_trades, "profit": base_pnl},
                "total_addresses": 0,
                "method": "adaptive_sliding_failed",
                "error": str(e)
            }
"""
Utility functions for Allocator AI
"""

from .validation import (
    validate_ethereum_address,
    validate_amount,
    validate_percentage,
    validate_positive_number,
    validate_trade_data,
    ValidationError
)
from .web3_utils import Web3Manager, TokenManager
from .math_utils import calculate_win_rate, calculate_volatility, safe_divide

__all__ = [
    "validate_ethereum_address",
    "validate_amount", 
    "validate_percentage",
    "validate_positive_number",
    "validate_trade_data",
    "ValidationError",
    "Web3Manager",
    "TokenManager",
    "calculate_win_rate",
    "calculate_volatility",
    "safe_divide"
]
"""
Mathematical utilities for Allocator AI
"""

import statistics
from decimal import Decimal
from typing import List, Union
import logging

logger = logging.getLogger(__name__)


def calculate_win_rate(pnl_list: List[Decimal]) -> Decimal:
    """Calculate win rate from PnL list"""
    if not pnl_list:
        return Decimal('0')
    
    wins = sum(1 for pnl in pnl_list if pnl > 0)
    total = len(pnl_list)
    return Decimal(str(wins)) / Decimal(str(total))


def calculate_volatility(pnl_list: List[Decimal]) -> Decimal:
    """Calculate volatility (standard deviation) from PnL list"""
    if len(pnl_list) <= 1:
        return Decimal('1')
    
    try:
        # Convert to float for statistics calculation
        float_list = [float(pnl) for pnl in pnl_list]
        stdev = statistics.pstdev(float_list)
        return Decimal(str(stdev))
    except Exception as e:
        logger.warning(f"Volatility calculation failed: {e}")
        return Decimal('1')


def calculate_sharpe_ratio(pnl_list: List[Decimal], risk_free_rate: Decimal = Decimal('0')) -> Decimal:
    """Calculate Sharpe ratio from PnL list"""
    if not pnl_list:
        return Decimal('0')
    
    try:
        mean_return = sum(pnl_list) / len(pnl_list)
        volatility = calculate_volatility(pnl_list)
        
        if volatility == 0:
            return Decimal('0')
        
        return (mean_return - risk_free_rate) / volatility
    except Exception as e:
        logger.warning(f"Sharpe ratio calculation failed: {e}")
        return Decimal('0')


def safe_divide(numerator: Union[Decimal, int, float], denominator: Union[Decimal, int, float], default: Decimal = Decimal('0')) -> Decimal:
    """Safely divide two numbers, returning default if division by zero"""
    try:
        num = Decimal(str(numerator))
        den = Decimal(str(denominator))
        
        if den == 0:
            return default
        
        return num / den
    except Exception as e:
        logger.warning(f"Safe divide failed: {e}")
        return default


def calculate_percentage_change(old_value: Decimal, new_value: Decimal) -> Decimal:
    """Calculate percentage change between two values"""
    if old_value == 0:
        return Decimal('0')
    
    return ((new_value - old_value) / old_value) * 100


def calculate_compound_growth(initial: Decimal, final: Decimal, periods: int) -> Decimal:
    """Calculate compound annual growth rate"""
    if initial <= 0 or final <= 0 or periods <= 0:
        return Decimal('0')
    
    try:
        growth_rate = (final / initial) ** (1 / periods) - 1
        return Decimal(str(growth_rate)) * 100
    except Exception as e:
        logger.warning(f"Compound growth calculation failed: {e}")
        return Decimal('0')


def calculate_max_drawdown(pnl_list: List[Decimal]) -> Decimal:
    """Calculate maximum drawdown from PnL list"""
    if not pnl_list:
        return Decimal('0')
    
    try:
        cumulative = []
        running_total = Decimal('0')
        
        for pnl in pnl_list:
            running_total += pnl
            cumulative.append(running_total)
        
        peak = cumulative[0]
        max_dd = Decimal('0')
        
        for value in cumulative:
            if value > peak:
                peak = value
            drawdown = peak - value
            if drawdown > max_dd:
                max_dd = drawdown
        
        return max_dd
    except Exception as e:
        logger.warning(f"Max drawdown calculation failed: {e}")
        return Decimal('0')


def calculate_sortino_ratio(pnl_list: List[Decimal], target_return: Decimal = Decimal('0')) -> Decimal:
    """Calculate Sortino ratio (downside deviation) from PnL list"""
    if not pnl_list:
        return Decimal('0')
    
    try:
        mean_return = sum(pnl_list) / len(pnl_list)
        
        # Calculate downside deviation
        downside_returns = [pnl for pnl in pnl_list if pnl < target_return]
        if not downside_returns:
            return Decimal('0')
        
        downside_variance = sum((pnl - target_return) ** 2 for pnl in downside_returns) / len(downside_returns)
        downside_deviation = Decimal(str(downside_variance)) ** Decimal('0.5')
        
        if downside_deviation == 0:
            return Decimal('0')
        
        return (mean_return - target_return) / downside_deviation
    except Exception as e:
        logger.warning(f"Sortino ratio calculation failed: {e}")
        return Decimal('0')


def normalize_score(score: Decimal, min_score: Decimal, max_score: Decimal) -> Decimal:
    """Normalize score to 0-1 range"""
    if max_score == min_score:
        return Decimal('0.5')
    
    normalized = (score - min_score) / (max_score - min_score)
    return max(Decimal('0'), min(Decimal('1'), normalized))


def calculate_ema(values: List[Decimal], alpha: Decimal = Decimal('0.1')) -> List[Decimal]:
    """Calculate exponential moving average"""
    if not values:
        return []
    
    ema_values = [values[0]]
    
    for i in range(1, len(values)):
        ema = alpha * values[i] + (1 - alpha) * ema_values[-1]
        ema_values.append(ema)
    
    return ema_values
"""
Web3 utilities for Allocator AI
"""

import logging
from typing import Dict, Any, Optional
from web3 import Web3
from web3.middleware import ExtraDataToPOAMiddleware
from decimal import Decimal

logger = logging.getLogger(__name__)


class Web3Manager:
    """Web3 connection manager with optimizations"""
    
    def __init__(self, rpc_url: str):
        self.rpc_url = rpc_url
        self.w3 = None
        self._connect()
    
    def _connect(self):
        """Establish Web3 connection"""
        try:
            if self.rpc_url.startswith('ws'):
                # Use LegacyWebSocketProvider with larger message limits for Erigon 3.0.17
                self.w3 = Web3(Web3.LegacyWebSocketProvider(
                    self.rpc_url,
                    websocket_kwargs={
                        'max_size': 20 * 1024 * 1024,  # 20MB message limit
                        'read_limit': 20 * 1024 * 1024,  # 20MB read buffer
                        'write_limit': 20 * 1024 * 1024,  # 20MB write buffer
                    }
                ))
            else:
                self.w3 = Web3(Web3.HTTPProvider(self.rpc_url))
            
            # Inject PoA fix (needed on Sepolia, Görli, BSC etc)
            self.w3.middleware_onion.inject(ExtraDataToPOAMiddleware, layer=0)
            
            if not self.w3.is_connected():
                raise ConnectionError(f"Failed to connect to RPC: {self.rpc_url}")
            
            logger.info(f"Connected to Web3: {self.w3.eth.chain_id}")
            
        except Exception as e:
            logger.error(f"Web3 connection failed: {e}")
            raise
    
    def is_connected(self) -> bool:
        """Check if Web3 is connected"""
        try:
            return self.w3.is_connected()
        except:
            return False
    
    def get_chain_id(self) -> Optional[int]:
        """Get chain ID"""
        try:
            return self.w3.eth.chain_id
        except:
            return None
    
    def get_gas_price(self) -> Optional[int]:
        """Get current gas price"""
        try:
            return self.w3.eth.gas_price
        except:
            return None
    
    def get_block_number(self) -> Optional[int]:
        """Get latest block number"""
        try:
            return self.w3.eth.block_number
        except:
            return None


class TokenManager:
    """Token metadata and contract management"""
    
    def __init__(self, w3: Web3, cache_manager=None):
        self.w3 = w3
        self.cache = cache_manager
        self.erc20_abi = self._load_erc20_abi()
    
    def _load_erc20_abi(self) -> list:
        """Load ERC20 ABI"""
        # Simplified ERC20 ABI for basic operations
        return [
            {
                "constant": True,
                "inputs": [],
                "name": "decimals",
                "outputs": [{"name": "", "type": "uint8"}],
                "type": "function"
            },
            {
                "constant": True,
                "inputs": [],
                "name": "symbol",
                "outputs": [{"name": "", "type": "string"}],
                "type": "function"
            },
            {
                "constant": True,
                "inputs": [],
                "name": "name",
                "outputs": [{"name": "", "type": "string"}],
                "type": "function"
            }
        ]
    
    def get_token_info(self, address: str) -> Dict[str, Any]:
        """Get token information with caching"""
        addr = Web3.to_checksum_address(address)
        
        # Check cache first
        if self.cache:
            cached_info = self.cache.get('token', addr)
            if cached_info:
                return cached_info
        
        try:
            contract = self.w3.eth.contract(address=addr, abi=self.erc20_abi)
            
            # Safe fetch metadata with validation
            try:
                decimals = contract.functions.decimals().call()
                if not isinstance(decimals, int) or decimals < 0 or decimals > 77:
                    decimals = 18
            except Exception as e:
                logger.warning(f"Failed to fetch decimals for {addr}: {e}")
                decimals = 18
            
            try:
                symbol = contract.functions.symbol().call()
                if not isinstance(symbol, str) or len(symbol) > 20:
                    symbol = addr[:6] + "…" + addr[-4:]
            except Exception as e:
                logger.warning(f"Failed to fetch symbol for {addr}: {e}")
                symbol = addr[:6] + "…" + addr[-4:]
            
            try:
                name = contract.functions.name().call()
                if not isinstance(name, str) or len(name) > 50:
                    name = symbol
            except Exception as e:
                logger.warning(f"Failed to fetch name for {addr}: {e}")
                name = symbol
            
            token_info = {
                "contract": contract,
                "decimals": decimals,
                "symbol": symbol,
                "name": name,
                "address": addr
            }
            
            # Cache the result
            if self.cache:
                self.cache.set('token', addr, token_info)
            
            return token_info
            
        except Exception as e:
            logger.error(f"Token info fetch failed for {address}: {e}")
            fallback_info = {
                "contract": None,
                "decimals": 18,
                "symbol": "UNK",
                "name": "Unknown Token",
                "address": addr
            }
            
            if self.cache:
                self.cache.set('token', addr, fallback_info)
            
            return fallback_info
    
    def format_amount(self, raw_amount: int, decimals: int) -> Decimal:
        """Convert raw onchain integer to human float"""
        return Decimal(raw_amount) / (10 ** decimals)
    
    def parse_amount(self, amount: Decimal, decimals: int) -> int:
        """Convert human float to raw onchain integer"""
        return int(amount * (10 ** decimals))
"""
Input validation utilities for Allocator AI
"""

import re
import logging
from decimal import Decimal, InvalidOperation
from typing import Union, Dict, Any
from web3 import Web3

logger = logging.getLogger(__name__)


class ValidationError(Exception):
    """Custom exception for validation errors"""
    pass


def validate_ethereum_address(address: str) -> bool:
    """Validate Ethereum address format"""
    if not address or not isinstance(address, str):
        return False
    
    # Check format: 0x + 40 hex characters
    pattern = r'^0x[a-fA-F0-9]{40}$'
    if not re.match(pattern, address):
        return False
    
    # Additional checksum validation
    try:
        # This will validate checksum if present
        return Web3.is_address(address)
    except:
        return False


def validate_amount(amount: Union[str, int, float, Decimal]) -> bool:
    """Validate trade amount is reasonable"""
    try:
        amount = Decimal(str(amount))
        # Must be positive and less than 1 million ETH (safety limit)
        return amount > 0 and amount < Decimal('1000000')
    except (ValueError, TypeError, InvalidOperation):
        return False


def validate_percentage(value: Union[str, int, float, Decimal]) -> bool:
    """Validate percentage values (0-100)"""
    try:
        value = Decimal(str(value))
        return value >= 0 and value <= 100
    except (ValueError, TypeError, InvalidOperation):
        return False


def validate_positive_number(value: Union[str, int, float, Decimal]) -> bool:
    """Validate positive numbers"""
    try:
        value = Decimal(str(value))
        return value >= 0
    except (ValueError, TypeError, InvalidOperation):
        return False


def safe_validate(func, *args, **kwargs):
    """Safely execute validation function with error handling"""
    try:
        return func(*args, **kwargs)
    except Exception as e:
        logger.warning(f"Validation error in {func.__name__}: {e}")
        return False


def validate_trade_data(trade_data: Dict[str, Any]) -> bool:
    """Comprehensive validation of trade data"""
    required_fields = ['from', 'to', 'token_in', 'token_out', 'amount_in']
    
    # Check required fields
    for field in required_fields:
        if field not in trade_data:
            logger.warning(f"Missing required field: {field}")
            return False
    
    # Validate addresses
    if not validate_ethereum_address(trade_data['from']):
        logger.warning(f"Invalid 'from' address: {trade_data['from']}")
        return False
    
    if not validate_ethereum_address(trade_data['to']):
        logger.warning(f"Invalid 'to' address: {trade_data['to']}")
        return False
    
    # Validate amounts
    if not validate_amount(trade_data['amount_in']):
        logger.warning(f"Invalid amount_in: {trade_data['amount_in']}")
        return False
    
    # Validate token data structure
    if not isinstance(trade_data.get('token_in'), dict) or not isinstance(trade_data.get('token_out'), dict):
        logger.warning("Invalid token data structure")
        return False
    
    return True


def validate_config_data(config_data: Dict[str, Any]) -> bool:
    """Validate configuration data"""
    required_fields = ['web3_rpc', 'capital', 'base_risk', 'max_slippage', 'min_profit', 'gas_boost']
    
    for field in required_fields:
        if field not in config_data:
            logger.error(f"Missing required config field: {field}")
            return False
    
    # Validate numeric fields
    numeric_fields = {
        'capital': (0, 1000000),
        'base_risk': (0, 1),
        'max_slippage': (0, 0.1),
        'min_profit': (0, 0.1),
        'gas_boost': (1, 5)
    }
    
    for field, (min_val, max_val) in numeric_fields.items():
        try:
            value = Decimal(str(config_data[field]))
            if not (min_val <= value <= max_val):
                logger.error(f"Invalid {field}: {value} (must be between {min_val} and {max_val})")
                return False
        except (ValueError, TypeError, InvalidOperation):
            logger.error(f"Invalid {field} value: {config_data[field]}")
            return False
    
    return True
#!/usr/bin/env python3
"""
Quick script to refresh whale metrics
"""

import sys
import logging
from pathlib import Path

# Add the allocator package to the path
sys.path.insert(0, str(Path(__file__).parent))

from allocator.config import Config
from allocator.data import DatabaseManager
from allocator.core import WhaleTracker
from allocator.data.cache import CacheManager

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("whale_refresh")

def main():
    try:
        # Load configuration
        config = Config.from_env_and_file("config.json")
        
        # Initialize components
        db_manager = DatabaseManager(config.database.file_path)
        cache_manager = CacheManager()
        
        # Initialize whale tracker
        whale_tracker = WhaleTracker(
            config.moralis_api_key,
            cache_manager,
            db_manager,
            config.discovery
        )
        
        # Load existing whales from database
        db_whales = db_manager.get_all_whales()
        for whale_data in db_whales:
            whale_tracker.tracked_whales.add(whale_data[0])  # Add address to tracked set
        
        logger.info(f"Found {len(whale_tracker.tracked_whales)} tracked whales")
        
        # Refresh metrics
        whale_tracker.refresh_all_whale_metrics(simulate_trades=True)
        
        logger.info("✅ Whale metrics refresh completed!")
        
    except Exception as e:
        logger.error(f"❌ Error refreshing whale metrics: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
Recalculate Discarded Whales Script

This script recalculates all existing whales in the database and marks those
that don't meet minimum requirements (20 trades, 5 tokens) as discarded.
"""

import sys
import os
import logging
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from allocator.data.database import DatabaseManager

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def recalculate_discarded_whales():
    """Recalculate all whales and mark those that don't meet requirements as discarded"""
    
    logger.info("Starting discarded whales recalculation...")
    
    # Initialize database
    db_manager = DatabaseManager("whales.db")
    
    # Get all whales from database (including already discarded ones)
    all_whales = db_manager.conn.execute("SELECT * FROM whales").fetchall()
    logger.info(f"Found {len(all_whales)} total whales in database")
    
    # Separate discarded and non-discarded whales
    non_discarded = [w for w in all_whales if w[11] is None]  # discarded_timestamp is None
    already_discarded = [w for w in all_whales if w[11] is not None]
    
    logger.info(f"  - {len(non_discarded)} non-discarded whales")
    logger.info(f"  - {len(already_discarded)} already discarded whales")
    
    # Process non-discarded whales
    newly_discarded = 0
    valid_whales = 0
    
    logger.info("\nProcessing non-discarded whales...")
    
    for i, whale_data in enumerate(non_discarded, 1):
        address = whale_data[0]
        trades = whale_data[3] if len(whale_data) > 3 else 0
        
        logger.info(f"Processing whale {i}/{len(non_discarded)}: {address[:10]}... (trades: {trades})")
        
        try:
            # Get token count for this whale
            token_breakdown = db_manager.get_whale_token_breakdown(address)
            token_count = len([t for t in token_breakdown if t[0] != "PROCESSED"])  # Exclude PROCESSED marker
            
            logger.info(f"  Token count: {token_count}")
            
            # Check minimum requirements
            MIN_TRADES = 20
            MIN_TOKENS = 5
            
            if trades < MIN_TRADES or token_count < MIN_TOKENS:
                reason = f"< {MIN_TRADES} trades ({trades}) or < {MIN_TOKENS} tokens ({token_count})"
                logger.info(f"  ❌ Does not meet requirements: {reason}")
                
                # Mark as discarded
                success = db_manager.mark_whale_discarded(address, reason)
                if success:
                    newly_discarded += 1
                    logger.info(f"  ✅ Marked as discarded")
                else:
                    logger.error(f"  ❌ Failed to mark as discarded")
            else:
                logger.info(f"  ✅ Meets requirements (trades: {trades}, tokens: {token_count})")
                valid_whales += 1
                
        except Exception as e:
            logger.error(f"  ❌ Error processing whale {address}: {e}")
            continue
    
    # Summary
    logger.info(f"\n{'='*60}")
    logger.info("RECALCULATION SUMMARY:")
    logger.info(f"  Total whales processed: {len(non_discarded)}")
    logger.info(f"  Valid whales: {valid_whales}")
    logger.info(f"  Newly discarded: {newly_discarded}")
    logger.info(f"  Already discarded: {len(already_discarded)}")
    logger.info(f"  Total discarded: {len(already_discarded) + newly_discarded}")
    
    # Show some examples of discarded whales
    if newly_discarded > 0:
        logger.info(f"\nRecently discarded whales:")
        recent_discarded = db_manager.conn.execute("""
            SELECT address, trades, score, discarded_timestamp 
            FROM whales 
            WHERE discarded_timestamp IS NOT NULL 
            ORDER BY discarded_timestamp DESC 
            LIMIT 10
        """).fetchall()
        
        for address, trades, score, discarded_time in recent_discarded:
            logger.info(f"  {address[:10]}... | trades: {trades} | score: {score:.2f} | discarded: {discarded_time}")
    
    logger.info(f"\nRecalculation completed!")
    logger.info(f"Dashboard will now show only {valid_whales} valid whales.")

def show_discarded_stats():
    """Show statistics about discarded whales"""
    
    logger.info("Discarded Whales Statistics:")
    
    db_manager = DatabaseManager("whales.db")
    
    # Get discarded whales
    discarded_whales = db_manager.get_discarded_whales()
    
    if not discarded_whales:
        logger.info("  No discarded whales found")
        return
    
    logger.info(f"  Total discarded whales: {len(discarded_whales)}")
    
    # Analyze reasons for discarding
    low_trades = 0
    low_tokens = 0
    both_low = 0
    
    for whale_data in discarded_whales:
        address = whale_data[0]
        trades = whale_data[3] if len(whale_data) > 3 else 0
        
        # Get token count
        token_breakdown = db_manager.get_whale_token_breakdown(address)
        token_count = len([t for t in token_breakdown if t[0] != "PROCESSED"])
        
        if trades < 20 and token_count < 5:
            both_low += 1
        elif trades < 20:
            low_trades += 1
        elif token_count < 5:
            low_tokens += 1
    
    logger.info(f"  - Low trades only (< 20): {low_trades}")
    logger.info(f"  - Low tokens only (< 5): {low_tokens}")
    logger.info(f"  - Both low: {both_low}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Recalculate discarded whales")
    parser.add_argument("--stats", action="store_true", 
                       help="Show discarded whales statistics only")
    parser.add_argument("--recalculate", action="store_true", 
                       help="Recalculate and mark whales as discarded")
    
    args = parser.parse_args()
    
    if args.stats:
        show_discarded_stats()
    elif args.recalculate:
        recalculate_discarded_whales()
    else:
        # Default: show stats then ask for confirmation
        show_discarded_stats()
        print("\n" + "="*60)
        response = input("Do you want to recalculate and mark whales as discarded? (y/N): ")
        if response.lower() in ['y', 'yes']:
            recalculate_discarded_whales()
        else:
            logger.info("Recalculation cancelled.")
"""
Main entry point for Allocator AI - Modular Version
"""

import os
import sys
import time
import threading
import logging
import argparse
import json
from pathlib import Path

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # If python-dotenv is not installed, try to load manually
    env_file = Path(__file__).parent / ".env"
    if env_file.exists():
        with open(env_file) as f:
            for line in f:
                if line.strip() and not line.startswith('#') and '=' in line:
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value

# Add the allocator package to the path
sys.path.insert(0, str(Path(__file__).parent))

from allocator.config import Config
from allocator.data import DatabaseManager, CacheManager
from allocator.core import WhaleTracker, TradeExecutor, RiskManager, AllocationEngine
from allocator.monitoring import MempoolWatcher
from allocator.web import create_app
from allocator.utils.web3_utils import Web3Manager, TokenManager
from allocator.analytics.adaptive_discovery import AdaptiveDiscoveryEngine
from allocator.analytics.market_conditions import MarketConditionAnalyzer

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("allocator.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("allocator")


class AllocatorAI:
    """Main Allocator AI application class"""
    
    def __init__(self, config_file: str = "config.json"):
        # Load configuration
        self.config = Config.from_env_and_file(config_file)
        self.config.validate()
        
        # Initialize components
        self.db_manager = DatabaseManager(self.config.database.file_path)
        self.cache_manager = CacheManager()
        
        # Create adaptive candidates table
        self._create_adaptive_candidates_table()
        
        # Initialize Web3
        self.web3_manager = Web3Manager(self.config.web3.rpc_url)
        self.token_manager = TokenManager(self.web3_manager.w3, self.cache_manager)
        
        # Initialize core components
        self.whale_tracker = WhaleTracker(
            self.config.moralis_api_key,
            self.cache_manager,
            self.db_manager,
            self.config.discovery
        )
        
        self.risk_manager = RiskManager(
            self.config.trading.base_risk,
            max_risk_multiplier=3.0,
            min_risk_multiplier=0.25,
            db_manager=self.db_manager
        )
        
        self.allocation_engine = AllocationEngine(
            self.config.trading.capital,
            self.config.trading.base_risk
        )
        
        # Initialize trade executor (will be set up when wallet is loaded)
        self.trade_executor = None
        
        # Initialize monitoring
        self.mempool_watcher = None
        
        # Application state
        self.is_running = False
        self.mode = "LIVE"  # Will be set by command line args
    
    def _create_adaptive_candidates_table(self):
        """Create table for adaptive discovery candidates"""
        with self.db_manager.lock:
            self.db_manager.conn.execute("""
                CREATE TABLE IF NOT EXISTS adaptive_candidates (
                    address TEXT PRIMARY KEY,
                    activity_score INTEGER,
                    profit_eth REAL,
                    trades INTEGER,
                    discovered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    processed_at TIMESTAMP,
                    moralis_validated BOOLEAN DEFAULT FALSE,
                    moralis_roi_pct REAL,
                    moralis_profit_usd REAL,
                    moralis_trades INTEGER,
                    status TEXT DEFAULT 'discovered'
                )
            """)
            self.db_manager.conn.commit()
    
    def _store_adaptive_candidate(self, address: str, discovery_result: dict) -> bool:
        """Store candidate in database if not already exists"""
        try:
            # Check if already exists
            existing = self.db_manager.conn.execute(
                "SELECT address FROM adaptive_candidates WHERE address = ?", (address,)
            ).fetchone()
            
            if existing:
                logger.debug(f"Candidate {address[:10]}... already exists in database")
                return False
            
            # Get candidate stats from discovery result
            thresholds = discovery_result.get("thresholds", {})
            activity_threshold = thresholds.get("trades", 0)
            profit_threshold = thresholds.get("profit", 0)
            
            # Store candidate with initial status
            self.db_manager.conn.execute("""
                INSERT INTO adaptive_candidates 
                (address, activity_score, profit_eth, trades, status, moralis_validated)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (address, activity_threshold, profit_threshold, activity_threshold, "discovered", False))
            
            self.db_manager.conn.commit()
            logger.info(f"Stored new candidate: {address[:10]}...")
            return True
            
        except Exception as e:
            logger.error(f"Failed to store candidate {address}: {e}")
            return False
    
    def _update_adaptive_candidate_status(self, address: str, status: str):
        """Update candidate status"""
        try:
            self.db_manager.conn.execute("""
                UPDATE adaptive_candidates 
                SET status = ?, processed_at = CURRENT_TIMESTAMP
                WHERE address = ?
            """, (status, address))
            self.db_manager.conn.commit()
        except Exception as e:
            logger.error(f"Failed to update status for {address}: {e}")
    
    def _update_adaptive_candidate_moralis(self, address: str, moralis_data: dict, status: str):
        """Update candidate with Moralis data"""
        try:
            self.db_manager.conn.execute("""
                UPDATE adaptive_candidates 
                SET moralis_validated = ?,
                    moralis_roi_pct = ?,
                    moralis_profit_usd = ?,
                    moralis_trades = ?,
                    status = ?,
                    processed_at = CURRENT_TIMESTAMP
                WHERE address = ?
            """, (
                status == "validated",
                float(moralis_data["realized_pct"]),
                float(moralis_data["realized_usd"]),
                moralis_data["total_trades"],
                status,
                address
            ))
            self.db_manager.conn.commit()
        except Exception as e:
            logger.error(f"Failed to update Moralis data for {address}: {e}")
    
    def setup_wallet(self, wallet_file: str = "wallet.json"):
        """Setup wallet and trade executor"""
        try:
            from eth_account import Account
            
            # Load wallet
            with open(wallet_file, 'r') as f:
                keyfile = json.load(f)
            
            password = self.config.wallet_password
            private_key = Account.decrypt(keyfile, password)
            account = Account.from_key(private_key)
            wallet_address = account.address
            
            logger.info(f"Loaded wallet: {wallet_address}")
            
            # Initialize trade executor
            self.trade_executor = TradeExecutor(
                self.web3_manager.w3,
                wallet_address,
                private_key,
                self.token_manager,
                self.config.trading.gas_boost
            )
            
            return wallet_address
            
        except Exception as e:
            logger.error(f"Failed to setup wallet: {e}")
            raise
    
    def setup_monitoring(self):
        """Setup mempool monitoring with separate WebSocket connection"""
        from allocator.utils.web3_utils import Web3Manager
        
        tracked_whales = set(self.config.tracked_whales)
        
        # Create separate WebSocket connection for mempool monitoring
        # to avoid conflicts with discovery process
        mempool_web3 = Web3Manager(self.config.web3.rpc_url)
        
        self.mempool_watcher = MempoolWatcher(
            mempool_web3.w3,
            tracked_whales,
            self.handle_whale_trade
        )
        
        logger.info(f"Setup monitoring for {len(tracked_whales)} whales with separate WebSocket connection")
    
    def handle_whale_trade(self, trade_data: dict):
        """Handle incoming whale trade"""
        try:
            whale_address = trade_data.get("whale_address", "").lower()
            
            # Check if we should follow this whale
            if not self.whale_tracker.should_follow_whale(
                whale_address,
                self.config.trading.min_moralis_roi_pct,
                self.config.trading.min_moralis_profit_usd,
                self.config.trading.min_moralis_trades
            ):
                logger.info(f"Skipping trade from whale {whale_address} - doesn't meet criteria")
                return
            
            # Get whale stats for allocation decision
            whale_stats = self.whale_tracker.get_whale_stats(whale_address)
            risk_profile = self.risk_manager.get_whale_risk_profile(whale_address)
            
            # Make allocation decision
            allocation_decision = self.allocation_engine.decide_allocation(
                trade_data,
                whale_stats.__dict__ if whale_stats else None,
                risk_profile["risk_multiplier"]
            )
            
            if not allocation_decision.should_trade:
                logger.info(f"Skipping trade: {allocation_decision.reason}")
                return
            
            # Check risk limits
            if not self.risk_manager.should_execute_trade(
                whale_address, 
                allocation_decision.allocation_size
            ):
                logger.warning(f"Trade rejected by risk manager for whale {whale_address}")
                return
            
            # Execute trade if not in dry run mode
            if self.mode == "LIVE" and self.trade_executor:
                result = self.trade_executor.execute_trade(trade_data, allocation_decision.allocation_size)
                if result:
                    tx_hash, receipt = result
                    logger.info(f"Executed trade: {tx_hash}")
                    
                    # Log trade to database
                    self._log_trade(trade_data, allocation_decision, tx_hash)
                else:
                    logger.error("Trade execution failed")
            else:
                logger.info(f"[{self.mode}] Would execute trade: {allocation_decision.allocation_size} ETH")
                self._log_trade(trade_data, allocation_decision, "SIMULATED")
            
        except Exception as e:
            logger.error(f"Error handling whale trade: {e}", exc_info=True)
    
    def _log_trade(self, trade_data: dict, allocation_decision, tx_hash: str):
        """Log trade to database"""
        try:
            trade_log = {
                "actor": "allocator",
                "whale": trade_data.get("whale_address", ""),
                "router": trade_data.get("to", ""),
                "path": f"{trade_data.get('token_in', {}).get('symbol', '?')} -> {trade_data.get('token_out', {}).get('symbol', '?')}",
                "side": "buy",  # Simplified
                "amount_in": float(allocation_decision.allocation_size),
                "amount_out": 0,  # Would be filled after execution
                "token_in": trade_data.get("token_in", {}).get("symbol", "?"),
                "token_out": trade_data.get("token_out", {}).get("symbol", "?"),
                "price_impact": 0,
                "gas_cost": 0,
                "pnl": 0,  # Would be calculated after execution
                "cum_pnl": 0,
                "risk_mult": float(allocation_decision.allocation_size / 1000),  # Simplified
                "mode": self.mode,
                "tx_hash": tx_hash
            }
            
            self.db_manager.save_trade(trade_log)
            
        except Exception as e:
            logger.error(f"Failed to log trade: {e}")
    
    def start_discovery(self):
        """Start simple, reliable sequential whale discovery"""
        
        def run_discovery_mode_http(mode: str):
            """Run discovery mode using HTTP connection (no WebSocket conflicts)"""
            try:
                from allocator.utils.web3_utils import Web3Manager
                from web3 import Web3
                
                logger.info(f"Starting discovery with mode: {mode}")
                start_time = time.time()
                
                # Create HTTP connection for this discovery mode (no async conflicts)
                # Try HTTP on port 8545 first, fallback to same port as WebSocket
                ws_url = self.config.web3.rpc_url
                if ':8546' in ws_url:
                    http_rpc = ws_url.replace('ws://', 'http://').replace(':8546', ':8545')
                else:
                    http_rpc = ws_url.replace('ws://', 'http://').replace('wss://', 'https://')
                
                try:
                    discovery_w3 = Web3(Web3.HTTPProvider(http_rpc))
                    # Test the connection
                    discovery_w3.eth.block_number
                    logger.info(f"Mode {mode}: Using HTTP connection {http_rpc}")
                except Exception as e:
                    # Fallback: try HTTP on the same port as WebSocket
                    logger.warning(f"Mode {mode}: HTTP port 8545 failed ({e}), trying same port as WebSocket")
                    http_rpc_fallback = ws_url.replace('ws://', 'http://').replace('wss://', 'https://')
                    discovery_w3 = Web3(Web3.HTTPProvider(http_rpc_fallback))
                    discovery_w3.eth.block_number  # Test this connection too
                    logger.info(f"Mode {mode}: Using HTTP connection {http_rpc_fallback}")
                
                # Get candidates from blockchain scanning
                candidate_whales = self.whale_tracker.discover_whales_from_blocks(
                    discovery_w3,
                    mode,
                    simulate=True  # Always simulate to get candidates only
                )
                
                scan_duration = time.time() - start_time
                logger.info(f"Discovery mode {mode} found {len(candidate_whales)} candidate whales in {scan_duration:.1f}s")
                
                # Immediately validate with Moralis (unless in DRY_RUN_WO_MOR mode)
                validated_whales = []
                if self.mode == "DRY_RUN_WO_MOR":
                    logger.info(f"Mode {mode}: Skipping Moralis validation (DRY_RUN_WO_MOR)")
                    validated_whales = candidate_whales  # Return candidates without validation
                else:
                    if len(candidate_whales) > 0:
                        logger.info(f"Mode {mode}: Validating {len(candidate_whales)} candidates with Moralis...")
                        
                        for whale_address in candidate_whales:
                            try:
                                # Check Moralis PnL to see if whale is worth tracking
                                if self.whale_tracker.bootstrap_whale_from_moralis(
                                    whale_address,
                                    min_roi_pct=self.config.trading.min_moralis_roi_pct,
                                    min_profit_usd=self.config.trading.min_moralis_profit_usd,
                                    min_trades=self.config.trading.min_moralis_trades
                                ):
                                    validated_whales.append(whale_address)
                                    logger.info(f"Mode {mode}: Whale {whale_address[:10]}... validated and added to tracking")
                            except Exception as e:
                                logger.warning(f"Mode {mode}: Failed to validate whale {whale_address[:10]}...: {e}")
                    
                    logger.info(f"Mode {mode}: {len(validated_whales)}/{len(candidate_whales)} whales validated by Moralis")
                
                total_duration = time.time() - start_time
                logger.info(f"Discovery mode {mode} completed in {total_duration:.1f}s")
                return mode, validated_whales
                
            except Exception as e:
                logger.error(f"Discovery mode {mode} failed: {e}")
                return mode, []

        def discovery_worker():
            while self.is_running:
                try:
                    # Only run adaptive discovery (hardcoded modes commented out)
                    discovery_modes = []
                    
                    # Add adaptive discovery mode if enabled
                    adaptive_config = getattr(self.config.discovery, 'adaptive_discovery', None)
                    if adaptive_config and getattr(adaptive_config, 'enabled', False):
                        discovery_modes.append('adaptive_percentile')
                    
                    # Comment out hardcoded discovery modes to focus on adaptive discovery
                    # discovery_modes = list(self.config.discovery.modes)
                    # discovery_modes.extend(['bot_hunter', 'active_whale', 'quick_profit_whale'])
                    
                    if not discovery_modes:
                        logger.info("No discovery modes enabled, skipping discovery round")
                        time.sleep(60)  # Wait 1 minute before checking again
                        continue
                    
                    logger.info(f"Starting discovery for modes: {discovery_modes}")
                    
                    # Run discovery modes
                    all_validated_whales = {}
                    
                    for mode in discovery_modes:
                        try:
                            if mode == 'adaptive_percentile':
                                # Run adaptive discovery
                                result_mode, validated_whales = self._run_adaptive_discovery_mode()
                                all_validated_whales[result_mode] = validated_whales
                                logger.info(f"Discovery mode {result_mode} completed successfully")
                            else:
                                # Run standard discovery (commented out)
                                # result_mode, validated_whales = run_discovery_mode_http(mode)
                                # all_validated_whales[result_mode] = validated_whales
                                logger.info(f"Standard discovery mode {mode} is disabled")
                        except Exception as e:
                            logger.error(f"Discovery mode {mode} exception: {e}")
                            all_validated_whales[mode] = []
                    
                    # Summary of the discovery round
                    total_validated = sum(len(whales) for whales in all_validated_whales.values())
                    if self.mode == "DRY_RUN_WO_MOR":
                        logger.info(f"Discovery round completed. Total candidates found: {total_validated} (not validated with Moralis)")
                    else:
                        logger.info(f"Discovery round completed. Total validated whales: {total_validated}")
                    
                    # Log detailed results per mode
                    for mode, whales in all_validated_whales.items():
                        if len(whales) > 0:
                            whale_preview = [whale[:10] + "..." for whale in whales[:3]]
                            logger.info(f"Mode {mode} result: {len(whales)} whales {whale_preview}")
                    
                    # Token data fetching is now handled immediately during validation
                    
                    # Wait before next discovery round
                    refresh_interval = self.config.discovery.refresh_interval
                    logger.info(f"Discovery round completed. Waiting {refresh_interval} seconds before next round...")
                    time.sleep(refresh_interval)
                    logger.info("Starting next discovery round...")
                    
                except Exception as e:
                    logger.error(f"Discovery worker error: {e}")
                    time.sleep(60)  # Wait before retrying
        
        discovery_thread = threading.Thread(target=discovery_worker, daemon=True)
        discovery_thread.start()
        logger.info(f"Started PARALLEL whale discovery for {len(self.config.discovery.modes)} modes using HTTP connections")
    
    
    def _run_adaptive_discovery_mode(self):
        """Run adaptive percentile-based discovery mode with automatic validation and token fetching"""
        try:
            logger.info("Starting discovery with mode: adaptive_percentile")
            start_time = time.time()
            
            # Get adaptive configuration
            adaptive_config = getattr(self.config.discovery, 'adaptive_discovery', None)
            if not adaptive_config:
                logger.warning("Adaptive discovery config not found")
                return "adaptive_percentile", []
            
            # Initialize adaptive components if needed
            if self.whale_tracker.market_analyzer is None:
                self.whale_tracker.market_analyzer = MarketConditionAnalyzer(self.web3_manager.w3, self.whale_tracker.cache)
            
            if self.whale_tracker.adaptive_engine is None:
                self.whale_tracker.adaptive_engine = AdaptiveDiscoveryEngine(self.web3_manager.w3, self.whale_tracker.market_analyzer)
            
            # Get percentile configuration
            percentile_config = getattr(adaptive_config, "percentile_mode", {}) or {}
            if not percentile_config.get("enabled", False):
                logger.info("Adaptive percentile discovery is disabled")
                return "adaptive_percentile", []
            
            activity_percentile = percentile_config.get("activity_percentile", 5.0)
            profit_percentile = percentile_config.get("profit_percentile", 25.0)
            blocks_back = percentile_config.get("blocks_back", 10000)
            
            logger.info(f"Running adaptive discovery: top {activity_percentile}% activity, "
                       f"top {profit_percentile}% profit over {blocks_back} blocks")
            
            # Run adaptive discovery
            result = self.whale_tracker.adaptive_engine.discover_whales_percentile(
                activity_percentile=activity_percentile,
                profit_percentile=profit_percentile,
                blocks_back=blocks_back
            )
            
            candidates = result.get("candidates", [])
            logger.info(f"Found {len(candidates)} adaptive candidates")
            
            # Store candidates in database and get candidates to process
            new_candidates = []
            for candidate in candidates:
                if self._store_adaptive_candidate(candidate, result):
                    new_candidates.append(candidate)
            
            logger.info(f"Stored {len(new_candidates)} new candidates in database")
            
            # Get candidates to process (both new and existing unvalidated ones)
            candidates_to_process = []
            
            # Add new candidates
            candidates_to_process.extend(new_candidates)
            
            # Add existing unvalidated candidates
            existing_unvalidated = self.db_manager.conn.execute("""
                SELECT address FROM adaptive_candidates 
                WHERE moralis_validated = FALSE 
                AND status IN ('discovered', 'failed_moralis', 'error')
                ORDER BY discovered_at 
            """).fetchall()
            
            for (address,) in existing_unvalidated:
                if address not in candidates_to_process:
                    candidates_to_process.append(address)
            
            logger.info(f"Processing {len(candidates_to_process)} candidates (new: {len(new_candidates)}, existing: {len(candidates_to_process) - len(new_candidates)})")
            
            # Validate candidates with Moralis (like test_adaptive_discovery.py)
            validated_whales = []
            if candidates_to_process and self.mode != "DRY_RUN_WO_MOR":
                logger.info(f"Validating {len(candidates_to_process)} candidates with Moralis...")
                
                for i, candidate in enumerate(candidates_to_process):
                    try:
                        logger.info(f"Validating candidate {i+1}/{len(candidates_to_process)}: {candidate[:10]}...")
                        candidate_start_time = time.time()
                        
                        # Fetch Moralis data
                        moralis_data = self.whale_tracker.fetch_moralis_data(candidate)
                        if not moralis_data:
                            logger.warning(f"Failed to fetch Moralis data for {candidate[:10]}...")
                            self._update_adaptive_candidate_status(candidate, "failed_moralis")
                            continue
                        
                        # Check if meets criteria
                        min_roi_pct = self.config.trading.min_moralis_roi_pct
                        min_profit_usd = self.config.trading.min_moralis_profit_usd
                        min_trades = self.config.trading.min_moralis_trades
                        
                        if (moralis_data["realized_pct"] < min_roi_pct or 
                            moralis_data["realized_usd"] < min_profit_usd or 
                            moralis_data["total_trades"] < min_trades):
                            logger.info(f"Candidate {candidate[:10]}... rejected: "
                                      f"{moralis_data['realized_pct']}% ROI, "
                                      f"${moralis_data['realized_usd']} profit, "
                                      f"{moralis_data['total_trades']} trades")
                            self._update_adaptive_candidate_moralis(candidate, moralis_data, "rejected")
                            continue
                        
                        # Add to main whales table
                        if self.whale_tracker.bootstrap_whale_from_moralis(candidate):
                            validated_whales.append(candidate)
                            self._update_adaptive_candidate_moralis(candidate, moralis_data, "validated")
                            
                            # Immediately fetch token data (like test_adaptive_discovery.py)
                            try:
                                logger.info(f"Fetching token data for validated whale {candidate[:10]}...")
                                token_start_time = time.time()
                                self.whale_tracker.fetch_token_data_from_moralis(candidate)
                                self._update_adaptive_candidate_status(candidate, "tokens_fetched")
                                token_elapsed = time.time() - token_start_time
                                logger.info(f"✅ Token data fetched for {candidate[:10]}... ({token_elapsed:.1f}s)")
                            except Exception as e:
                                logger.error(f"Error fetching token data for {candidate[:10]}...: {e}")
                                self._update_adaptive_candidate_status(candidate, "token_error")
                            
                            candidate_elapsed = time.time() - candidate_start_time
                            logger.info(f"✅ Candidate {candidate[:10]}... validated and added to tracking ({candidate_elapsed:.1f}s)")
                        else:
                            logger.info(f"❌ Candidate {candidate[:10]}... rejected by bootstrap_whale_from_moralis")
                            self._update_adaptive_candidate_moralis(candidate, moralis_data, "rejected")
                        
                        # Small delay to respect rate limits
                        time.sleep(0.5)
                        
                    except Exception as e:
                        logger.error(f"Error validating {candidate[:10]}...: {e}")
                        self._update_adaptive_candidate_status(candidate, "error")
                
                logger.info(f"Validated {len(validated_whales)} candidates successfully")
            elif self.mode == "DRY_RUN_WO_MOR":
                logger.info("Mode adaptive_percentile: Skipping Moralis validation (DRY_RUN_WO_MOR)")
                validated_whales = candidates_to_process
            
            # Log detailed summary like the test script
            if validated_whales:
                whale_preview = [whale[:10] + "..." for whale in validated_whales[:3]]
                logger.info(f"Adaptive discovery result: {len(validated_whales)} whales validated {whale_preview}")
            
            # Return validated whales like the old discovery modes
            total_duration = time.time() - start_time
            logger.info(f"Discovery mode adaptive_percentile completed in {total_duration:.1f}s")
            return "adaptive_percentile", validated_whales
            
        except Exception as e:
            logger.error(f"Discovery mode adaptive_percentile failed: {e}")
            return "adaptive_percentile", []
    
    def start_monitoring(self):
        """Start mempool monitoring"""
        if self.mempool_watcher:
            # Determine mempool usage based on mode
            use_mempool = self.mode in ["LIVE", "DRY_RUN", "DRY_RUN_WO_MOR", "TEST"]
            self.mempool_watcher.start_watching(use_mempool=use_mempool)
            
            monitoring_type = "mempool" if use_mempool else "block"
            logger.info(f"Started {monitoring_type} monitoring for mode: {self.mode}")
    
    def start_dashboard(self, host: str = "0.0.0.0", port: int = 8080):
        """Start web dashboard"""
        try:
            logger.info("Attempting to start dashboard...")
            app = create_app(
                self.whale_tracker,
                self.risk_manager,
                self.db_manager,
                self.mode
            )
            logger.info("Dashboard app created successfully")
            
            def run_dashboard():
                try:
                    logger.info(f"Starting Flask app on {host}:{port}")
                    app.run(host=host, port=port, debug=False, use_reloader=False)
                except Exception as e:
                    logger.error(f"Dashboard runtime error: {e}", exc_info=True)
            
            dashboard_thread = threading.Thread(target=run_dashboard, daemon=True)
            dashboard_thread.start()
            logger.info(f"Started dashboard on http://{host}:{port}")
        except Exception as e:
            logger.error(f"Failed to start dashboard: {e}", exc_info=True)
    
    def run(self, mode: str = "LIVE", use_mempool: bool = True):
        """Run the Allocator AI system"""
        self.mode = mode
        self.is_running = True
        
        logger.info(f"Starting Allocator AI in {mode} mode")
        
        try:
            # Setup wallet (skip in test modes if wallet.json doesn't exist)
            if self.mode == "LIVE" or os.path.exists("wallet.json"):
                self.setup_wallet()
            else:
                logger.info(f"Skipping wallet setup for {self.mode} mode (no wallet.json found)")
            
            # Setup monitoring
            self.setup_monitoring()
            
            # Start components (dashboard first, then discovery)
            self.start_dashboard()
            logger.info("Dashboard startup completed")
            
            self.start_monitoring()
            logger.info("Monitoring startup completed")
            
            logger.info("About to start discovery...")
            self.start_discovery()
            logger.info("Discovery startup completed")
            
            # Keep running
            logger.info("Allocator AI is running. Press Ctrl+C to stop.")
            while self.is_running:
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("Shutting down Allocator AI...")
            self.is_running = False
        except Exception as e:
            logger.error(f"Fatal error: {e}", exc_info=True)
            self.is_running = False


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description="Allocator AI - Whale Following Trading Bot")
    parser.add_argument("--mode", choices=["LIVE", "DRY_RUN", "DRY_RUN_WO_MOR", "DRY_RUN_MEMPOOLHACK", "TEST"], default="TEST",
                       help="Operation mode: LIVE (real trading), DRY_RUN (simulate with Moralis), DRY_RUN_WO_MOR (simulate without Moralis to save CU), DRY_RUN_MEMPOOLHACK (block monitoring), TEST (basic test)")
    parser.add_argument("--config", default="config.json", help="Configuration file")
    parser.add_argument("--no-mempool", action="store_true", help="Use block monitoring instead of mempool")
    parser.add_argument("--refresh-whales", action="store_true", 
                       help="Refresh metrics for all tracked whales and exit")
    parser.add_argument("--simulate-trades", action="store_true",
                       help="Include trade simulation when refreshing whale metrics")
    parser.add_argument("--recalc-scores", action="store_true",
                       help="Recalculate all whale scores using Score Formula v2.0 and exit")
    parser.add_argument("--fetch-tokens", action="store_true",
                       help="Fetch real token-level data from Moralis for all whales and exit")
    parser.add_argument("--clear-tokens", action="store_true",
                       help="Clear all whale token data and exit")
    parser.add_argument("--process-adaptive", action="store_true",
                       help="Process adaptive candidates (validate with Moralis and fetch tokens)")
    parser.add_argument("--show-adaptive", action="store_true",
                       help="Show status of adaptive candidates")
    
    args = parser.parse_args()
    
    try:
        # Create and run Allocator AI
        allocator = AllocatorAI(args.config)
        
        # Handle whale refresh command
        if args.refresh_whales:
            logger.info("Refreshing whale metrics...")
            allocator.whale_tracker.refresh_all_whale_metrics(simulate_trades=args.simulate_trades)
            logger.info("Whale metrics refresh completed!")
            return
        
        # Handle score recalculation command
        if args.recalc_scores:
            logger.info("Recalculating all whale scores using Score Formula v2.0...")
            
            # Load existing whales from database
            db_whales = allocator.db_manager.get_all_whales()
            for whale_data in db_whales:
                allocator.whale_tracker.tracked_whales.add(whale_data[0])
            
            logger.info(f"Found {len(allocator.whale_tracker.tracked_whales)} tracked whales")
            
            # First, fetch real token data from Moralis for whales that don't have it
            logger.info("Step 1: Fetching real token data from Moralis for existing whales...")
            fetch_count = 0
            for whale_address in allocator.whale_tracker.tracked_whales:
                try:
                    # Check if whale has token data
                    existing_tokens = allocator.db_manager.get_whale_token_breakdown(whale_address)
                    if not existing_tokens:
                        allocator.whale_tracker.fetch_token_data_from_moralis(whale_address)
                        fetch_count += 1
                        
                        # Add small delay to respect rate limits
                        import time
                        time.sleep(1)
                    else:
                        logger.debug(f"Whale {whale_address} already has {len(existing_tokens)} token records")
                except Exception as e:
                    logger.error(f"Error fetching token data for {whale_address}: {e}")
            
            logger.info(f"Fetched real token data from Moralis for {fetch_count} whales")
            
            # Now recalculate scores for all whales
            logger.info("Step 2: Recalculating scores using Score Formula v2.0...")
            updated_count = 0
            for whale_address in allocator.whale_tracker.tracked_whales:
                try:
                    # Load whale stats into memory first
                    whale_data = allocator.db_manager.get_whale(whale_address)
                    if whale_data:
                        # Create whale stats object if it doesn't exist
                        if whale_address not in allocator.whale_tracker.whale_scores:
                            from allocator.core.whale_tracker import WhaleStats
                            from decimal import Decimal
                            import decimal
                            
                            # Safe conversion function for Decimal fields
                            def safe_decimal(value, default="0"):
                                if value is None or value == '':
                                    return Decimal(default)
                                try:
                                    return Decimal(str(value))
                                except (ValueError, decimal.InvalidOperation, decimal.ConversionSyntax):
                                    logger.warning(f"Invalid decimal value: {value}, using default: {default}")
                                    return Decimal(default)
                            
                            allocator.whale_tracker.whale_scores[whale_address] = WhaleStats(
                                address=whale_address,
                                score=safe_decimal(whale_data[9], "0"),  # score (index 9)
                                roi=safe_decimal(whale_data[6], "0"),    # cumulative_pnl (index 6)
                                trades=whale_data[3] or 0,               # trades (index 3)
                                win_rate=safe_decimal(whale_data[10], "0"), # win_rate (index 10)
                                volatility=Decimal("1"),
                                sharpe_ratio=Decimal("0"),
                                moralis_roi_pct=safe_decimal(whale_data[1], "0"),  # moralis_roi_pct (index 1)
                                moralis_profit_usd=safe_decimal(whale_data[2], "0"), # roi_usd (index 2)
                                moralis_trades=whale_data[3] or 0  # trades (index 3)
                            )
                    
                    # Calculate new score
                    new_score = allocator.whale_tracker.calculate_score_v2(whale_address)
                    if new_score is not None and new_score > 0:
                        allocator.db_manager.update_whale_performance(whale_address, score=new_score)
                        updated_count += 1
                        
                        # Get diversity factor for logging
                        diversity = allocator.whale_tracker.calculate_diversity_factor(whale_address)
                        tokens = allocator.db_manager.get_whale_token_breakdown(whale_address)
                        
                        logger.info(f"Updated {whale_address[:10]}...: Score v2.0 = {new_score:.2f} "
                                  f"(diversity: {diversity:.3f}, tokens: {len(tokens)})")
                    elif new_score is None:
                        logger.warning(f"Whale {whale_address} calculated score is None - skipping update")
                    else:
                        logger.warning(f"Whale {whale_address} calculated score is 0 - skipping update")
                        
                except Exception as e:
                    logger.error(f"Error recalculating score for {whale_address}: {e}")
                    logger.error(f"Error type: {type(e)}")
                    import traceback
                    logger.error(f"Full traceback: {traceback.format_exc()}")
            
            logger.info(f"Score recalculation completed! Updated {updated_count}/{len(allocator.whale_tracker.tracked_whales)} whales.")
            return
        
        # Handle clear tokens command
        if args.clear_tokens:
            logger.info("Clearing all whale token data...")
            
            # Clear the whale_token_pnl table
            with allocator.db_manager.lock:
                cursor = allocator.db_manager.conn.execute("DELETE FROM whale_token_pnl")
                deleted_count = cursor.rowcount
                allocator.db_manager.conn.commit()
            
            logger.info(f"Cleared {deleted_count} token records from database")
            return
        
        # Handle adaptive candidates processing
        if args.process_adaptive:
            logger.info("Processing adaptive candidates...")
            
            # Get unvalidated candidates
            candidates = allocator.db_manager.conn.execute("""
                SELECT address FROM adaptive_candidates 
                WHERE moralis_validated = FALSE 
                ORDER BY discovered_at 
                LIMIT 20
            """).fetchall()
            
            if not candidates:
                logger.info("No unvalidated adaptive candidates found")
                return
            
            logger.info(f"Validating {len(candidates)} adaptive candidates with Moralis...")
            validated_count = 0
            
            for i, (address,) in enumerate(candidates):
                try:
                    logger.info(f"Validating candidate {i+1}/{len(candidates)}: {address[:10]}...")
                    start_time = time.time()
                    
                    # Fetch Moralis data
                    moralis_data = allocator.whale_tracker.fetch_moralis_data(address)
                    if not moralis_data:
                        logger.warning(f"Failed to fetch Moralis data for {address[:10]}...")
                        continue
                    
                    # Check if meets criteria
                    min_roi_pct = Decimal("5")
                    min_profit_usd = Decimal("500")
                    min_trades = 5
                    
                    if (moralis_data["realized_pct"] < min_roi_pct or 
                        moralis_data["realized_usd"] < min_profit_usd or 
                        moralis_data["total_trades"] < min_trades):
                        logger.info(f"Candidate {address[:10]}... rejected: "
                                  f"{moralis_data['realized_pct']}% ROI, "
                                  f"${moralis_data['realized_usd']} profit, "
                                  f"{moralis_data['total_trades']} trades")
                        continue
                    
                    # Add to main whales table
                    if allocator.whale_tracker.bootstrap_whale_from_moralis(address):
                        validated_count += 1
                        logger.info(f"✅ Candidate {address[:10]}... added to main whales")
                        
                        # Update adaptive candidates table
                        allocator.db_manager.conn.execute("""
                            UPDATE adaptive_candidates 
                            SET moralis_validated = TRUE,
                                moralis_roi_pct = ?,
                                moralis_profit_usd = ?,
                                moralis_trades = ?,
                                status = 'validated',
                                processed_at = CURRENT_TIMESTAMP
                            WHERE address = ?
                        """, (
                            float(moralis_data["realized_pct"]),
                            float(moralis_data["realized_usd"]),
                            moralis_data["total_trades"],
                            address
                        ))
                        allocator.db_manager.conn.commit()
                    
                    elapsed = time.time() - start_time
                    logger.info(f"Processed {address[:10]}... in {elapsed:.1f}s")
                    
                    # Small delay to respect rate limits
                    time.sleep(0.5)
                    
                except Exception as e:
                    logger.error(f"Error processing {address[:10]}...: {e}")
            
            logger.info(f"Processed {validated_count} adaptive candidates successfully")
            return
        
        # Handle show adaptive candidates status
        if args.show_adaptive:
            logger.info("Adaptive Candidates Status:")
            
            # Get summary statistics
            stats = allocator.db_manager.conn.execute("""
                SELECT 
                    COUNT(*) as total,
                    SUM(CASE WHEN moralis_validated = TRUE THEN 1 ELSE 0 END) as validated,
                    SUM(CASE WHEN status = 'tokens_fetched' THEN 1 ELSE 0 END) as tokens_fetched,
                    SUM(CASE WHEN status = 'rejected' THEN 1 ELSE 0 END) as rejected
                FROM adaptive_candidates
            """).fetchone()
            
            logger.info(f"  Total discovered: {stats[0]}")
            logger.info(f"  Moralis validated: {stats[1]}")
            logger.info(f"  Token data fetched: {stats[2]}")
            logger.info(f"  Rejected: {stats[3]}")
            
            # Show recent candidates
            recent = allocator.db_manager.conn.execute("""
                SELECT address, status, moralis_roi_pct, moralis_profit_usd, moralis_trades
                FROM adaptive_candidates 
                ORDER BY discovered_at DESC 
                LIMIT 10
            """).fetchall()
            
            if recent:
                logger.info("Recent candidates:")
                for address, status, roi, profit, trades in recent:
                    logger.info(f"  {address[:10]}... | {status} | {roi or 'N/A'}% ROI | ${profit or 'N/A'} | {trades or 'N/A'} trades")
            
            return
        
        
        # Handle token data fetching command
        if args.fetch_tokens:
            logger.info("Fetching real token-level data from Moralis for all whales...")
            
            # Load existing whales from database
            db_whales = allocator.db_manager.get_all_whales()
            for whale_data in db_whales:
                allocator.whale_tracker.tracked_whales.add(whale_data[0])
            
            logger.info(f"Found {len(allocator.whale_tracker.tracked_whales)} tracked whales")
            
            # Fetch token data from Moralis
            fetch_count = 0
            total_tokens = 0
            for whale_address in allocator.whale_tracker.tracked_whales:
                try:
                    logger.info(f"Processing whale {whale_address[:10]}... ({fetch_count + 1}/{len(allocator.whale_tracker.tracked_whales)})")
                    
                    # Check if whale already has token data
                    existing_tokens = allocator.db_manager.get_whale_token_breakdown(whale_address)
                    if existing_tokens:
                        logger.info(f"  Already has {len(existing_tokens)} token records - skipping")
                        continue
                    
                    # Fetch from Moralis
                    allocator.whale_tracker.fetch_token_data_from_moralis(whale_address)
                    fetch_count += 1
                    
                    # Check what was fetched
                    new_tokens = allocator.db_manager.get_whale_token_breakdown(whale_address)
                    total_tokens += len(new_tokens)
                    
                    # Rate limiting delay
                    import time
                    time.sleep(1.2)  # 50 requests per minute max for free Moralis
                    
                except Exception as e:
                    logger.error(f"Error fetching token data for {whale_address}: {e}")
            
            logger.info(f"Token data fetching completed! Processed {fetch_count} whales, got {total_tokens} total token records.")
            return
        
        allocator.run(mode=args.mode, use_mempool=not args.no_mempool)
        
    except Exception as e:
        logger.error(f"Failed to start Allocator AI: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
Whale Analyzer - Automated Copy Trading Analysis

This script analyzes all tracked whales and generates a webpage with
ranked recommendations for copy trading based on multiple criteria.
"""

import sys
import os
import logging
import math
from pathlib import Path
from typing import List, Dict, Tuple, Any
from dataclasses import dataclass
from datetime import datetime

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from allocator.data.database import DatabaseManager

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class WhaleAnalysis:
    """Analysis results for a single whale"""
    address: str
    score_v2: float
    roi_pct: float
    profit_usd: float
    trades: int
    win_rate: float
    risk_multiplier: float
    token_count: int
    token_breakdown: List[Tuple]  # (symbol, address, pnl, trades, last_updated)
    
    # Calculated metrics
    diversification_score: float
    concentration_risk: float
    copy_trading_score: float
    risk_level: str
    recommendation: str
    reasons: List[str]

class WhaleAnalyzer:
    """Analyzes whales for copy trading suitability"""
    
    def __init__(self, db_file: str = "whales.db"):
        self.db_manager = DatabaseManager(db_file)
    
    def calculate_diversification_score(self, token_breakdown: List[Tuple]) -> float:
        """Calculate diversification score (0-100)"""
        if not token_breakdown:
            return 0.0
        
        # Filter out PROCESSED marker and calculate total PnL
        # token_breakdown format: (symbol, address, pnl, trades, last_updated)
        valid_tokens = [(row[0], row[2], row[3]) for row in token_breakdown if row[0] != "PROCESSED"]
        if not valid_tokens:
            return 0.0
        
        total_pnl = sum(pnl for _, pnl, _ in valid_tokens)
        if total_pnl <= 0:
            return 0.0
        
        # Calculate Herfindahl-Hirschman Index (HHI) for concentration
        hhi = 0
        for _, pnl, _ in valid_tokens:
            if pnl > 0:  # Only count profitable tokens
                weight = pnl / total_pnl
                hhi += weight ** 2
        
        # Convert HHI to diversification score (0-100)
        # HHI = 1 means completely concentrated, HHI = 0 means perfectly diversified
        diversification_score = (1 - hhi) * 100
        
        # Bonus for more tokens
        token_bonus = min(len(valid_tokens) * 2, 20)  # Max 20 point bonus
        
        return min(diversification_score + token_bonus, 100)
    
    def calculate_concentration_risk(self, token_breakdown: List[Tuple]) -> float:
        """Calculate concentration risk (0-100, higher = more risky)"""
        if not token_breakdown:
            return 100.0
        
        # token_breakdown format: (symbol, address, pnl, trades, last_updated)
        valid_tokens = [(row[0], row[2], row[3]) for row in token_breakdown if row[0] != "PROCESSED"]
        if not valid_tokens:
            return 100.0
        
        total_pnl = sum(pnl for _, pnl, _ in valid_tokens)
        if total_pnl <= 0:
            return 100.0
        
        # Find top token's percentage of total PnL
        top_token_pnl = max(pnl for _, pnl, _ in valid_tokens)
        top_token_percentage = (top_token_pnl / total_pnl) * 100
        
        # Calculate top 3 tokens' percentage
        sorted_tokens = sorted(valid_tokens, key=lambda x: x[1], reverse=True)
        top3_pnl = sum(pnl for _, pnl, _ in sorted_tokens[:3])
        top3_percentage = (top3_pnl / total_pnl) * 100
        
        # Risk score based on concentration
        risk_score = (top_token_percentage * 0.7) + (top3_percentage * 0.3)
        
        return min(risk_score, 100)
    
    def calculate_copy_trading_score(self, whale: WhaleAnalysis) -> float:
        """Calculate overall copy trading suitability score (0-100)"""
        
        # Base score from Score v2.0 (normalized to 0-100)
        base_score = min(whale.score_v2 / 5, 100)  # Assume max score around 500
        
        # Diversification bonus (0-30 points)
        diversification_bonus = whale.diversification_score * 0.3
        
        # Trade volume bonus (0-20 points)
        volume_bonus = min(whale.trades / 25, 20)  # Max 20 points for 500+ trades
        
        # Win rate bonus (0-15 points)
        win_rate_bonus = whale.win_rate * 15  # Max 15 points for 100% win rate
        
        # Risk penalty (0-25 points penalty)
        risk_penalty = whale.concentration_risk * 0.25
        
        # Token count bonus (0-10 points)
        token_bonus = min(whale.token_count / 2, 10)  # Max 10 points for 20+ tokens
        
        # Calculate final score
        final_score = base_score + diversification_bonus + volume_bonus + win_rate_bonus - risk_penalty + token_bonus
        
        return max(0, min(final_score, 100))
    
    def determine_risk_level(self, concentration_risk: float, risk_multiplier: float) -> str:
        """Determine risk level based on concentration and risk multiplier"""
        if concentration_risk > 80 or risk_multiplier > 1.4:
            return "VERY HIGH"
        elif concentration_risk > 60 or risk_multiplier > 1.2:
            return "HIGH"
        elif concentration_risk > 40 or risk_multiplier > 1.1:
            return "MEDIUM"
        else:
            return "LOW"
    
    def generate_recommendation(self, whale: WhaleAnalysis) -> Tuple[str, List[str]]:
        """Generate recommendation and reasons"""
        reasons = []
        
        # Determine recommendation
        if whale.copy_trading_score >= 80:
            recommendation = "EXCELLENT"
        elif whale.copy_trading_score >= 65:
            recommendation = "GOOD"
        elif whale.copy_trading_score >= 50:
            recommendation = "FAIR"
        elif whale.copy_trading_score >= 35:
            recommendation = "POOR"
        else:
            recommendation = "AVOID"
        
        # Generate reasons
        if whale.trades >= 300:
            reasons.append(f"High trade volume ({whale.trades} trades)")
        elif whale.trades >= 200:
            reasons.append(f"Good trade volume ({whale.trades} trades)")
        elif whale.trades < 100:
            reasons.append(f"Low trade volume ({whale.trades} trades)")
        
        if whale.token_count >= 15:
            reasons.append(f"Excellent diversification ({whale.token_count} tokens)")
        elif whale.token_count >= 10:
            reasons.append(f"Good diversification ({whale.token_count} tokens)")
        elif whale.token_count < 5:
            reasons.append(f"Poor diversification ({whale.token_count} tokens)")
        
        if whale.diversification_score >= 70:
            reasons.append("Well-balanced token allocation")
        elif whale.diversification_score < 30:
            reasons.append("Highly concentrated in few tokens")
        
        if whale.concentration_risk > 80:
            reasons.append("Very high concentration risk")
        elif whale.concentration_risk > 60:
            reasons.append("High concentration risk")
        
        if whale.win_rate >= 0.7:
            reasons.append(f"High win rate ({whale.win_rate*100:.1f}%)")
        elif whale.win_rate < 0.5:
            reasons.append(f"Low win rate ({whale.win_rate*100:.1f}%)")
        
        if whale.roi_pct >= 100:
            reasons.append(f"Excellent ROI ({whale.roi_pct:.1f}%)")
        elif whale.roi_pct >= 50:
            reasons.append(f"Good ROI ({whale.roi_pct:.1f}%)")
        elif whale.roi_pct < 0:
            reasons.append(f"Negative ROI ({whale.roi_pct:.1f}%)")
        
        if whale.risk_multiplier > 1.3:
            reasons.append(f"High risk multiplier ({whale.risk_multiplier:.2f})")
        elif whale.risk_multiplier < 1.1:
            reasons.append(f"Conservative risk ({whale.risk_multiplier:.2f})")
        
        return recommendation, reasons
    
    def analyze_whale(self, whale_data: Tuple) -> WhaleAnalysis:
        """Analyze a single whale"""
        # Database columns: 0=address, 1=moralis_roi_pct, 2=roi_usd, 3=trades, 4=bootstrap_time, 
        # 5=last_refresh, 6=cumulative_pnl, 7=risk_multiplier, 8=allocation_size, 9=score, 10=win_rate, 11=discarded_timestamp
        address = whale_data[0]
        roi_pct = whale_data[1] if len(whale_data) > 1 else 0
        profit_usd = whale_data[2] if len(whale_data) > 2 else 0
        trades = whale_data[3] if len(whale_data) > 3 else 0
        score_v2 = whale_data[9] if len(whale_data) > 9 else 0
        win_rate = whale_data[10] if len(whale_data) > 10 else 0
        risk_multiplier = whale_data[7] if len(whale_data) > 7 else 1.0
        
        # Get token breakdown
        token_breakdown = self.db_manager.get_whale_token_breakdown(address)
        token_count = len([t for t in token_breakdown if t[0] != "PROCESSED"])
        
        # Create analysis object
        whale = WhaleAnalysis(
            address=address,
            score_v2=score_v2,
            roi_pct=roi_pct,
            profit_usd=profit_usd,
            trades=trades,
            win_rate=win_rate,
            risk_multiplier=risk_multiplier,
            token_count=token_count,
            token_breakdown=token_breakdown,
            diversification_score=0,  # Will be calculated
            concentration_risk=0,     # Will be calculated
            copy_trading_score=0,     # Will be calculated
            risk_level="",            # Will be calculated
            recommendation="",        # Will be calculated
            reasons=[]                # Will be calculated
        )
        
        # Calculate metrics
        whale.diversification_score = self.calculate_diversification_score(token_breakdown)
        whale.concentration_risk = self.calculate_concentration_risk(token_breakdown)
        whale.copy_trading_score = self.calculate_copy_trading_score(whale)
        whale.risk_level = self.determine_risk_level(whale.concentration_risk, whale.risk_multiplier)
        whale.recommendation, whale.reasons = self.generate_recommendation(whale)
        
        return whale
    
    def analyze_all_whales(self) -> List[WhaleAnalysis]:
        """Analyze all tracked whales"""
        logger.info("Analyzing all tracked whales...")
        
        # Get all non-discarded whales
        all_whales = self.db_manager.get_all_whales_sorted_by_score()
        logger.info(f"Found {len(all_whales)} whales to analyze")
        
        analyses = []
        for i, whale_data in enumerate(all_whales, 1):
            logger.info(f"Analyzing whale {i}/{len(all_whales)}: {whale_data[0][:10]}...")
            try:
                analysis = self.analyze_whale(whale_data)
                analyses.append(analysis)
            except Exception as e:
                logger.error(f"Error analyzing whale {whale_data[0]}: {e}")
                continue
        
        # Sort by copy trading score (descending)
        analyses.sort(key=lambda x: x.copy_trading_score, reverse=True)
        
        logger.info(f"Analysis complete. Generated {len(analyses)} whale analyses.")
        return analyses
    
    def generate_html_report(self, analyses: List[WhaleAnalysis], output_file: str = "whale_analysis_report.html"):
        """Generate HTML report with whale recommendations"""
        
        html_content = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Whale Copy Trading Analysis Report</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
            color: #333;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
            text-align: center;
        }}
        .header h1 {{
            margin: 0;
            font-size: 2.5em;
        }}
        .header p {{
            margin: 10px 0 0 0;
            font-size: 1.2em;
            opacity: 0.9;
        }}
        .summary {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }}
        .summary-card {{
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            text-align: center;
        }}
        .summary-card h3 {{
            margin: 0 0 10px 0;
            color: #667eea;
        }}
        .summary-card .number {{
            font-size: 2em;
            font-weight: bold;
            color: #333;
        }}
        .whale-card {{
            background: white;
            border-radius: 10px;
            padding: 25px;
            margin-bottom: 20px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            border-left: 5px solid #ddd;
        }}
        .whale-card.excellent {{ border-left-color: #28a745; }}
        .whale-card.good {{ border-left-color: #17a2b8; }}
        .whale-card.fair {{ border-left-color: #ffc107; }}
        .whale-card.poor {{ border-left-color: #fd7e14; }}
        .whale-card.avoid {{ border-left-color: #dc3545; }}
        .whale-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
        }}
        .whale-address {{
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            font-weight: bold;
            color: #333;
        }}
        .copy-btn {{
            background: #007bff;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 0.9em;
        }}
        .copy-btn:hover {{
            background: #0056b3;
        }}
        .metrics-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }}
        .metric {{
            text-align: center;
            padding: 10px;
            background: #f8f9fa;
            border-radius: 5px;
        }}
        .metric-label {{
            font-size: 0.9em;
            color: #666;
            margin-bottom: 5px;
        }}
        .metric-value {{
            font-size: 1.2em;
            font-weight: bold;
            color: #333;
        }}
        .recommendation {{
            background: #e9ecef;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 15px;
        }}
        .recommendation.excellent {{ background: #d4edda; color: #155724; }}
        .recommendation.good {{ background: #d1ecf1; color: #0c5460; }}
        .recommendation.fair {{ background: #fff3cd; color: #856404; }}
        .recommendation.poor {{ background: #f8d7da; color: #721c24; }}
        .recommendation.avoid {{ background: #f5c6cb; color: #721c24; }}
        .reasons {{
            margin-top: 15px;
        }}
        .reasons h4 {{
            margin: 0 0 10px 0;
            color: #333;
        }}
        .reasons ul {{
            margin: 0;
            padding-left: 20px;
        }}
        .reasons li {{
            margin-bottom: 5px;
        }}
        .token-breakdown {{
            margin-top: 20px;
        }}
        .token-breakdown h4 {{
            margin: 0 0 10px 0;
            color: #333;
        }}
        .token-list {{
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
        }}
        .token {{
            background: #e9ecef;
            padding: 4px 8px;
            border-radius: 3px;
            font-size: 0.9em;
        }}
        .token.positive {{ background: #d4edda; color: #155724; }}
        .token.negative {{ background: #f8d7da; color: #721c24; }}
        .risk-indicator {{
            display: inline-block;
            padding: 4px 8px;
            border-radius: 3px;
            font-size: 0.8em;
            font-weight: bold;
            text-transform: uppercase;
        }}
        .risk-low {{ background: #d4edda; color: #155724; }}
        .risk-medium {{ background: #fff3cd; color: #856404; }}
        .risk-high {{ background: #f8d7da; color: #721c24; }}
        .risk-very-high {{ background: #f5c6cb; color: #721c24; }}
        .footer {{
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            color: #666;
            border-top: 1px solid #dee2e6;
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>🐋 Whale Copy Trading Analysis</h1>
        <p>Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    </div>
    
    <div class="summary">
        <div class="summary-card">
            <h3>Total Whales</h3>
            <div class="number">{len(analyses)}</div>
        </div>
        <div class="summary-card">
            <h3>Excellent</h3>
            <div class="number">{len([w for w in analyses if w.recommendation == 'EXCELLENT'])}</div>
        </div>
        <div class="summary-card">
            <h3>Good</h3>
            <div class="number">{len([w for w in analyses if w.recommendation == 'GOOD'])}</div>
        </div>
        <div class="summary-card">
            <h3>Fair</h3>
            <div class="number">{len([w for w in analyses if w.recommendation == 'FAIR'])}</div>
        </div>
        <div class="summary-card">
            <h3>Poor/Avoid</h3>
            <div class="number">{len([w for w in analyses if w.recommendation in ['POOR', 'AVOID']])}</div>
        </div>
    </div>
    
    <div class="whales">
"""
        
        for i, whale in enumerate(analyses, 1):
            # Get top 5 tokens for display
            # token_breakdown format: (symbol, address, pnl, trades, last_updated)
            top_tokens = sorted(whale.token_breakdown, key=lambda x: x[2], reverse=True)[:5]
            top_tokens = [(row[0], row[2], row[3]) for row in top_tokens if row[0] != "PROCESSED"]
            
            html_content += f"""
        <div class="whale-card {whale.recommendation.lower()}">
            <div class="whale-header">
                <div>
                    <div class="whale-address">{whale.address}</div>
                    <div style="font-size: 0.9em; color: #666; margin-top: 5px;">
                        Rank #{i} | Copy Trading Score: {whale.copy_trading_score:.1f}/100
                    </div>
                </div>
                <button class="copy-btn" onclick="copyAddress('{whale.address}')">Copy Address</button>
            </div>
            
            <div class="metrics-grid">
                <div class="metric">
                    <div class="metric-label">Score v2.0</div>
                    <div class="metric-value">{whale.score_v2:.2f}</div>
                </div>
                <div class="metric">
                    <div class="metric-label">ROI</div>
                    <div class="metric-value">{whale.roi_pct:.1f}%</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Profit</div>
                    <div class="metric-value">${whale.profit_usd:,.0f}</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Trades</div>
                    <div class="metric-value">{whale.trades:,}</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Win Rate</div>
                    <div class="metric-value">{whale.win_rate*100:.1f}%</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Tokens</div>
                    <div class="metric-value">{whale.token_count}</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Diversification</div>
                    <div class="metric-value">{whale.diversification_score:.1f}/100</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Risk Level</div>
                    <div class="metric-value">
                        <span class="risk-indicator risk-{whale.risk_level.lower().replace(' ', '-')}">{whale.risk_level}</span>
                    </div>
                </div>
            </div>
            
            <div class="recommendation {whale.recommendation.lower()}">
                <strong>Recommendation: {whale.recommendation}</strong>
            </div>
            
            <div class="reasons">
                <h4>Analysis:</h4>
                <ul>
"""
            
            for reason in whale.reasons:
                html_content += f"                    <li>{reason}</li>\n"
            
            html_content += f"""
                </ul>
            </div>
            
            <div class="token-breakdown">
                <h4>Top Tokens:</h4>
                <div class="token-list">
"""
            
            for symbol, pnl, trades in top_tokens:
                token_class = "positive" if pnl > 0 else "negative"
                html_content += f'                    <span class="token {token_class}">{symbol}: {pnl:.2f} ETH ({trades} trades)</span>\n'
            
            html_content += """
                </div>
            </div>
        </div>
"""
        
        html_content += """
    </div>
    
    <div class="footer">
        <p>Generated by Whale Analyzer - Allocator AI</p>
        <p>Higher scores indicate better copy trading suitability</p>
    </div>
    
    <script>
        function copyAddress(address) {
            navigator.clipboard.writeText(address).then(function() {
                // Show feedback
                event.target.textContent = 'Copied!';
                event.target.style.background = '#28a745';
                
                setTimeout(function() {
                    event.target.textContent = 'Copy Address';
                    event.target.style.background = '#007bff';
                }, 1500);
            }).catch(function(err) {
                console.error('Failed to copy address: ', err);
                alert('Failed to copy address to clipboard');
            });
        }
    </script>
</body>
</html>
"""
        
        # Write to file
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        logger.info(f"HTML report generated: {output_file}")

def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Analyze whales for copy trading suitability")
    parser.add_argument("--output", "-o", default="whale_analysis_report.html",
                       help="Output HTML file (default: whale_analysis_report.html)")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="Verbose logging")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Create analyzer and run analysis
    analyzer = WhaleAnalyzer()
    analyses = analyzer.analyze_all_whales()
    
    # Generate HTML report
    analyzer.generate_html_report(analyses, args.output)
    
    # Print summary
    print(f"\n{'='*60}")
    print("ANALYSIS COMPLETE")
    print(f"{'='*60}")
    print(f"Total whales analyzed: {len(analyses)}")
    print(f"Excellent recommendations: {len([w for w in analyses if w.recommendation == 'EXCELLENT'])}")
    print(f"Good recommendations: {len([w for w in analyses if w.recommendation == 'GOOD'])}")
    print(f"Fair recommendations: {len([w for w in analyses if w.recommendation == 'FAIR'])}")
    print(f"Poor/Avoid recommendations: {len([w for w in analyses if w.recommendation in ['POOR', 'AVOID']])}")
    print(f"\nHTML report generated: {args.output}")
    print(f"Open the file in your browser to view the full analysis!")

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
Whale Manager Script

This script provides commands to manage whales without affecting the main Allocator service.
"""

import sys
import os
import logging
from pathlib import Path

# Add the project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from allocator.data.database import DatabaseManager

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def show_top_whales(n=10):
    """Show top N whales for copying"""
    logger.info(f"Top {n} Whales for Copying:")
    
    db_manager = DatabaseManager("whales.db")
    top_whales = db_manager.get_all_whales_sorted_by_score()[:n]
    
    if not top_whales:
        logger.info("  No whales found")
        return
    
    logger.info("  Rank | Address | Score | Trades | Tokens | ROI% | Win Rate | Risk")
    logger.info("  " + "-" * 100)
    
    for i, whale_data in enumerate(top_whales, 1):
        address = whale_data[0]
        score = whale_data[9] if len(whale_data) > 9 else 0
        trades = whale_data[3] if len(whale_data) > 3 else 0
        roi = whale_data[1] if len(whale_data) > 1 else 0
        win_rate = whale_data[10] if len(whale_data) > 10 else 0
        risk = whale_data[7] if len(whale_data) > 7 else 1.0
        
        # Get token count
        token_breakdown = db_manager.get_whale_token_breakdown(address)
        token_count = len([t for t in token_breakdown if t[0] != "PROCESSED"])
        
        logger.info(f"  {i:2d}   | {address} | {score:6.2f} | {trades:6d} | {token_count:6d} | {roi:5.1f}% | {win_rate*100:7.1f}% | {risk:4.2f}")
    
    logger.info(f"\n💡 Copy any address above to start following that whale!")
    logger.info(f"💡 Higher score = better overall performance")
    logger.info(f"💡 More trades + tokens = more reliable data")
    logger.info(f"💡 Lower risk multiplier = more conservative")

def show_discarded_whales():
    """Show all discarded whales"""
    logger.info("Discarded Whales:")
    
    db_manager = DatabaseManager("whales.db")
    discarded_whales = db_manager.get_discarded_whales()
    
    if not discarded_whales:
        logger.info("  No discarded whales found")
        return
    
    logger.info(f"  Found {len(discarded_whales)} discarded whales:")
    logger.info("  Address | Score | Trades | ROI% | Discarded Time")
    logger.info("  " + "-" * 80)
    
    for whale_data in discarded_whales:
        address = whale_data[0]
        score = whale_data[9] if len(whale_data) > 9 else 0
        trades = whale_data[3] if len(whale_data) > 3 else 0
        roi = whale_data[1] if len(whale_data) > 1 else 0
        discarded_time = whale_data[11] if len(whale_data) > 11 else "Unknown"
        
        # Convert timestamp to readable format
        if discarded_time and discarded_time != "Unknown":
            try:
                import datetime
                discarded_time = datetime.datetime.fromtimestamp(int(discarded_time)).strftime('%Y-%m-%d %H:%M:%S')
            except:
                pass
        
        logger.info(f"  {address[:10]}... | {score:.2f} | {trades} | {roi:.2f}% | {discarded_time}")

def rescan_whale(address):
    """Remove discarded status from a whale to allow rescanning"""
    logger.info(f"Removing discarded status from whale {address}...")
    
    db_manager = DatabaseManager("whales.db")
    success = db_manager.rescan_whale(address)
    
    if success:
        logger.info(f"Successfully removed discarded status from {address}")
        logger.info("Whale is now ready for rescanning")
    else:
        logger.error(f"Failed to remove discarded status from {address}")

def show_adaptive_candidates():
    """Show status of adaptive candidates"""
    logger.info("Adaptive Candidates Status:")
    
    db_manager = DatabaseManager("whales.db")
    
    # Get summary statistics
    stats = db_manager.conn.execute("""
        SELECT 
            COUNT(*) as total,
            SUM(CASE WHEN moralis_validated = TRUE THEN 1 ELSE 0 END) as validated,
            SUM(CASE WHEN status = 'tokens_fetched' THEN 1 ELSE 0 END) as tokens_fetched,
            SUM(CASE WHEN status = 'rejected' THEN 1 ELSE 0 END) as rejected
        FROM adaptive_candidates
    """).fetchone()
    
    total, validated, tokens_fetched, rejected = stats
    logger.info(f"  Total candidates: {total}")
    logger.info(f"  Validated with Moralis: {validated}")
    logger.info(f"  Tokens fetched: {tokens_fetched}")
    logger.info(f"  Rejected: {rejected}")
    
    # Show recent candidates
    recent = db_manager.conn.execute("""
        SELECT address, status, moralis_roi_pct, moralis_profit_usd, moralis_trades
        FROM adaptive_candidates 
        ORDER BY created_at DESC 
        LIMIT 10
    """).fetchall()
    
    if recent:
        logger.info("Recent candidates:")
        for address, status, roi, profit, trades in recent:
            logger.info(f"  {address[:10]}... | {status} | {roi or 'N/A'}% ROI | ${profit or 'N/A'} | {trades or 'N/A'} trades")

def show_whale_details(address):
    """Show detailed information about a specific whale"""
    logger.info(f"Whale Details for {address}:")
    
    db_manager = DatabaseManager("whales.db")
    whale_data = db_manager.get_whale(address)
    
    if not whale_data:
        logger.error(f"Whale {address} not found in database")
        return
    
    logger.info(f"  Address: {whale_data[0]}")
    logger.info(f"  Moralis ROI: {whale_data[1]:.2f}%")
    logger.info(f"  Moralis Profit: ${whale_data[2]:.2f}")
    logger.info(f"  Trades: {whale_data[3]}")
    logger.info(f"  Cumulative PnL: {whale_data[6]:.4f} ETH")
    logger.info(f"  Risk Multiplier: {whale_data[7]:.2f}")
    logger.info(f"  Allocation Size: {whale_data[8]:.4f} ETH")
    logger.info(f"  Score v2.0: {whale_data[9]:.2f}")
    logger.info(f"  Win Rate: {whale_data[10]*100:.1f}%")
    logger.info(f"  Bootstrap Time: {whale_data[4]}")
    logger.info(f"  Last Refresh: {whale_data[5]}")
    
    # Show token breakdown
    token_breakdown = db_manager.get_whale_token_breakdown(address)
    if token_breakdown:
        logger.info(f"  Token Breakdown ({len(token_breakdown)} tokens):")
        for token_symbol, token_address, token_pnl, trade_count, last_updated in token_breakdown:
            if token_symbol != "PROCESSED":
                logger.info(f"    {token_symbol}: {token_pnl:.4f} ETH ({trade_count} trades)")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Whale Manager - Manage whales without affecting main service")
    parser.add_argument("--top", type=int, metavar="N", default=None,
                       help="Show top N whales for copying")
    parser.add_argument("--discarded", action="store_true",
                       help="Show all discarded whales")
    parser.add_argument("--rescan", type=str, metavar="ADDRESS",
                       help="Remove discarded status from a whale to allow rescanning")
    parser.add_argument("--adaptive", action="store_true",
                       help="Show status of adaptive candidates")
    parser.add_argument("--details", type=str, metavar="ADDRESS",
                       help="Show detailed information about a specific whale")
    
    args = parser.parse_args()
    
    if args.top is not None:
        show_top_whales(args.top)
    elif args.discarded:
        show_discarded_whales()
    elif args.rescan:
        rescan_whale(args.rescan)
    elif args.adaptive:
        show_adaptive_candidates()
    elif args.details:
        show_whale_details(args.details)
    else:
        # Default: show top 10 whales
        show_top_whales(10)
"""
Windows Service wrapper for Allocator AI
Install: python allocator_service.py install
Start: python allocator_service.py start
Stop: python allocator_service.py stop
Remove: python allocator_service.py remove
"""

import sys
import os
import servicemanager
import win32serviceutil
import win32service
import win32event
import subprocess

class AllocatorService(win32serviceutil.ServiceFramework):
    _svc_name_ = "AllocatorAI"
    _svc_display_name_ = "Allocator AI Trading Bot"
    _svc_description_ = "Whale Following Trading Bot for Cryptocurrency"

    def __init__(self, args):
        win32serviceutil.ServiceFramework.__init__(self, args)
        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)
        self.process = None

    def SvcStop(self):
        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)
        if self.process:
            self.process.terminate()
        win32event.SetEvent(self.hWaitStop)

    def SvcDoRun(self):
        servicemanager.LogMsg(
            servicemanager.EVENTLOG_INFORMATION_TYPE,
            servicemanager.PYS_SERVICE_STARTED,
            (self._svc_name_, '')
        )
        
        # Change to the directory containing main.py
        script_dir = os.path.dirname(os.path.abspath(__file__))
        os.chdir(script_dir)
        
        # Start the main script
        try:
            self.process = subprocess.Popen([
                sys.executable, 'main.py', '--mode', 'LIVE'
            ])
            
            # Wait for service stop or process termination
            while True:
                wait_result = win32event.WaitForSingleObject(self.hWaitStop, 1000)
                if wait_result == win32event.WAIT_OBJECT_0:
                    break
                if self.process.poll() is not None:
                    # Process terminated, restart it
                    servicemanager.LogMsg(
                        servicemanager.EVENTLOG_WARNING_TYPE,
                        servicemanager.PYS_SERVICE_STARTED,
                        (self._svc_name_, 'Process terminated, restarting...')
                    )
                    self.process = subprocess.Popen([
                        sys.executable, 'main.py', '--mode', 'LIVE'
                    ])
                    
        except Exception as e:
            servicemanager.LogMsg(
                servicemanager.EVENTLOG_ERROR_TYPE,
                servicemanager.PYS_SERVICE_STARTED,
                (self._svc_name_, f'Error: {str(e)}')
            )

if __name__ == '__main__':
    win32serviceutil.HandleCommandLine(AllocatorService)
#!/usr/bin/env python3
"""
Test script for adaptive whale discovery
Fetches adaptive candidates and processes them separately from the main bot
"""

import os
import sys
import time
import logging
import argparse
from pathlib import Path
from decimal import Decimal

# Add the allocator package to the path
sys.path.insert(0, str(Path(__file__).parent))

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # Manual env loading
    env_file = Path(__file__).parent / ".env"
    if env_file.exists():
        with open(env_file) as f:
            for line in f:
                if line.strip() and not line.startswith('#') and '=' in line:
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value

from allocator.config import Config
from allocator.data import DatabaseManager, CacheManager
from allocator.core import WhaleTracker
from allocator.utils.web3_utils import Web3Manager
from allocator.analytics.adaptive_discovery import AdaptiveDiscoveryEngine
from allocator.analytics.market_conditions import MarketConditionAnalyzer

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("adaptive_discovery.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("adaptive_discovery")


class AdaptiveDiscoveryTester:
    """Test adaptive discovery independently"""
    
    def __init__(self, config_file: str = "config.json"):
        # Load configuration
        self.config = Config.from_env_and_file(config_file)
        self.config.validate()
        
        # Initialize components
        self.db_manager = DatabaseManager(self.config.database.file_path)
        self.cache_manager = CacheManager()
        
        # Initialize Web3
        self.web3_manager = Web3Manager(self.config.web3.rpc_url)
        
        # Initialize adaptive components
        self.market_analyzer = MarketConditionAnalyzer(self.web3_manager.w3, self.cache_manager)
        self.adaptive_engine = AdaptiveDiscoveryEngine(self.web3_manager.w3, self.market_analyzer)
        
        # Initialize whale tracker for Moralis calls
        self.whale_tracker = WhaleTracker(
            self.config.moralis_api_key,
            self.cache_manager,
            self.db_manager,
            self.config.discovery
        )
        
        # Create adaptive candidates table
        self._create_adaptive_candidates_table()
    
    def _create_adaptive_candidates_table(self):
        """Create table for adaptive discovery candidates"""
        with self.db_manager.lock:
            self.db_manager.conn.execute("""
                CREATE TABLE IF NOT EXISTS adaptive_candidates (
                    address TEXT PRIMARY KEY,
                    activity_score INTEGER,
                    profit_eth REAL,
                    trades INTEGER,
                    discovered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    processed_at TIMESTAMP,
                    moralis_validated BOOLEAN DEFAULT FALSE,
                    moralis_roi_pct REAL,
                    moralis_profit_usd REAL,
                    moralis_trades INTEGER,
                    status TEXT DEFAULT 'discovered'
                )
            """)
            self.db_manager.conn.commit()
            logger.info("Adaptive candidates table ready")
    
    def discover_adaptive_candidates(self, max_candidates: int = 50) -> list:
        """Discover adaptive candidates using percentile-based thresholds"""
        try:
            # Get adaptive configuration
            adaptive_config = getattr(self.config.discovery, 'adaptive_discovery', None)
            if not adaptive_config:
                logger.error("Adaptive discovery config not found")
                return []
            
            percentile_config = getattr(adaptive_config, "percentile_mode", {}) or {}
            if not percentile_config.get("enabled", False):
                logger.error("Adaptive percentile discovery is disabled")
                return []
            
            activity_percentile = percentile_config.get("activity_percentile", 5.0)
            profit_percentile = percentile_config.get("profit_percentile", 25.0)
            blocks_back = percentile_config.get("blocks_back", 10000)
            
            logger.info(f"Running adaptive discovery: top {activity_percentile}% activity, "
                       f"top {profit_percentile}% profit over {blocks_back} blocks")
            
            # Run adaptive discovery
            result = self.adaptive_engine.discover_whales_percentile(
                activity_percentile=activity_percentile,
                profit_percentile=profit_percentile,
                blocks_back=blocks_back
            )
            
            candidates = result.get("candidates", [])
            logger.info(f"Found {len(candidates)} adaptive candidates")
            
            # Store candidates in database
            new_candidates = []
            for candidate in candidates[:max_candidates]:
                if self._store_candidate(candidate, result):
                    new_candidates.append(candidate)
            
            logger.info(f"Stored {len(new_candidates)} new candidates in database")
            return new_candidates
            
        except Exception as e:
            logger.error(f"Adaptive discovery failed: {e}")
            return []
    
    def _store_candidate(self, address: str, discovery_result: dict) -> bool:
        """Store candidate in database if not already exists"""
        try:
            # Check if already exists
            existing = self.db_manager.conn.execute(
                "SELECT address FROM adaptive_candidates WHERE address = ?", (address,)
            ).fetchone()
            
            if existing:
                logger.debug(f"Candidate {address[:10]}... already exists in database")
                return False
            
            # Get candidate stats from discovery result
            thresholds = discovery_result.get("thresholds", {})
            activity_threshold = thresholds.get("trades", 0)
            profit_threshold = thresholds.get("profit", 0)
            
            # Store candidate
            self.db_manager.conn.execute("""
                INSERT INTO adaptive_candidates 
                (address, activity_score, profit_eth, trades, status)
                VALUES (?, ?, ?, ?, ?)
            """, (address, activity_threshold, profit_threshold, activity_threshold, "discovered"))
            
            self.db_manager.conn.commit()
            logger.info(f"Stored new candidate: {address[:10]}...")
            return True
            
        except Exception as e:
            logger.error(f"Failed to store candidate {address}: {e}")
            return False
    
    def validate_candidates_with_moralis(self, max_candidates: int = 20) -> list:
        """Validate candidates with Moralis API"""
        try:
            # Get unprocessed candidates
            candidates = self.db_manager.conn.execute("""
                SELECT address FROM adaptive_candidates 
                WHERE moralis_validated = FALSE 
                ORDER BY discovered_at 
                LIMIT ?
            """, (max_candidates,)).fetchall()
            
            if not candidates:
                logger.info("No unvalidated candidates found")
                return []
            
            logger.info(f"Validating {len(candidates)} candidates with Moralis...")
            validated_candidates = []
            
            for i, (address,) in enumerate(candidates):
                try:
                    logger.info(f"Validating candidate {i+1}/{len(candidates)}: {address[:10]}...")
                    start_time = time.time()
                    
                    # Fetch Moralis data
                    moralis_data = self.whale_tracker.fetch_moralis_data(address)
                    if not moralis_data:
                        logger.warning(f"Failed to fetch Moralis data for {address[:10]}...")
                        self._update_candidate_status(address, "failed_moralis")
                        continue
                    
                    # Check if meets criteria
                    min_roi_pct = Decimal("5")
                    min_profit_usd = Decimal("500")
                    min_trades = 5
                    
                    if (moralis_data["realized_pct"] < min_roi_pct or 
                        moralis_data["realized_usd"] < min_profit_usd or 
                        moralis_data["total_trades"] < min_trades):
                        logger.info(f"Candidate {address[:10]}... rejected: "
                                  f"{moralis_data['realized_pct']}% ROI, "
                                  f"${moralis_data['realized_usd']} profit, "
                                  f"{moralis_data['total_trades']} trades")
                        self._update_candidate_status(address, "rejected")
                        continue
                    
                    # Update candidate with Moralis data
                    self._update_candidate_moralis(address, moralis_data)
                    validated_candidates.append(address)
                    
                    elapsed = time.time() - start_time
                    logger.info(f"✅ Candidate {address[:10]}... validated ({elapsed:.1f}s)")
                    
                    # Small delay to respect rate limits
                    time.sleep(0.5)
                    
                except Exception as e:
                    logger.error(f"Error validating {address[:10]}...: {e}")
                    self._update_candidate_status(address, "error")
            
            logger.info(f"Validated {len(validated_candidates)} candidates successfully")
            return validated_candidates
            
        except Exception as e:
            logger.error(f"Validation failed: {e}")
            return []
    
    def _update_candidate_status(self, address: str, status: str):
        """Update candidate status"""
        try:
            self.db_manager.conn.execute("""
                UPDATE adaptive_candidates 
                SET status = ?, processed_at = CURRENT_TIMESTAMP
                WHERE address = ?
            """, (status, address))
            self.db_manager.conn.commit()
        except Exception as e:
            logger.error(f"Failed to update status for {address}: {e}")
    
    def _update_candidate_moralis(self, address: str, moralis_data: dict):
        """Update candidate with Moralis data"""
        try:
            self.db_manager.conn.execute("""
                UPDATE adaptive_candidates 
                SET moralis_validated = TRUE,
                    moralis_roi_pct = ?,
                    moralis_profit_usd = ?,
                    moralis_trades = ?,
                    status = 'validated',
                    processed_at = CURRENT_TIMESTAMP
                WHERE address = ?
            """, (
                float(moralis_data["realized_pct"]),
                float(moralis_data["realized_usd"]),
                moralis_data["total_trades"],
                address
            ))
            self.db_manager.conn.commit()
        except Exception as e:
            logger.error(f"Failed to update Moralis data for {address}: {e}")
    
    def fetch_token_data_for_validated(self, max_candidates: int = 10) -> int:
        """Fetch token data for validated candidates"""
        try:
            # Get validated candidates without token data
            candidates = self.db_manager.conn.execute("""
                SELECT address FROM adaptive_candidates 
                WHERE moralis_validated = TRUE 
                AND status = 'validated'
                ORDER BY processed_at 
                LIMIT ?
            """, (max_candidates,)).fetchall()
            
            if not candidates:
                logger.info("No validated candidates found for token data fetching")
                return 0
            
            logger.info(f"Fetching token data for {len(candidates)} validated candidates...")
            processed_count = 0
            
            for i, (address,) in enumerate(candidates):
                try:
                    logger.info(f"Fetching tokens for candidate {i+1}/{len(candidates)}: {address[:10]}...")
                    start_time = time.time()
                    
                    # Fetch token data
                    self.whale_tracker.fetch_token_data_from_moralis(address)
                    
                    # Update status
                    self._update_candidate_status(address, "tokens_fetched")
                    processed_count += 1
                    
                    elapsed = time.time() - start_time
                    logger.info(f"✅ Token data fetched for {address[:10]}... ({elapsed:.1f}s)")
                    
                    # Delay to respect rate limits
                    time.sleep(1)
                    
                except Exception as e:
                    logger.error(f"Error fetching token data for {address[:10]}...: {e}")
                    self._update_candidate_status(address, "token_error")
            
            logger.info(f"Fetched token data for {processed_count} candidates")
            return processed_count
            
        except Exception as e:
            logger.error(f"Token data fetching failed: {e}")
            return 0
    
    def show_candidates_summary(self):
        """Show summary of all candidates"""
        try:
            # Get summary statistics
            stats = self.db_manager.conn.execute("""
                SELECT 
                    COUNT(*) as total,
                    SUM(CASE WHEN moralis_validated = TRUE THEN 1 ELSE 0 END) as validated,
                    SUM(CASE WHEN status = 'tokens_fetched' THEN 1 ELSE 0 END) as tokens_fetched,
                    SUM(CASE WHEN status = 'rejected' THEN 1 ELSE 0 END) as rejected
                FROM adaptive_candidates
            """).fetchone()
            
            logger.info(f"Adaptive Candidates Summary:")
            logger.info(f"  Total discovered: {stats[0]}")
            logger.info(f"  Moralis validated: {stats[1]}")
            logger.info(f"  Token data fetched: {stats[2]}")
            logger.info(f"  Rejected: {stats[3]}")
            
            # Show recent candidates
            recent = self.db_manager.conn.execute("""
                SELECT address, status, moralis_roi_pct, moralis_profit_usd, moralis_trades
                FROM adaptive_candidates 
                ORDER BY discovered_at DESC 
                LIMIT 10
            """).fetchall()
            
            if recent:
                logger.info("Recent candidates:")
                for address, status, roi, profit, trades in recent:
                    logger.info(f"  {address[:10]}... | {status} | {roi or 'N/A'}% ROI | ${profit or 'N/A'} | {trades or 'N/A'} trades")
            
        except Exception as e:
            logger.error(f"Failed to show summary: {e}")


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description="Test Adaptive Discovery")
    parser.add_argument("--discover", action="store_true", help="Discover new adaptive candidates")
    parser.add_argument("--validate", action="store_true", help="Validate candidates with Moralis")
    parser.add_argument("--fetch-tokens", action="store_true", help="Fetch token data for validated candidates")
    parser.add_argument("--summary", action="store_true", help="Show candidates summary")
    parser.add_argument("--max-candidates", type=int, default=20, help="Maximum candidates to process")
    parser.add_argument("--config", default="config.json", help="Configuration file")
    
    args = parser.parse_args()
    
    try:
        tester = AdaptiveDiscoveryTester(args.config)
        
        if args.discover:
            logger.info("Starting adaptive discovery...")
            candidates = tester.discover_adaptive_candidates(args.max_candidates)
            logger.info(f"Discovery completed. Found {len(candidates)} new candidates.")
        
        if args.validate:
            logger.info("Starting Moralis validation...")
            validated = tester.validate_candidates_with_moralis(args.max_candidates)
            logger.info(f"Validation completed. {len(validated)} candidates validated.")
        
        if args.fetch_tokens:
            logger.info("Starting token data fetching...")
            processed = tester.fetch_token_data_for_validated(args.max_candidates)
            logger.info(f"Token fetching completed. {processed} candidates processed.")
        
        if args.summary:
            tester.show_candidates_summary()
        
        if not any([args.discover, args.validate, args.fetch_tokens, args.summary]):
            logger.info("No action specified. Use --help for available options.")
            tester.show_candidates_summary()
            
    except Exception as e:
        logger.error(f"Script failed: {e}", exc_info=True)


if __name__ == "__main__":
    main()
